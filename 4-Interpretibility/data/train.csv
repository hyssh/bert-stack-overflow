52821204,"How to queue build pipeline as task from release pipeline? <p>There is a build pipeline that someone else owns in the project (it runs one shell script task doesn't publish anything). I own a release pipeline and want to run a job that effectively \queues\"" their build pipeline. I cannot add an extension to do this. Regardless of how we got to this point or best practices  is there a way to accomplish triggering a build of their build pipeline from a job in the release pipeline in azure devops? Thank you.</p>""",azure-devops
52818615,"Unable to download the change history and the discussion details of \Scrum tasks\"" in VSTS using odata <p>I don't exactly know how to fetch the change history and discussion details in VSTS. I have looked into Workitems and Work Item Revisions but didn't get any data related to history or discussion from it.</p>  <p>PFB the format of odata url used - </p>  <pre><code>https://analytics.dev.azure.com/{OrganizationName}/{ProjectName}/_odata/{version}//WorkItemRevisions?   $filter=WorkItemId eq {Id}   &amp;$select=WorkItemId  Title  State  https://analytics.dev.azure.com/{OrganizationName}/{ProjectName}/_odata/{version}//WorkItems?   $filter=WorkItemId eq {Id}   &amp;$select=WorkItemId  Title  State </code></pre>""",azure-devops
55840501,Is FileUpload functionality for Azure IoT Java SDK possible on Android? <p>We've been trying to use the Azure IoT SDK for Java on Android (via Kotlin) to initiate blob file uploads. The process seems to hang after the SAS token is received and the call to the CloudBlockBlob constructor is made.</p>  <p>So I tried calling the constructor directly and discovered a dependency on <code>javax.xml.stream.XMLOutputFactory</code> by virtue of the dependency on the Azure Storage SDK v. 2.2 (suprisingly old!).  The <code>javax</code> libraries AFAIK aren't easily incorporated on Android.  </p>  <p>There is a separate Android storage SDK (which presumably doesn't have these dependencies)  but including that in addition to the IoT SDK understandably results in a ton of Duplicate Class errors.</p>  <p>What's the way out of this?  Fork the Azure IoT SDK for Java and replace the storage SDK reference with the Android version?</p>,azure-storage
29638084,"Error Calling InitializeCache on WindowsAzure Storage Account <p>I have the following snippet being called on on application start:</p>  <pre><code>var driveCache = RoleEnvironment.GetLocalResource(\imageslive\""); CloudDrive.InitializeCache(driveCache.RootPath  driveCache.MaximumSizeInMegabytes); </code></pre>  <p>This has been working for year or so. I have just upload a new version of the site and am now getting the following error:</p>  <pre><code>Exception of type 'Microsoft.WindowsAzure.CloudDrive.Interop.InteropCloudDriveException' was thrown. at ThrowIfFailed(UInt32 hr) at Microsoft.WindowsAzure.StorageClient.CloudDrive.InitializeCache(String cachePath  Int32 totalCacheSize)  Unknown Error HRESULT=80070103 at Microsoft.WindowsAzure.StorageClient.CloudDrive.InitializeCache(String cachePath  Int32 totalCacheSize) at Site.Global.Application_Start(Object sender  EventArgs e) </code></pre>  <p>This works when running from within VS with the emulator so presumably is something about the update. </p>  <p>Does anyone have any pointers about how I might go about getting more information? I cannot see any way of getting more information  let alone what the sudden cause of the error is.</p>""",azure-storage
56484241,"AZURE_FUNCTIONS_ENVIRONMENT vs ASPNETCORE_ENVIRONMENT <p>In azure functions (v2  c#)  there are two environment variables that can be potentially used to identify the name of the current environment.</p>  <ul> <li><code>AZURE_FUNCTIONS_ENVIRONMENT</code></li> <li><code>ASPNETCORE_ENVIRONMENT</code></li> </ul>  <p>I am planning to use <code>AZURE_FUNCTIONS_ENVIRONMENT</code>  and I am wondering if there are reasons to choose one over another?</p>  <p>In terms of behavior of the two  this is what I discovered:</p>  <ul> <li><code>AZURE_FUNCTIONS_ENVIRONMENT</code> is set to <code>Development</code> locally by the functions host/runtime. It is not automatically set in azure to <code>Production</code>. One can set this in App Settings in azure.</li> <li><code>ASPNETCORE_ENVIRONMENT</code> is not set by the functions host/runtime either locally or in Azure.</li> </ul>  <p>I have also raised a <a href=\https://github.com/Azure/azure-functions-host/issues/4491\"" rel=\""nofollow noreferrer\"">github issue</a> about this a couple of weeks ago  but got no response. I am hoping I might get an answer here.</p>""",azure-functions
15122998,Azure Blob Shared Access Signature without the api <p>I'm trying to create a REST call to Azure to List Blobs within a container.  The container is private so I need to access it through a Shared Access Signature (SAS).</p>  <p>I make that call in a Silverlight application so I cannot use the Client API.</p>  <p>I find a lot of examples with ClientAPI but nothing really clear and obvious for REST.</p>  <p>Anyone has a nice... clean and simple example on how to do that?</p>  <p>Thanks</p>,azure-storage
39381114,"Azure Webapp wheels --find-links does not work <p>I have been struggling with --find-links for an entire day  and I will be very grateful if sb could help me out here.</p>  <p>I have been developing using python3.4 and one of the new features I added uses Azure Storage( the most recent version) and it requires cryptograph  which requires cffi  idna  etc... However  when I try to test it against Azure Webapp  the deployment failes  saying 'error : unable to find vcvarsall.bat'</p>  <p>With some research  I figured putting --find-links wheelhouse at the top of my requirements.txt and have wheels(cffi-1.8.2-cp34-cp34m-win32.whl (md5) and cryptography-1.5-cp34-cp34m-win32.whl (md5)) located at wheelhouse folder in the root should work. This was not helping at all  and I was running into same problems.</p>  <p>I tried --no-index and it gives \Could not find any downloads that satisfy the requirement cffi==1.8.2\"". Somebody says if I want to use --no-index  then I should have all wheels located in wheelhouse; otherwise  i will get that error.</p>  <p>With this  I would like to use my wheels for cffi and cryptograph and the rest download from pypi. Anyone have any clue...? HELP!</p>""",azure-web-app-service
55574037,"Access denied on wwwroot after DevOps deployment <p>I've deployed a .Net Core web application to Azure App Service using Azure DevOps. Now  when I try to create file in 'D:\\home\\site\\wwwroot' using Kudu it says:</p>  <blockquote>   <p>409 Conflict: Could not write to local resource 'D:\\home\\site\\wwwroot\\anc' >due to error 'Could not find file 'D:\\home\\site\\wwwroot\\anc'.'.</p> </blockquote>  <p>I've noticed that the persmissions on the 'D:\\home\\site\\wwwroot' directory are different than in a similar web app that I deployed using Publish Profile</p>  <p>Get-Acl result on the problematic app:</p>  <pre><code>PS D:\\home\\site\\wwwroot&gt; Get-Acl \D:\\home\\site\\wwwroot\"" Get-Acl \""D:\\home\\site\\wwwroot\""         Directory: D:\\home\\site      Path    Owner                   Access                                           ----    -----                   ------                                           wwwroot IIS APPPOOL\\luncher-dev NT AUTHORITY\\SYSTEM Allow  FullControl...         </code></pre>  <p>Get-Acl result on other similar app:</p>  <pre><code>PS D:\\home\\site\\wwwroot&gt; Get-Acl \""D:\\home\\site\\wwwroot\"" Get-Acl \""D:\\home\\site\\wwwroot\""         Directory: D:\\home\\site      Path    Owner                  Access                                            ----    -----                  ------                                            wwwroot BUILTIN\\Administrators Everyone Allow  DeleteSubdirectoriesAndFiles ...   </code></pre>  <p>Corresponding Release pipeline from Azure DevOps</p>  <p><img src=\""https://i.imgur.com/BiFopkW.png\"" alt=\""Dev Ops Pipeline\""></p>  <p>How can I make the wwwroot directory writable?</p>""",azure-devops
53532538,Running an Azure DevOps pipline via CLI or web-hook <p>Is there a way to run (queue) a specific azure pipeline from the command line or via http web-hook or an API ? I would like to automatically trigger a pipeline without the need to change git or whatever. </p>,azure-devops
50077386,"How to dynamically define 'path' in @BlobOutput? <p>I am looking at the following code example at <a href=\https://github.com/Azure/azure-functions-java-worker\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-functions-java-worker</a></p>  <pre><code>public class MyClass {     @FunctionName(\""copy\"")     @StorageAccount(\""AzureWebJobsStorage\"")     @BlobOutput(name = \""$return\""  path = \""samples-output-java/{name}\"")     public static String copy(@BlobTrigger(name = \""blob\""  path = \""samples-input-java/{name}\"") String content) {         return content;     } } </code></pre>  <p>In <code>@BlobOutput</code> we are using <code>{name}</code> parameter  because it was provided to us in <code>@BlobInput</code>. How can I dynamically generate that name in my function?</p>  <p>I want my blob name to be <code>files/E36567AB1B93F7D9798</code> where the <code>E36567AB1B93F7D9798</code> part is a hash generated from blob content. I want to generate it inside the function and return the hash as output. Sort of like GitHub creates unique IDs for files.</p>""",azure-functions
11096470,"Accessing azure storage services <p>There are couple of ways to access azure storage services. And I wanted to know from the experts:</p>  <ul> <li>Which is the recommended way for accessing azure storage services?</li> <li>What are the pros/cons of either? (like performance  no of requests…)</li> </ul>  <p><a href=\http://msdn.microsoft.com/en-us/library/microsoft.windowsazure.storageclient.aspx\"" rel=\""nofollow\"">Windows Azure Storage Client Library Class Library</a> OR <a href=\""http://msdn.microsoft.com/en-us/library/windowsazure/dd179355\"" rel=\""nofollow\"">Windows Azure Storage Services REST API</a> </p>""",azure-storage
55062220,Disable certain W3C logging fields on Azure App Services <p>When logging web server logs in Azure App Services  every field is logged by default and there doesn't seem to be any way to disable specific fields.</p>  <p>Is there a way around this? Or am I missing something?</p>,azure-web-app-service
41119540,To add/remove Partition key and Row key to use Azure Tables with WebAPI <p>I am developing an application back-end using Azure and Web API. For this I have created some Azure tables. Below is the sample of my model.</p>  <pre><code>public class Device : TableEntity  {    public Device(string partitionKey  string rowKey)      {         this.PartitionKey = partitionKey;         this.RowKey = rowKey;      }        public Device() { }        public string DeviceName { get; set; }        public string DeviceOS { get; set; }        public string Make { get; set; }  } </code></pre>  <p>The Partition Key is formed by using Table Name like UD_Device (UD_ being a constant and Device being the table name. The Row key is simply the DeviceName unique for all devices.</p>  <p>Now when I query these tables in my Web API I get a List of entities along with Partition key and Row key as properties in them. </p>  <p>This list I have to give it to the front-end angular application as JSON  but the Partition Key and Row Key are not to be sent while doing this.</p>  <p>Same thing when I am making a POST request i.e. when I am getting data from angular front-end and I have to send it to Azure Table  then the user does not send the Partition key and Row key. So how could I make a model which caters need to both this requirement? </p>,azure-storage
11733665,"Load Balancing virtual machines via Service Management API - MS Azure <p>I found the below article to create a virtual machine and load balance with an existing virtual machine.</p>  <p><a href=\https://www.windowsazure.com/en-us/manage/windows/common-tasks/how-to-load-balance-virtual-machines/?_sm_au_=iVVNR02FVsMFjVB3\"" rel=\""nofollow\"">https://www.windowsazure.com/en-us/manage/windows/common-tasks/how-to-load-balance-virtual-machines/?_sm_au_=iVVNR02FVsMFjVB3</a></p>  <p>But how can the same be done via Service Management API.</p>  <p>The  related tags i found in the POST request to create a VM are   </p>  <p>LoadBalancedEndpointSetName  LoadBalancerProbe</p>  <p>Where do I get started ? How do i connect two virtual machine via API ?</p>  <p>Thanks.</p>""",azure-virtual-machine
56664562,"How to access Azure VM from App Service in virtual network by private DNS name? <ul> <li>VM and App Service are located in the same Virtual Network.</li> <li>App Service is added to VM through VNet Integration (preview)</li> <li>VM is autoregistered in Private DNS zone  say by name <code>myvm1</code>. And full name <code>myvm1.priv.zone</code></li> <li>Private DNS zone is linked to Virtual Network.</li> <li>Virtual Network - DNS Servers is set to default.</li> <li>VM and App Service were restarted after configuration.</li> </ul>  <p>Problem is I can resolve neither <code>myvm1</code> nor <code>myvm1.priv.zone</code> from App Service console by <code>nameresolver.exe</code></p>  <p>UPDATE: Actually  the issue is even bigger. App Service is not able to send requests to VMs in Virtual Network by their Private IPs (10.1.x.x) even if everything is allowed on VMs' subnet. If the same requests are sent to VMs' Public IPs there is no problem. <a href=\https://i.stack.imgur.com/uu2D5.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/uu2D5.png\"" alt=\""VNET Integration settings\""></a></p>""",azure-virtual-machine
46047177,Build and Deploy Azure Functions App from Build Server <p>I have an Azure Functions App developed in Visual Studio using C# and Microsoft.NET.Sdk.Function.</p>  <p>I need to build and deploy this app from our Jenkins build server. What is the recommended approach? MSBuild? MSDeploy? Azure Functions CLI? FTP? I can't use the Source Control or VSTS deployment. </p>  <p>Some sample scripts would be appreciated!</p>,azure-functions
42086641,"Azure App-Service Swap \Bounces\"" Between Source and Destination <p>I'm seeing some interesting behavior on Azure App Service that I'm hoping somebody will be kind enough to comment on.</p>  <p>Reproduction steps (all Azure steps can be done in the portal):</p>  <ul> <li>Create a new Web App in App Service (Standard pricing level  single instance is fine)  e.g. <code>mysite</code></li> <li><a href=\""https://docs.microsoft.com/en-us/azure/app-service-web/web-sites-staged-publishing\"" rel=\""nofollow noreferrer\"">Create a new staging slot</a> for that App  e.g. <code>mysite-staging</code></li> <li>Deploy a bare-bones ASP.NET app to <code>mysite</code> with a file /scripts/test.js that has the content <code>//ONE</code></li> <li>Deploy a bare-bones ASP.NET app to <code>mysite-staging</code> with a file /scripts/test.js that has the content <code>//TWO</code></li> <li><a href=\""https://docs.microsoft.com/en-us/azure/app-service-web/web-sites-staged-publishing#swap-deployment-slots\"" rel=\""nofollow noreferrer\"">Swap the deployment slots</a></li> <li>Immediately after the swap starts  navigate to <code>mysite.azurewebsites.net/scripts/test.js</code> and monitor the returned content during the swap operation (by continually doing a force-refresh in the browser)</li> </ul>  <p>What I would expect to see:</p>  <ul> <li>At some point during the swap  the content changes seamlessly/consistently/irreversibly from <code>//ONE</code> to <code>//TWO</code></li> </ul>  <p>What I actually see:</p>  <ul> <li>During the swap operation  the content \""flickers\""/\""bounces\"" between <code>//ONE</code> and <code>//TWO</code>. After the swap operation is complete  the behavior is stable and <code>//TWO</code> is consistently returned</li> </ul>  <p>The observed behavior suggests that there is no single point in time at which all traffic can be said to be going to the new version.</p>  <p>The reason this concerns me is the following scenario:</p>  <ul> <li>A user requests a page mysite.azurewebsites.net which  during this \""bouncing\"" stage  responds with the \""v2\"" version of the page with a link to a CDN-hosted script <code>mycdn.com/scripts/test.js?v2</code> (the <code>?v2</code> is a new query string)</li> <li>The browser requests the script from the CDN  which in turn requests the script from <code>mysite.azurewebsites.net</code>. This time  the \""bouncing\"" causes the response to be the v1 version of the script. </li> <li>Now we have a v1 version of the script cached in the CDN  which all users in that region will load with the v2 version of the page</li> </ul>  <p><strong>My question</strong>: Is this \""bouncing\"" behavior during a swap operation \""by design\""? If so  what is the recommended approach for solving the pathological case above?</p>""",azure-web-app-service
52319281,"Azure Function Custom Class request body - No Parameter-less constructor/Invalid Cast string -> guid <p>I have an azure function that looks something like:</p>  <pre><code>    [FunctionName(\AddMaterial\"")]     public static async Task&lt;IActionResult&gt; Run([HttpTrigger(AuthorizationLevel.Function  \""post\""  Route = null)]AddMaterialCommand command           ILogger log  [Inject(typeof(IMediator))]IMediator mediator)     {         log.LogInformation(\""AddMaterial Function is processing a request\"");          var events = await mediator.Send(command);         if (events != null)         {             await mediator.Publish(events);             return (ActionResult)new OkObjectResult(events);         }         return new BadRequestObjectResult(new { message = \""Please check that WarehouseId  RollPoNumber  RollNumber  Location and RollWeight are included in request\"" });     } </code></pre>  <p>This function uses the custom object AddMaterialCommand as the request per <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook#http-trigger\"" rel=\""nofollow noreferrer\"">the docs</a>.</p>  <p>The custom object class looks something like this: </p>  <pre><code>{     [DataContract]     public class AddMaterialCommand : IRequest&lt;EventList&gt;     {         [DataMember]         public Guid WarehouseId { get; set; }          [DataMember]         public int RollPoNumber { get; set; }         [DataMember]         public DateTime? DateRecieved { get; set; }          public AddMaterialCommand(Guid warehouseId  int rollPoNumber   DateTime dateRecieved)         {             WarehouseId = warehouseId;             RollPoNumber = rollPoNumber;             Location = location;             DateRecieved = dateRecieved;         } } </code></pre>  <p>When posting to the function it throws this error:</p>  <blockquote>   <p>Executed 'AddMaterial' (Failed    Id=d7322061-c972-4e93-83cd-4d0313d26e86) [9/12/2018 8:59:46 PM]   System.Private.CoreLib: Exception while executing function:   AddMaterial. Microsoft.Azure.WebJobs.Host: Exception binding parameter   'command'. <strong>System.Private.CoreLib: No parameterless constructor   defined for this object</strong>.</p> </blockquote>  <p>When I add a parameterless constructor (why do I need to do this?)  it then fails with this error:</p>  <blockquote>   <p>Executed 'AddMaterial' (Failed    Id=973cd363-19d6-49a3-a2eb-759f30c284bb) [9/12/2018 9:01:27 PM]   System.Private.CoreLib: Exception while executing function:   AddMaterial. Microsoft.Azure.WebJobs.Host: Exception binding parameter   'command'. <strong>System.Private.CoreLib: Invalid cast from 'System.String'   to 'System.Guid</strong>'.</p> </blockquote>  <p>What is going on here?</p>  <p>My best guess is that the body of the request is not getting read and that an empty value is throwing the invalid cast exception. I'm still clueless as to why I need a paramaterless constructor. I didn't have this issue before moving to azure functions when I was using the <code>[FromBody]</code> binding  but I don't think I can use that binding with azure functions. </p>""",azure-functions
20631279,SSRS Reports hosted in Azure Virtual Machine not available outside the VM <p>I have created an ssrs report inside an Azure Virtual Machine (SQL Server 2012 SP1 on Windows Server 2012). When I try to view the report from the Virtual machine it opens up in the browser with a proper url like</p>  <pre><code>    http://mysamplevm/ReportServer/Pages/ReportViewer.aspx?%2fMySampleReport&amp;rs:Command=Render </code></pre>  <p>When I try to open the same url from my local machine  it says webpage is not available. I have completed the following settings too.</p>  <ul> <li>Created Inbound &amp; Outbound rules in Virtual Machine Firewall for port numbers 80 and 443.</li> <li>Created end points for the same port numbers in azure management portal.</li> </ul>,azure-virtual-machine
48428031,Weird issue with JWT token with web app in Azure <p>I have 2 web apps setup in azure  both with the same clientids setup with oauth middleware. Both use the same Azure AD  with the same user I get a token and on one webapp I get a claimsprincipal but on the other one I get a windowsprincipal. Why could this be?</p>,azure-web-app-service
39845540,"Could not retrieve the repositories: Visual Studio Team Services and Azure <p>I'm trying to do <a href=\https://azure.microsoft.com/en-us/documentation/articles/cloud-services-continuous-delivery-use-vso/\"" rel=\""nofollow noreferrer\"">Continuous delivery to Azure using Visual Studio Team Services</a>. But when i try to connect Azure my web app to Visual Studio Team Services (Visual Studio Online) after typing the url for Team Services. it does the authorization successfully. but I get the following error.</p>  <p><a href=\""https://i.stack.imgur.com/U2Y9x.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/U2Y9x.png\"" alt=\""enter image description here\""></a></p>  <p>I was looking at this screen for a long time but it doesn't seem to complete. What mistake am I making here?</p>""",azure-devops
25491683,Lost all linux azure VM changes from 8/16 - 8/22. Possible to get those changes back & What can I do in the future to avoid this? <p>I'm having a serious concern with my azure VM  as the title says I lost all of my change from 8/16 to 8/22. This was noticed on the 23rd  I am wondering if due to maintenance all changes were reverted back to 8/16? I need to know if its possible to get the VM back to state it was at the end of the day 8/22. </p>  <p>More importantly - I need to know how to avoid such regressions of the VM in the future. </p>,azure-virtual-machine
14260654,"Unable to recreate Azure VM deleted after going over free limit <p>I had two VMs running in azure and went over my free limit for this month. I enabled the ability to charge my account and found they were gone.</p>  <p>The VM disks are still there but the VMs themselves have been made into hosted services. To recreate the VM I deleted the hosted service  then went to the create new VM dialog like I've seen others post previously. Under the \create from disk\"" option I do not see either of my OS disks as options to create a VM. Is this the right way to recreate VMs or am I missing something?</p>  <p>Also of note  the disks still show up as attached to the deleted VMs in the portal.</p>""",azure-virtual-machine
55605560,"Azure Blob Storage Java SDK: Why isn't asynchronous working? <p>I am still spinning up on the Azure Storage Java SDK 10 and its use of reactive programming the paradigm.  I wrote the following method to asynchronously download a blob to a byte stream as fast as possible.  When I use the synchronous version (below)  it works properly.  When I comment out the blockingAwait() and uncomment the subscribe  the write and the doOnComplete never are executed...  Basically  the run just falls out of the bottom of the method back to the caller.  I am sure that I have made an asynchronous processing mistake  and hope that someone can steer me in the correct direction.  By the way  I was surprised to find that there are very few samples of downloading to a stream rather than to a file...  Hopefully  this posting will help others.</p>  <h2>Thank you for your time and interest in my problem...</h2>  <pre><code>override fun downloadBlob(url: String  downloadStream: OutputStream) {      BlockBlobURL(URL(url)  pipeline)             .download(null  null  false  null)             .flatMapCompletable { response -&gt;                 FlowableUtil.collectBytesInBuffer(response.body(null))                         .map {                             Channels.newChannel(downloadStream).write(it)                         }.toCompletable()             }.doOnComplete {                 println(\The blob was downloaded...\"")             }.blockingAwait()             //.subscribe() } </code></pre>  <p>Here is the code that is calling the above method:</p>  <pre><code>fun getAerialImageBlobStream(aerialImageUrl: String): MapOutputStream {      val aerialImageStream = MapOutputStream()     blobStorage.downloadBlob(aerialImageUrl  aerialImageStream)     return aerialImageStream } </code></pre>""",azure-storage
43207962,"Azure Web App - Prevent routing to specific instances <p>We are hosting an ASP.NET Core application on an Azure App Service (Web Apps).</p>  <p>Our individual instances take some time to \preload\"" the required data needed to process requests. But when scaling out  requests will be routed to the instances still being prepared.</p>  <p>How does the App Service load balancer decide when an instance is ready and requests can be routed to it? Is there a way to prevent routing to some specific instance until we deem it ready?</p>""",azure-web-app-service
50011679,"Was BlobEncryptionPolicy removed for azure storage? <p>I'm trying to use client side encryption for azure to securely upload files to blob storage in .NET </p>  <p>However it seems that BlobEncryptionPolicy is not available and I have not seen any documentation specifying alternative solutions from microsoft.</p>  <p>Even their documentation still uses BlobEncryptionPolicy:</p>  <p><a href=\https://docs.microsoft.com/en-us/azure/storage/common/storage-client-side-encryption?toc=%2Fazure%2Fstorage%2Fblobs%2Ftoc.json\"" rel=\""nofollow noreferrer\"">Client-Side Encryption and Azure Key Vault for Microsoft Azure Storage</a></p>  <p>Specifically i'm inside of a xamarin project using the latest .net version. </p>  <p>If i create a sample console app  I can reference BlobEncryptionPolicy without any issues. However the same nuget package inside a xamarin shared project can not resolve the reference to BlobEncryptionPolicy under the Microsoft.WindowsAzure.Storage.Blob namespace.</p>  <p>Does anyone know what is going on here?</p>""",azure-storage
49314112,"Add Azure Web App diagnostic log settings to ARM template <p>I'm looking for the option to enable diagnostic log settings (file level  not blob) on the template deployment stage.<br> I've found the following <a href=\https://github.com/davidebbo/AzureWebsitesSamples/blob/master/ARMTemplates/WebAppManyFeatures.json\"" rel=\""nofollow noreferrer\"">example</a> on Github however  it doesn't work  saying <code>\""Microsoft.Web/sites/logs\"" is not a valid option\""</code>.<br> Below is the part of my template:  </p>  <pre><code>{           \""apiVersion\"": \""2015-08-01\""            \""name\"": \""logs\""            \""type\"": \""config\""            \""location\"": \""[resourcegroup().location]\""            \""dependsOn\"": [             \""[resourceId('Microsoft.Web/Sites'  parameters('siteName'))]\""           ]            \""properties\"": {             \""applicationLogs\"": {               \""fileSystem\"": {                 \""level\"": \""Verbose\""               }             }              \""httpLogs\"": {               \""fileSystem\"": {                 \""retentionInMb\"": 100                  \""retentionInDays\"": 90                  \""enabled\"": true               }             }              \""failedRequestsTracing\"": {               \""enabled\"": true             }              \""detailedErrorMessages\"": {               \""enabled\"": true             }           }         }  </code></pre>  <p>Also  I've found the <a href=\""https://social.msdn.microsoft.com/Forums/en-US/716b1d6c-6bff-4b39-ada0-727330d014b5/azure-arm-diagnostic-logs-settings?forum=windowsazurewebsitespreview\"" rel=\""nofollow noreferrer\"">following</a> discussion on a similar question but the topic starter stated that this piece of code works correctly in most cases.</p>""",azure-web-app-service
51308330,"How to use Connection String in Azure functions for EF Core 2.1 <p>When using Entity Framework 6+ I can have a class inherit form DbContext like this</p>  <pre><code>MyContext : DbContext </code></pre>  <p>Then I could use the code like this </p>  <pre><code>using (var context = new MyContext())         {         ...         } </code></pre>  <p>As long as I had a configuration file with connection string settings with the same name this would be picked up by Entity Framework. Quite nice for different environments.</p>  <p>Now I am working with Azure Functions running on .NET CORE  .NET STANDARD and Entity Framework Core 2.1</p>  <p>But I cant figure out how to achieve the same. Even though there is a dedicated section for ConnectionStrings in Azure Function app and i would expect the local.seeting.json with an input like this </p>  <pre><code>  {       \IsEncrypted\"": false        \""Values\"": {         \""AzureWebJobsStorage\"": \""UseDevelopmentStorage=true\""          \""AzureWebJobsDashboard\"": \""UseDevelopmentStorage=true\""        }        \""ConnectionStrings\"": {         \""MyContext\"": \""Server=(localdb)\\\\mssqllocaldb;Database=MyContext;Trusted_Connection=True;ConnectRetryCount=0\""       }     }  </code></pre>  <p>should do the same. But no.</p>  <p>All the samples I can find is where you have to inject the DbContextOptionsBuilder or a connection string into the constructor.</p>  <p>But since it is Azure Function and DI framework dont play that well with it I rather avoid to pass the connection string or db context all the way down the layers. </p>  <p>In short: Can EF Core not pick up the settings from a file itself?</p>""",azure-functions
49900848,"Azure Functions \Consumption Plan\"" HIPAA Compliance <p>Since Azure Functions host are dynamically added and removed based on the number of incoming events under \""Consumption Plan\""  what is the guarantee that Azure transparently encrypts the data in-transit as well as at-rest on the hosts? Are there any documentations which can share some light on how Azure Functions fulfills HIPAA compliance?</p>""",azure-functions
51558155,".Net Core web api not working after deployed to Azure <p>I do have a simple .Net Core web api application  the one made by Visual Studio when a new project is created. I want to deploy it to an Azure App Service via FTP (part of a TFS 2017 build job)  which is successful:</p>  <p><a href=\https://i.stack.imgur.com/o3fW7.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/o3fW7.png\"" alt=\""enter image description here\""></a></p>  <p>However  when trying a GET like <code>http://somerandomname.azurewebsites.net/api/values</code> all I get is a 404 with the text</p>  <blockquote>   <p>The resource you are looking for has been removed  had its name changed  or is temporarily unavailable.</p> </blockquote>  <p>From Kudu I get the following error: <a href=\""https://i.stack.imgur.com/CPuyn.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/CPuyn.png\"" alt=\""enter image description here\""></a></p>  <p>What am I missing?</p>""",azure-web-app-service
45571362,"Full Public Read Access on Azure Storage Emulator <p>I am putting together a website which I would like to host static content via Azure Blob. The documentation is very clear on how to set \Public read access for blobs only\"" to a container via this document: <a href=\""https://docs.microsoft.com/en-us/azure/storage/storage-manage-access-to-resources\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/storage/storage-manage-access-to-resources</a></p>  <p>In my development environment I am using the Azure storage emulator (<a href=\""https://docs.microsoft.com/en-us/azure/storage/storage-use-emulator\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/storage/storage-use-emulator</a>). </p>  <p>My question is: How can I set the permission of a container in the emulator to \""Public read access for blobs only\""?</p>""",azure-storage
53257498,"How to get an free Azure account for testing Azure devOps project <p>I am trying to get a Azure free account but it needs a credit card at sign up. I don't have a credit card to get started. Is there an alternative for subscribing to Azure. I require this to work on Azure DevOps CD stage. </p>  <p><a href=\https://i.stack.imgur.com/i4eg9.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/i4eg9.png\"" alt=\""Subscription\""></a></p>  <p>This is required for working on Azure DevOps Labs. Since there is not much practical solution available out there for Azure DevOps  these labs provide very good base for learning the DevOps process. These labs require azure subscription which is a road block for even learning the process.</p>  <p><a href=\""https://i.stack.imgur.com/R5jTz.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/R5jTz.png\"" alt=\""azuredevopslabs\""></a></p>""",azure-devops
52377689,"Merge multiple web projects into a single output zip package <p>I'm using Visual Studio Online and working through building a continuous integration setup. The scenario I have requires that multiple web projects are built out to a single Azure App Service deployment.  The catch is that \out of the box\"" when you create a new build  the Visual Studio Build task appears to create a separate zip file for each project in the solution  and then the Azure App Service Deploy task throws an error saying there is more than one file matching the pattern  which is *.zip. </p>  <p>What I'd like to do is build all of these projects out to a single location  merging the various projects together  and then Azure App Service Deploy only has a single zip file to push  which I know it can do just fine. My MSBuild arguments for the Visual Studio Build task are <code>/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:PackageLocation=\""$(build.artifactstagingdirectory)\\\\\""</code>. I tried removing the <code>PackageAsSingleFile</code> attribute but it still created the zip files.</p>  <p>Is the scenario I want to do possible in VSO  perhaps with a different set of command codes?</p>""",azure-devops
57137369,"How do I transfer artifacts in Azure Pipelines between pipelines in the same azure project? <p>I am trying to set up Azure Pipelines to have the Idris 1 binary produced for the various platforms here: <a href=\https://github.com/zenntenn/Idris-dev\"" rel=\""nofollow noreferrer\"">https://github.com/zenntenn/Idris-dev</a> from head and use it to build Idris 2 head for the various platforms from here: <a href=\""https://github.com/zenntenn/Idris2\"" rel=\""nofollow noreferrer\"">https://github.com/zenntenn/Idris2</a> . </p>  <p>My problem is I can't figure out how to configure the two pipelines properly to make this work. </p>  <p>I have been trying to follow the documentation here: </p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/artifacts/pipeline-artifacts?view=azure-devops&amp;tabs=yaml\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/artifacts/pipeline-artifacts?view=azure-devops&amp;tabs=yaml</a></p>  <p>I can't figure out how to get the exact YAML needed to make it work for Idris 2.</p>  <p>Idris 1 pipeline is here: <a href=\""https://dev.azure.com/zentenca/Idris/_build?definitionId=2\"" rel=\""nofollow noreferrer\"">https://dev.azure.com/zentenca/Idris/_build?definitionId=2</a></p>  <p>Idris 2 pipeline is here: <a href=\""https://dev.azure.com/zentenca/Idris/_build?definitionId=1\"" rel=\""nofollow noreferrer\"">https://dev.azure.com/zentenca/Idris/_build?definitionId=1</a></p>  <p>This is the relevant section of my current Idris 1 azure-pipelines.yml:</p>  <pre><code>  # Test on Linux   - job: Linux     pool:       vmImage: 'ubuntu-16.04'     steps:     - script: |         echo Collection ID is $(System.CollectionId)         sudo add-apt-repository ppa:hvr/ghc         sudo apt-get update         sudo apt-get install ghc-8.2.2 cabal-install-2.2         sudo update-alternatives --config opt-ghc         sudo update-alternatives --config opt-cabal       displayName: 'Prepare system'     - script: |         export PATH=/opt/ghc/bin:$HOME/.cabal/bin:$PATH         cabal update         CABALFLAGS=\""-fffi -fci\"" make       displayName: 'Build Idris'     - script: |         export PATH=/opt/ghc/bin:$HOME/.cabal/bin:$PATH         make test_c       displayName: 'Run tests'     - publish: $(System.DefaultWorkingDirectory)/       artifact: LinuxHead </code></pre>  <p>This is what I have currently for Idris 2's azure-pipelines.yml:</p>  <pre><code># Build Idris 2 from Idris 1.  Idris 1 located here: https://github.com/idris-lang/Idris-dev jobs:   # Linux build using the latest Idris 1   - job: Linux_Latest     pool:       vmImage: 'ubuntu-16.04'     steps:     - task: DownloadPipelineArtifact@2       inputs:         source: 'specific'         artifact: LinuxHead         project: e3cceb10-4a17-48c7-a9b8-72264bd71a81         pipelineid: 2         runVersion: 'latest'     - script: |          echo Works so far     displayName: 'Linux build using the latest Idris 1' </code></pre>  <p>I am trying to have the build results of Idris 1 show up in a way that I can access them in the Idris 2 pipeline.</p>  <p>The current error is: \""Input string was not in a correct format.\""</p>  <p>If in the Idris 2 azure-pipelines.yml I change pipelineid: to pipeline: I get the error:</p>  <p>\""TF50309: The following account does not have sufficient permissions to complete the operation: Idris Build Service (zentenca). The following permissions are needed to perform this operation: View project-level information.\""</p>  <p>Example build result using pipeline: is here: <a href=\""https://dev.azure.com/zentenca/Idris/_build/results?buildId=35&amp;view=results\"" rel=\""nofollow noreferrer\"">https://dev.azure.com/zentenca/Idris/_build/results?buildId=35&amp;view=results</a></p>""",azure-devops
36089171,Consume soap web service from Azure web app <p>I'm trying to consume a soap web service from an azure web app.</p>  <p>To do this I need to run a connectivity test through telnet to do this.</p>  <p>How would I go about doing this in Azure?</p>  <p>thanks</p>  <p>Chris</p>,azure-web-app-service
41982562,"VSTS Task Creation : Required field missing <p>I am trying to create task in <code>VSTS</code>  but I am getting the below <em>error</em>.</p>  <blockquote>   <p>TF401320: Rule Error for field Task Type. Error code: Required  HasValues  LimitedToValues  AllowsOldValue  InvalidEmpty.</p> </blockquote>  <p>From <code>Exception</code> it is clear that I am missing a required field which is <code>Task Type</code>. Now I am not able to find the field path for <code>Task Type</code>. Can anyone help me with this.</p>  <p>Below is the code I am writing to add a task :</p>  <pre><code>string discipline = \Research Task\"";  if (taskDesc.Key.Contains(\""Configuration\"")) {     discipline = \""Dev Task\""; } if (taskDesc.Key.Contains(\""Validation\"")) {     discipline = \""Quality Task\""; }  var workitemtype = \""Task\""; var document = new JsonPatchDocument(); document.Add(     new JsonPatchOperation()     {         Path = \""/fields/Microsoft.VSTS.Common.Discipline\""          Operation = Microsoft.VisualStudio.Services.WebApi.Patch.Operation.Add          Value = discipline     }); document.Add(     new JsonPatchOperation()     {         Path = \""/fields/System.Title\""          Operation = Microsoft.VisualStudio.Services.WebApi.Patch.Operation.Add          Value = string.Format(\""{0} {1}\""  porIDText  taskDesc.Key)     }); document.Add(new JsonPatchOperation() {     Path = \""/fields/System.AreaPath\""      Operation = Microsoft.VisualStudio.Services.WebApi.Patch.Operation.Add      Value = System.Configuration.ConfigurationManager.AppSettings[\""AreaPath\""] }); document.Add(     new JsonPatchOperation()     {         Path = \""/fields/System.AssignedTo\""          Operation = Microsoft.VisualStudio.Services.WebApi.Patch.Operation.Add          Value = \""&lt;name&gt;\""     }); document.Add(     new JsonPatchOperation()     {         Path = \""/fields/System.Description\""          Operation = Microsoft.VisualStudio.Services.WebApi.Patch.Operation.Add          Value = taskDesc.Value     }); var wi = client.CreateWorkItemAsync( document  teamProjectName  workitemtype).Result; </code></pre>""",azure-devops
54237884,Durable Functions - Activities seem to stop <p>Please could someone confirm my thoughts.</p>  <p>I have an orchestration  which is calling the same Activity say 400 times. I'm using a fan-out/fan-in concept. </p>  <pre><code>await Task.WhenAll(collectionOfTasks); </code></pre>  <p>If those 400 activities take longer than 10 minutes in total to process  it seems that it doesn't complete  and doesn't pick up/continue again  unless another call is made to the orchestration method.</p>  <p>Is this right? Does the Azure Function shut down if nothing is running in the Orchestration for 10 minutes? Doesn't matter if the Activities functions are still running?</p>,azure-functions
36252723,How do I delete an availability set? <p>I wanted to try out using Azure availability sets  but it turns out I can't use them because my nodes cannot be in the same cloud service. I now have an unused availability set but I don't see it listed anywhere in my Resources in the Portal. Is there anyway to delete an availability set?</p>,azure-virtual-machine
52235684,How to create VSTS Service Endpoint using Azure Keyvault secrets <p>Am working on VSTS CI&amp;CD. For that  am trying to create “Azure Resource Manager” Service Endpoint as a VSTS Connection. But  here I don’t want give SPN credentials i.e. “Client Id and Client Secret” directly for making connection  in spite of that I need to pass SPN Credentials which are in Keyvault secrets saved in Azure keyvault. Is this possible  that the VSTS Service Endpoint creation using Azure Keyvault Secrets. If possible  please suggest me to “How to done it”</p>,azure-devops
57394529,"No agents are registered or you do not have permission to view the agents <p>After creating the new custom agent pool  if I am view that  I am seeing the message as \No agents are registered or you do not have permission to view the agents.\"". Can anyone tell me what kind permission is needed or do I need to any other configuration? </p>  <p>And I have created this pool with my username which has administrator privilege.</p>""",azure-devops
45058223,"How to monitor Azure Classic VM using REST API or via Java SDK? <p>HI i want to  monitor Azure Classic VM using REST API/Java SDK   when i tried it with REST API with the following URL(The below url worked for Azure VM) </p>  <pre><code>https://management.azure.com/subscriptions/&lt;subscription_id&gt;/resourceGroups/Preprod2-Resource-Group/providers/Microsoft.ClassicCompute/virtualMachines/cloudops-testvm1/providers/microsoft.insights/metrics?api-version=2016-09-01 </code></pre>  <p>I'm getting the following error</p>  <blockquote>   <p>{     \code\"": \""NotFound\""      \""message\"": \""Resource provider not found: [Microsoft.ClassicCompute]\""   }</p> </blockquote>  <p>Please suggest me if it can be done via REST API or if there is an SDK please suggest me the same.</p>  <p>My requirement is i want to monitor Classic VM and collect Network In Network Out Percentage CPU Disk Read Operations/Sec Disk Write Operations/Sec Disk Write Bytes and Disk Read Bytes for every 5mins</p>""",azure-virtual-machine
32941879,"multiple public IPs for Azure Virtual machine <p>I have found it difficult to figure out how to have multiple public IPs for one Azure Virtual Server... </p>  <ol> <li>it is possible?</li> <li>exactly what are the commands to do so?</li> </ol>  <p>I've already added what seemed to be virtual ips via <a href=\https://stackoverflow.com/questions/15132756/azure-vm-more-than-one-public-ip\"">this article</a>. which also references <a href=\""https://azure.microsoft.com/en-gb/updates/multiple-vips-per-cloud-service/\"" rel=\""nofollow noreferrer\"">this article</a></p>  <p>But I'm really confused now... <a href=\""https://azure.microsoft.com/en-us/pricing/details/ip-addresses/\"" rel=\""nofollow noreferrer\"">This link</a> talks about pricing pricing pricing  but nowhere on any page so far have I seen how to actually <strong><em>configure</em></strong> a load balancer.. There's a difference between ReservedIPs and Virtual IPs(VIPs)...</p>  <p>help?</p>""",azure-virtual-machine
47749537,"Azure REST API metric Collection Data JSON Issue <p>When I try to collect metrics for VM using AZURE REST API for some m/c's I get metrics where data is in average and for some m/c's I get data in total please help me fix this issue   I want to get only average data for last 5mins .</p>  <p>I'm using the following URL </p>  <p><code>https://management.azure.com/subscriptions/{subscription_ID}/resourceGroups/rg-np-eastjp-vnet-10-198-0-0-24/providers/Microsoft.Compute/virtualMachines/vm-dev-eastjp-waf/providers/microsoft.insights/metrics?api-version=2016-09-01&amp;$filter=%28+name.value+eq+%27Network+In%27+or++name.value+eq+%27Network+Out%27+or++name.value+eq+%27Percentage+CPU%27+or++name.value+eq+%27Disk+Read+Bytes%27+or++name.value+eq+%27Disk+Write+Bytes%27+or++name.value+eq+%27Disk+Read+Operations%2FSec%27+or++name.value+eq+%27Disk+Write+Operations%2FSec%27++%29+and+timeGrain+eq+duration%27PT5M%27+and+startTime+eq+2017-12-08T12%3A58%3A41.729+and+endTime+eq+2017-12-08T13%3A03%3A41.729+</code></p>  <p><a href=\https://i.stack.imgur.com/5Lksw.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/5Lksw.png\"" alt=\""Data output 1\""></a> <a href=\""https://i.stack.imgur.com/x3z07.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/x3z07.png\"" alt=\""Data output 2\""></a></p>  <p>The following is the O/P for total:</p>  <pre><code>{   \""value\"":[     {       \""data\"":[         {           \""timeStamp\"":\""2017-12-11T08:19:00Z\""            \""total\"":1791478.0         }       ]        \""id\"":\""/subscriptions/{subscription_ID}/resourceGroups/MWatchLab-dev-db-mcs-473968/providers/Microsoft.Compute/virtualMachines/dev-db-mcs/providers/Microsoft.Insights/metrics/Network In\""        \""name\"":{         \""value\"":\""Network In\""          \""localizedValue\"":\""Network In\""       }        \""type\"":\""Microsoft.Insights/metrics\""        \""unit\"":\""Bytes\""     }      {       \""data\"":[         {           \""timeStamp\"":\""2017-12-11T08:19:00Z\""            \""total\"":1503183.0         }       ]        \""id\"":\""/subscriptions/{subscription_ID}/resourceGroups/MWatchLab-dev-db-mcs-473968/providers/Microsoft.Compute/virtualMachines/dev-db-mcs/providers/Microsoft.Insights/metrics/Network Out\""        \""name\"":{         \""value\"":\""Network Out\""          \""localizedValue\"":\""Network Out\""       }        \""type\"":\""Microsoft.Insights/metrics\""        \""unit\"":\""Bytes\""     }      {       \""data\"":[         {           \""timeStamp\"":\""2017-12-11T08:19:00Z\""            \""total\"":896.99         }       ]        \""id\"":\""/subscriptions/{subscription_ID}/resourceGroups/MWatchLab-dev-db-mcs-473968/providers/Microsoft.Compute/virtualMachines/dev-db-mcs/providers/Microsoft.Insights/metrics/Percentage CPU\""        \""name\"":{         \""value\"":\""Percentage CPU\""          \""localizedValue\"":\""Percentage CPU\""       }        \""type\"":\""Microsoft.Insights/metrics\""        \""unit\"":\""Percent\""     }      {       \""data\"":[         {           \""timeStamp\"":\""2017-12-11T08:19:00Z\""            \""total\"":0.0         }       ]        \""id\"":\""/subscriptions/{subscription_ID}/resourceGroups/MWatchLab-dev-db-mcs-473968/providers/Microsoft.Compute/virtualMachines/dev-db-mcs/providers/Microsoft.Insights/metrics/Disk Read Bytes\""        \""name\"":{         \""value\"":\""Disk Read Bytes\""          \""localizedValue\"":\""Disk Read Bytes\""       }        \""type\"":\""Microsoft.Insights/metrics\""        \""unit\"":\""Bytes\""     }      {       \""data\"":[         {           \""timeStamp\"":\""2017-12-11T08:19:00Z\""            \""total\"":5022690.87         }       ]        \""id\"":\""/subscriptions/{subscription_ID}/resourceGroups/MWatchLab-dev-db-mcs-473968/providers/Microsoft.Compute/virtualMachines/dev-db-mcs/providers/Microsoft.Insights/metrics/Disk Write Bytes\""        \""name\"":{         \""value\"":\""Disk Write Bytes\""          \""localizedValue\"":\""Disk Write Bytes\""       }        \""type\"":\""Microsoft.Insights/metrics\""        \""unit\"":\""Bytes\""     }      {       \""data\"":[         {           \""timeStamp\"":\""2017-12-11T08:19:00Z\""            \""total\"":0.0         }       ]        \""id\"":\""/subscriptions/{subscription_ID}/resourceGroups/MWatchLab-dev-db-mcs-473968/providers/Microsoft.Compute/virtualMachines/dev-db-mcs/providers/Microsoft.Insights/metrics/Disk Read Operations/Sec\""        \""name\"":{         \""value\"":\""Disk Read Operations/Sec\""          \""localizedValue\"":\""Disk Read Operations/Sec\""       }        \""type\"":\""Microsoft.Insights/metrics\""        \""unit\"":\""CountPerSecond\""     }      {       \""data\"":[         {           \""timeStamp\"":\""2017-12-11T08:19:00Z\""            \""total\"":10.77         }       ]        \""id\"":\""/subscriptions/{subscription_ID}/resourceGroups/MWatchLab-dev-db-mcs-473968/providers/Microsoft.Compute/virtualMachines/dev-db-mcs/providers/Microsoft.Insights/metrics/Disk Write Operations/Sec\""        \""name\"":{         \""value\"":\""Disk Write Operations/Sec\""          \""localizedValue\"":\""Disk Write Operations/Sec\""       }        \""type\"":\""Microsoft.Insights/metrics\""        \""unit\"":\""CountPerSecond\""     }   ] } </code></pre>""",azure-virtual-machine
56272369,"How to deploy a ASP.NET Web Application + ASP.NET Web API to a single Web App resource on Azure <p>I am trying to automate the deployment process of an old project to use octopus to deploy to azure. The solution has two projects  one classic ASP.NET Web Application and one Web API  these were previously deployed to a single Web App resource. I can package each project separately using octopack but how can I package the two as one and deploy to one  Web App resource on Azure using Octopus?</p>  <p><a href=\https://i.stack.imgur.com/Cy92T.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Cy92T.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
54637913,"Azure DevOps API- How to create a repository? <p>I'm developing a internal app that creates the skeleton of a solution according to internal guidelines.</p>  <p>As a improvement  I would like to enable the user to automatically have the solution \formalized\"" on our DevOps  where he would clone and start coding right away  instead of the current download as ZIP.</p>  <p>In order to do that  i started looking at the azure devops docs  but could not figure out a way to create a repository via API...</p>  <p>How can I do that?</p>""",azure-devops
57185608,"How to create Azure function with C# using HTTP POST and store incoming data into text file in BLOB storage? <p>I am new to Azure function. I am trying to create Azure function in portal with Http trigger which gets the data as JSON and POST it as a text file in BLOB storage. I know I am missing something here in the code:</p>  <blockquote>   <p>function.json</p> </blockquote>  <pre><code>{   \bindings\"": [     {       \""authLevel\"": \""function\""        \""name\"": \""req\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""methods\"": [         \""get\""          \""post\""       ]     }      {       \""name\"": \""$return\""        \""type\"": \""http\""        \""direction\"": \""out\""     }      {       \""type\"": \""blob\""        \""name\"": \""outputBlob\""        \""path\"": \""outcontainer/{rand-guid}\""        \""connection\"": \""AzureWebJobsStorage\""        \""direction\"": \""out\""     }   ] } </code></pre>  <blockquote>   <p>run.csx</p> </blockquote>  <pre><code>#r \""Newtonsoft.Json\"" #r \""Microsoft.WindowsAzure.Storage\"" #r \""Microsoft.Azure.WebJobs.Extensions.Storage\"" using System.Net; using Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.Primitives; using Newtonsoft.Json; using Microsoft.WindowsAzure.Storage.Blob; using Microsoft.Azure.WebJobs.Extensions.Storage;  public static async Task&lt;IActionResult&gt; Run(HttpRequest req  [Blob(\""blobcontainer\""  Connection = \""AzureWebJobsStorage\"")] CloudBlobContainer outputContainer  ILogger log) {     log.LogInformation(\""C# HTTP trigger function processed a request.\"");      await outputContainer.CreateIfNotExistsAsync();      var requestBody = await new StreamReader(req.Body).ReadToEndAsync();     dynamic data = JsonConvert.DeserializeObject(requestBody);     var blobName = Guid.NewGuid().ToString();      var cloudBlockBlob = outputContainer.GetBlockBlobReference(blobName);     await cloudBlockBlob.UploadTextAsync(data);      return new OkObjectResult(blobName); } </code></pre>  <p>It compiles successfully but getting run time error as below:</p>  <blockquote>   <p>No value was provided for parameter 'outputContainer'</p> </blockquote>""",azure-functions
50629150,"VSTS build on clean due to dotnet version <p>My VSTS build has started to fail recently when doing a <code>clean</code> and it looks like it is something to do with the dotnet version that it's running. If I do a <code>dotnet --version</code> I get the following output:</p>  <p>2018-05-31T16:40:51.0191791Z 2.1.300-rc1-008673</p>  <p>Why is the build agent running a RC version of the dotnet? How can I fix this to a released version?</p>  <p>Looking around at the scripts for building the images for the agents I came across this change which is suppose to stop installing preview/rc version - <a href=\https://github.com/Microsoft/vsts-image-generation/commit/e9c0aec89ad797d1985a76ab262349b943b02c34\"" rel=\""nofollow noreferrer\"">https://github.com/Microsoft/vsts-image-generation/commit/e9c0aec89ad797d1985a76ab262349b943b02c34</a> but the agent that is getting built at the moment for me is has rc version?</p>  <p>Here are the error logs from VSTS when we hit out clean stage that runs <code>dotnet clean</code></p>  <pre><code>2018-06-01T10:35:05.2388624Z ======================================== 2018-06-01T10:35:05.2389045Z Clean 2018-06-01T10:35:05.2389205Z ======================================== 2018-06-01T10:35:05.2389542Z Executing task: Clean 2018-06-01T10:35:05.2389744Z Microsoft (R) Build Engine version 15.7.177.53362 for .NET Core 2018-06-01T10:35:05.2389940Z Copyright (C) Microsoft Corporation. All rights reserved. 2018-06-01T10:35:05.2390085Z  2018-06-01T10:35:05.2390243Z Build started 6/1/2018 10:35:04 AM. 2018-06-01T10:35:05.4567633Z      1&gt;Project \""D:\\a\\1\\s\\EvilCorp.Shopping.sln\"" on node 1 (Clean target(s)). 2018-06-01T10:35:05.4576926Z      1&gt;ValidateSolutionConfiguration: 2018-06-01T10:35:05.4577117Z          Building solution configuration \""Debug|Any CPU\"". 2018-06-01T10:35:05.4577301Z        ValidateProjects: 2018-06-01T10:35:05.4577538Z          The project \""EvilCorp.Shopping.CloudFormation\"" is not selected for building in solution configuration \""Debug|Any CPU\"". 2018-06-01T10:35:05.6568982Z      1&gt;Project \""D:\\a\\1\\s\\EvilCorp.Shopping.sln\"" (1) is building \""D:\\a\\1\\s\\test\\EvilCorp.Shopping.BitCoinMining.Tests\\EvilCorp.Shopping.BitCoinMining.Tests.csproj\"" (2) on node 1 (Clean target(s)). 2018-06-01T10:35:05.6570131Z      2&gt;_CheckForNETCoreSdkIsPreview: 2018-06-01T10:35:05.6570885Z          You are working with a preview version of the .NET Core SDK. You can define the SDK version via a global.json file in the current project. More at https://go.microsoft.com/fwlink/?linkid=869452 2018-06-01T10:35:05.6571157Z        CoreClean: 2018-06-01T10:35:05.6571366Z          Creating directory \""obj\\Debug\\netcoreapp2.0\\\"". 2018-06-01T10:35:05.6573173Z      2&gt;C:\\Program Files\\dotnet\\sdk\\2.1.300-rc1-008673\\Sdks\\Microsoft.NET.Sdk\\targets\\Microsoft.PackageDependencyResolution.targets(197 5): error : Assets file 'D:\\a\\1\\s\\test\\EvilCorp.Shopping.BitCoinMining.Tests\\obj\\project.assets.json' not found. Run a NuGet package restore to generate this file. [D:\\a\\1\\s\\test\\EvilCorp.Shopping.BitCoinMining.Tests\\EvilCorp.Shopping.BitCoinMining.Tests.csproj] 2018-06-01T10:35:05.6574793Z      2&gt;Done Building Project \""D:\\a\\1\\s\\test\\EvilCorp.Shopping.BitCoinMining.Tests\\EvilCorp.Shopping.BitCoinMining.Tests.csproj\"" (Clean target(s)) -- FAILED. 2018-06-01T10:35:06.3974865Z      1&gt;Project \""D:\\a\\1\\s\\EvilCorp.Shopping.sln\"" (1) is building \""D:\\a\\1\\s\\src\\EvilCorp.Shopping.BitCoinMining\\EvilCorp.Shopping.BitCoinMining.csproj\"" (3) on node 2 (Clean target(s)). 2018-06-01T10:35:06.3976276Z      3&gt;_CheckForNETCoreSdkIsPreview: 2018-06-01T10:35:06.3976868Z          You are working with a preview version of the .NET Core SDK. You can define the SDK version via a global.json file in the current project. More at https://go.microsoft.com/fwlink/?linkid=869452 2018-06-01T10:35:06.4013004Z        CoreClean: 2018-06-01T10:35:06.4013409Z          Creating directory \""obj\\Debug\\netcoreapp2.0\\\"". 2018-06-01T10:35:06.4033872Z      3&gt;C:\\Program Files\\dotnet\\sdk\\2.1.300-rc1-008673\\Sdks\\Microsoft.NET.Sdk\\targets\\Microsoft.PackageDependencyResolution.targets(197 5): error : Assets file 'D:\\a\\1\\s\\src\\EvilCorp.Shopping.BitCoinMining\\obj\\project.assets.json' not found. Run a NuGet package restore to generate this file. [D:\\a\\1\\s\\src\\EvilCorp.Shopping.BitCoinMining\\EvilCorp.Shopping.BitCoinMining.csproj] 2018-06-01T10:35:06.4039865Z      3&gt;Done Building Project \""D:\\a\\1\\s\\src\\EvilCorp.Shopping.BitCoinMining\\EvilCorp.Shopping.BitCoinMining.csproj\"" (Clean target(s)) -- FAILED. 2018-06-01T10:35:06.4237898Z      1&gt;Done Building Project \""D:\\a\\1\\s\\EvilCorp.Shopping.sln\"" (Clean target(s)) -- FAILED. 2018-06-01T10:35:06.4315334Z  2018-06-01T10:35:06.4317290Z Build FAILED. 2018-06-01T10:35:06.4320946Z  2018-06-01T10:35:06.4322792Z        \""D:\\a\\1\\s\\EvilCorp.Shopping.sln\"" (Clean target) (1) -&gt; 2018-06-01T10:35:06.4324451Z        \""D:\\a\\1\\s\\test\\EvilCorp.Shopping.BitCoinMining.Tests\\EvilCorp.Shopping.BitCoinMining.Tests.csproj\"" (Clean target) (2) -&gt; 2018-06-01T10:35:06.4324845Z        (ResolvePackageAssets target) -&gt;  2018-06-01T10:35:06.4325763Z          C:\\Program Files\\dotnet\\sdk\\2.1.300-rc1-008673\\Sdks\\Microsoft.NET.Sdk\\targets\\Microsoft.PackageDependencyResolution.targets(197 5): error : Assets file 'D:\\a\\1\\s\\test\\EvilCorp.Shopping.BitCoinMining.Tests\\obj\\project.assets.json' not found. Run a NuGet package restore to generate this file. [D:\\a\\1\\s\\test\\EvilCorp.Shopping.BitCoinMining.Tests\\EvilCorp.Shopping.BitCoinMining.Tests.csproj] 2018-06-01T10:35:06.4326110Z  2018-06-01T10:35:06.4326235Z  2018-06-01T10:35:06.4326444Z        \""D:\\a\\1\\s\\EvilCorp.Shopping.sln\"" (Clean target) (1) -&gt; 2018-06-01T10:35:06.4326731Z        \""D:\\a\\1\\s\\src\\EvilCorp.Shopping.BitCoinMining\\EvilCorp.Shopping.BitCoinMining.csproj\"" (Clean target) (3) -&gt; 2018-06-01T10:35:06.4327177Z          C:\\Program Files\\dotnet\\sdk\\2.1.300-rc1-008673\\Sdks\\Microsoft.NET.Sdk\\targets\\Microsoft.PackageDependencyResolution.targets(197 5): error : Assets file 'D:\\a\\1\\s\\src\\EvilCorp.Shopping.BitCoinMining\\obj\\project.assets.json' not found. Run a NuGet package restore to generate this file. [D:\\a\\1\\s\\src\\EvilCorp.Shopping.BitCoinMining\\EvilCorp.Shopping.BitCoinMining.csproj] 2018-06-01T10:35:06.4327515Z  2018-06-01T10:35:06.4327682Z     0 Warning(s) 2018-06-01T10:35:06.4327863Z     2 Error(s) 2018-06-01T10:35:06.4327987Z  2018-06-01T10:35:06.4328151Z Time Elapsed 00:00:01.51 </code></pre>""",azure-devops
46531036,"nuget package restore fails for webapp with custom nuget.config <p>I am attempting to fix a problem I have with restoring nuget packages for a .net core 2.0 webapi that has a custom package source. </p>  <p>Basically when including the nuget.config any microsoft packages fail to install because it seems to ignore my nuget reference. </p>  <p>I have found a workaround  that is to remove my custom nuget.config  let the build fail  once it fails it will have downloaded the proper things from nuget.org and then by adding the custom file back in  it will restore those microsoft packages from disk and then reachout to get my custom nuget package.</p>  <p>My nuget Package config looks like this: </p>  <pre><code>    &lt;?xml version=\1.0\"" encoding=\""utf-8\""?&gt; &lt;configuration&gt;   &lt;packageSources&gt;     &lt;add key=\""nuget.org\"" value=\""https://api.nuget.org/v3/index.json\"" protocolVersion=\""3\"" /&gt;     &lt;add key=\""ASPNET Team\"" value=\""https://dotnet.myget.org/F/aspnetcore-ci-dev/api/v3/index.json\"" /&gt;     &lt;add key=\""OTL\"" value=\""https://www.myget.org/F/{redacted}/api/v3/index.json\"" /&gt;   &lt;/packageSources&gt;   &lt;packageRestore&gt;     &lt;add key=\""enabled\"" value=\""True\"" /&gt;     &lt;add key=\""automatic\"" value=\""True\"" /&gt;   &lt;/packageRestore&gt;   &lt;bindingRedirects&gt;     &lt;add key=\""skip\"" value=\""False\"" /&gt;   &lt;/bindingRedirects&gt;   &lt;packageManagement&gt;     &lt;add key=\""format\"" value=\""0\"" /&gt;     &lt;add key=\""disabled\"" value=\""False\"" /&gt;   &lt;/packageManagement&gt;   &lt;disabledPackageSources /&gt; &lt;/configuration&gt; </code></pre>  <p>The Errors from Kudu are:</p>  <pre><code>An error occurred while sending the request.     A connection with the server could not be established   Retrying 'FindPackagesByIdAsync' for source 'https://www.myget.org/F/{redacted}/api/v3/flatcontainer/microsoft.extensions.caching.sqlserver/index.json'.   An error occurred while sending the request.     A connection with the server could not be established   Retrying 'FindPackagesByIdAsync' for source 'https://dotnetmyget.blob.core.windows.net/artifacts/aspnetcore-ci-dev/nuget/v3/flatcontainer/microsoft.extensions.hosting.abstractions/index.json'.   An error occurred while sending the request.     A connection with the server could not be established   Retrying 'FindPackagesByIdAsync' for source 'https://dotnetmyget.blob.core.windows.net/artifacts/aspnetcore-ci-dev/nuget/v3/flatcontainer/microsoft.extensions.caching.sqlserver/index.json'.   An error occurred while sending the request.     A connection with the server could not be established   Retrying 'FindPackagesByIdAsync' for source 'https://dotnetmyget.blob.core.windows.net/artifacts/aspnetcore-ci-dev/nuget/v3/flatcontainer/microsoft.entityframeworkcore.tools/index.json'.   An error occurred while sending the request.     A connection with the server could not be established   Retrying 'FindPackagesByIdAsync' for source 'https://www.myget.org/F/{redacted}/api/v3/flatcontainer/microsoft.extensions.dependencyinjection.abstractions/index.json'.   An error occurred while sending the request.     A connection with the server could not be established   Retrying 'FindPackagesByIdAsync' for source 'https://dotnetmyget.blob.core.windows.net/artifacts/aspnetcore-ci-dev/nuget/v3/flatcontainer/microsoft.extensions.dependencyinjection.abstractions/index.json'.   An error occurred while sending the request.     A connection with the server could not be established   Retrying 'FindPackagesByIdAsync' for source 'https://www.myget.org/F/{redacted}/api/v3/flatcontainer/microsoft.extensions.caching.sqlserver/index.json'. </code></pre>  <p>Doing a dotnet restore directly from Kudu console yields the same results. I have pulled the NuGet.config from my development machine which i know successfully restores both microsoft packages and custom packages and attempted to use that and it still failed.</p>  <p>I'm beginning to think its an outbound port blocking firewall thing within azure but some googling of outbound firewall or proxy on webapp was not fruitful. </p>""",azure-web-app-service
52729006,"Azure Functions Mac - Wrong Host Version <p>I am trying to debug an Azure functions project on my Mac using Visual Studio Mac.</p>  <p>I have updated my core tools to version 2.0.3. If I type <code>func</code> at my terminal  I can see I updated to the latest version.</p>  <pre><code>                  %%%%%%                  %%%%%%             @   %%%%%%    @           @@   %%%%%%      @@        @@@    %%%%%%%%%%%    @@@      @@      %%%%%%%%%%        @@        @@         %%%%       @@          @@      %%%       @@            @@    %%      @@                 %%                 %  Azure Functions Core Tools (2.0.3) Function Runtime Version: 2.0.12115.0 </code></pre>  <p>You can also see the runtime version is <code>2.0.12115.0</code>.</p>  <p>However when I debug using Visual Studio Mac  I get a runtime error:</p>  <blockquote>   <p>Hosting environment: Production Now listening on: <a href=\http://0.0.0.0:7071\"" rel=\""nofollow noreferrer\"">http://0.0.0.0:7071</a>   Application started. Press Ctrl+C to shut down. [09/10/2018 20:30:53]   Reading host configuration file   'xxxxx/bin/Debug/netstandard2.0/host.json' [09/10/2018 20:30:53] Host   configuration file read: [09/10/2018 20:30:53] {} [09/10/2018   20:30:53] Starting Host (HostId=xxxxx    InstanceId=0ef8b0eb-215d-4d08-9945-6dd50c8094c7  Version=2.0.11933.0    ProcessId=22941  AppDomainId=1  Debug=False  ConsecutiveErrors=0    StartupCount=1  FunctionsExtensionVersion=) Function host is not   running. Press any to continue....[09/10/2018 20:30:58] A ScriptHost   error has occurred [09/10/2018 20:30:58] System.Private.CoreLib: Could   not load type 'Microsoft.Azure.WebJobs.Hosting.IWebJobsStartup' from   assembly 'Microsoft.Azure.WebJobs.Host  Version=3.0.0.0    Culture=neutral  PublicKeyToken=null'.</p> </blockquote>  <p>Notice the runtime version is <code>Version=2.0.11933.0</code>.</p>  <p>There must be a way to tell visual studio where the location of the Azure-Functions-Core tools is installed or can I at least copy my 2.0.3 installation to where Visual Studio is executing from  where ever that is.</p>""",azure-functions
55670691,"Azure QueueTrigger - binding both a POCO AND a CloudQueueMessage? <p>We use  the Singleton attribute with a scope expression against a POCO. For example:</p>  <pre><code>[Singleton(\{SomeValue}\"")] public static void SomeMethod([QueueTrigger(\""somequeue\"")] SomePOCO poco) </code></pre>  <p>This works fine. We now however need to be able to change the queue message's visibility timeout  and thus need access to the CloudQueueMessage itself since CloudQueue UpdateMessage() requires the CloudQueueMessage. However after much reading of documentation (and trial and error) it seems that both a POCO AND a CloudQueueMessage cannot be bound in the method signature - or at least I cannot figure out how to do it.</p>  <p>I have gone through documentation on creating your own custom bindings  but:</p>  <ol> <li>Its not clear that I can get the CloudQueueMessage this way since there seems to be some internal implementation interfaces in the WebJobs SDK to instantiate the CloudQueueMessage  and</li> <li>It seems a lot of work to do something I would of expected to be a somewhat common use case.</li> </ol>  <p>What am I missing in this scenario - that is  is there a simple way of declaring both a POCO and CloudQueueMessage binding  or do I have to create a custom binding to get the CloudQueueMessage (and are there any hints to do this)?</p>  <p>Cheers</p>""",azure-storage
33890149,"OpsHub VSO Migration Utility Error - could not initialize a collection <p>When I try to see migration progress in the utility I now get an error.  It is showing this for all migrations I have set running.  I have tried rebooting the machine but same error  as below.  Thanks in advance for any help. </p>  <p><a href=\http://i.stack.imgur.com/Qx1Ji.png\"" rel=\""nofollow\"">See this link to a screenshot of error: could not initialize a collection: [com.opshub.dao.eai.EAIIntegrationsContext#1]</a></p>""",azure-devops
48714233,"Azure Account-Level SAS Token: Possible to Have a Policy? <p>I found how to create an Azure account-level SAS token with PowerShell. <a href=\https://docs.microsoft.com/en-us/powershell/module/azure.storage/new-azurestorageaccountsastoken?view=azurermps-5.2.0\"" rel=\""nofollow noreferrer\"">Link</a> However  the cmdlet <code>New-AzureStorageAccountSASToken</code> does not appear to accept a <code>-Policy</code> parameter.</p>  <p>Does this mean that there cannot be a SAS policy on an account-level SAS token? An implication would be that if the token were compromised  one could not just remove the policy but would have to change the key.</p>""",azure-storage
4171881,"Why does Html.DisplayFor and .ToString(\C2\"") not respect CurrentUICulture? <p>In my ASP.MVC 2.0 website I have the following setting in web.config:</p>  <pre><code>&lt;globalization uiCulture=\""da-DK\"" culture=\""en-US\"" /&gt; </code></pre>  <p>When I try to display an amount in a view using Html.DisplayFor() or ToString(\""C2\"") I expected to get \""kr. 3.500 00\"" (uiCulture) and not \""$3 500.00\"" (culture). </p>  <pre><code>&lt;%:Html.DisplayFor(posting =&gt; posting.Amount)%&gt; &lt;%:Model.Amount.ToString(\""C2\"")%&gt; </code></pre>  <p>If I explicit uses CurrentUICulture info it works as expected  but I don't want to do that everytime I need to display a number  date or decimal. And I also like to use DisplayFor  which doesn't support the IFormatProvider parameter.</p>  <pre><code>&lt;%:Model.Amount.ToString(\""C2\""  System.Globalization.CultureInfo.CurrentUICulture)%&gt; </code></pre>  <p>How can I change the formatting  without changing the culture of the system?</p>  <p>This is running in Azure  and if I change the culture to \""da-DK\"" all decimal points are lost  when saving to Azure Table storage! #BUG</p>""",azure-storage
56825285,"Where do I find my logs in azure app services? <p>I have enabled logging in my web app running on azure web services  I can see the log output if I enable log streaming but I cannot find any GUI where I can find the logs so where are they?</p>  <p>I have defined my logging as follows in program.cs</p>  <pre><code>WebHost.CreateDefaultBuilder(args)                 .UseApplicationInsights()                 .ConfigureLogging((hostingContext  logging) =&gt;                 {                 logging.AddConfiguration(hostingContext.Configuration.GetSection(\Logging\""));                 logging.AddConsole();                 logging.AddDebug();                 logging.AddEventSourceLogger();                 logging.AddApplicationInsights();                 })                 .UseStartup&lt;Startup&gt;(); </code></pre>  <p>And in my API controller I am simply doing this</p>  <pre><code> private readonly ILogger _logger;         public ReveController(ILogger&lt;Controller&gt; logger)         {             _logger = logger;         } </code></pre>  <p>Followed by</p>  <pre><code>_logger.LogInformation(\""Test test test\""); </code></pre>  <p>My logging settings in appsettings.json looks as follows</p>  <pre><code>\""Logging\"": {     \""LogLevel\"": {       \""Default\"": \""Warning\""     }   }  </code></pre>  <p>I looked on the app service and in App Insights but nowhere in the GUI can I find the entries where are they?</p>  <p>Am I missing something?</p>""",azure-web-app-service
57280331,"How does Nuget Restore task work? Does nuget.config in the solution have to match that of in the build server? <p><a href=\https://i.stack.imgur.com/igSX1.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/igSX1.jpg\"" alt=\""enter image description here\""></a>I am new to Nuget and have added a Nuget restore step to install dependencies on the build server. When I looked up the Nuget restore  we need the Nuget.config file under the solution folder as well as in the local build machine where the build will be running. %Appdata%/Nuget/Nuget.config</p>  <p>My question is do the two nuget.config files need to match? Does the nuget.config file in the source repository replace the nuget.config in the build server during the build?</p>""",azure-devops
51830440,"Reset root account password of a CentOS 6.9 vm on azure? <p>I have a CentOS 6.9 vm on azure  it was created from a vhd disk that was uploaded. The root account has been blocked because of failed login attemps. So i wonder if there is a way to reset the root account password?</p>  <p>I've tried the steps of this post: <a href=\https://serverfault.com/questions/680460/how-to-reset-root-password-on-a-linux-vm-on-windows-azure?newreg=5d2142cb59ba400a9def39ad7245fc74\"">https://serverfault.com/questions/680460/how-to-reset-root-password-on-a-linux-vm-on-windows-azure?newreg=5d2142cb59ba400a9def39ad7245fc74</a></p>  <p>But the Azure Cli stucks at  Installing extension \""VMAccessForLinux\""  VM: \""API-GW\""</p>  <p>Any ideas on how to solve this?</p>""",azure-virtual-machine
46166865,Getting error when trying to call API inside Web App through another Web App - Azure <p>I have two Web Apps  inside the same App Service. One is a back-end portion (with API on it  using .NET Core  SSL cert installed) and the other one is the front-end (ReactTS  created using <code>create-react-app</code>).</p>  <p>When I try to call the API method (an Auth method) using my Front-end I got this message as response:</p>  <blockquote>   <p>Login failed: The resource you are looking for has been removed  had   its name changed  or is temporarily unavailable.</p>      <p>-404 error</p> </blockquote>  <p>Another fact is  if I run my ront-end solution locally  I can use the API (published on the Web App)  normally.</p>  <p>My API URL is set inside the <code>package.json</code> file  as <code>proxy</code>.</p>  <p>My first thought was about an <code>CORS</code> problem  but it throws a 404 error.</p>  <p>Any configuration that I can do on my Azure  or something that I need to change in my application to allow my front-end to communicate with my API?</p>,azure-web-app-service
44259047,"How to remove App Service Certificate resource <p>So I have SSL certificate bought directly using Azure portal.</p>  <p>Now I migrated from Azure and want to delete every resource from Azure except my SQL Server and database.</p>  <p>When I try to delete App Service Certificate I have this error:</p>  <blockquote>   <p>Operation name       Delete the App Service Certificate       Time stamp       Tue May 30 2017 11:47:36 GMT+0200 (W. Europe Standard Time)       Event initiated by       -       Description       Failed to delete the App Service Certificate. : Delete for 'JerrySwitalski' App Service Certificate failed because there are   still imported certificates derived from the App Service Certificate   in the source subscription. Imported certificates:   /subscriptions/77cf2897-8c03-413c-8e16-38ea0e025d72/resourceGroups/01/providers/Microsoft.Web/certificates/JerrySwitalski-01-SouthCentralUSwebspace /subscriptions/77cf2897-8c03-413c-8e16-38ea0e025d72/resourceGroups/01/providers/Microsoft.Web/certificates/JerrySwitalski-01-WestEuropewebspace</p> </blockquote>  <p>As you can see below  I have only SQL Server and database and this certificate: <a href=\https://i.stack.imgur.com/av9Xc.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/av9Xc.png\"" alt=\""enter image description here\""></a></p>  <p><strong>How can I remove for good this certificate?</strong></p>""",azure-web-app-service
50789319,Does Azure App Services come with a default WAF? <p>I understand that one can develop an App Service Environment  and put a WAF within it to protect an AppService.</p>  <p>What I'd like to know is:</p>  <ul> <li>whether there is a default WAF provided by Microsoft -- even if rudimentary -- in front of App Services that are not within an ASE.</li> <li>if there wasn't one  or one wanted to put another one  can one actually put a WAF in front of a non-ASE AS (doesn't the AppService have a public IP that would always be available?)</li> </ul>  <p>Thank you!</p>  <p>PS: Any link to documentation that than can be referenced either way would be greatly appreciated.</p>,azure-web-app-service
24691018,How to access Azure storage queue by JavaScript <p>For our testing purpose  we would like to access Azure storage queue directly with JavaScript instead of preparing a new web service.</p>  <p>Is this possible? What should we do to achieve this  since I cannot find the official documentation for JavaScript API of Azure storage.</p>,azure-storage
11767055,How can I shake relational database thinking for designing an azure table storage datastore? <p>I have been trying to get a good grasp of Azure Table storage for a little while now  and while I understand generally how it works I am really struggling to shake my relational database thinking. I usually learn best by example  so I'm wondering if someone can help me out. I'm going to outline a simple setup for how I would solve a problem using a relational database  can someone help guide me to converting it to use Azure Table storage?</p>  <p>Lets say that I have simple note taking app  it has users and each user can have as many notes as they want  and each note can have as many users (owners or viewers) as it needs. If I were going to deploy this using a relational database I would likely deploy it as follows:</p>  <p>For the database  I'd start with something like this:</p>  <pre><code>CREATE TABLE [dbo].[Users](     [ID] [int] IDENTITY(1 1) NOT NULL      [Username] [nvarchar](20) NOT NULL)  CREATE TABLE [dbo].[UsersNotes](     [ID] [int] IDENTITY(1 1) NOT NULL      [UserID] [int] NOT NULL      [NoteID] [int] NOT NULL)  CREATE TABLE [dbo].[Notes](     [ID] [int] IDENTITY(1 1) NOT NULL      [NoteData] [nvarchar](max) NULL)         </code></pre>  <p>I would then setup a relationship between <code>Users.ID and UsersNotes.UserID</code> as well as <code>Notes.ID and UsersNotes.NoteID</code> with constraints to enforce referential integrity.</p>  <p>For the application  I would have an ORM generate some entities with matching name properties for each of these  and I'd probably call it a day:</p>  <pre><code>public class Users {     public int ID { get; set; }     public String Username { get; set; } } // and so on and so forth </code></pre>  <p>I realize that this design is fully dependent on the relational database  and what I'm looking for is some advise on how to shake this train of thought to use Azure Table storage  or any other non-relational data storage techniques. </p>  <p>Lets also assume for the sake of argument that I've installed the Azure SDK  and have played around with it  but my working knowledge of using the SDK is limited  I'd rather not focus on that  but rather what a good solution to the above would look like. A good starting point will help make the SDK make sense to me  since I'll have a point of reference.</p>  <p>For the sake of completeness  lets say that</p>  <ul> <li>Note data will change frequently when first created  and taper off over time</li> <li>Users will have many notes  and notes may have multiple users (not concurrent  just viewers)</li> <li>I expect fairly few users (low hundreds)  but I expect a fair number of notes (low hundreds  per user)</li> <li>I expect to query against <code>Username</code> the most  and then show the notes the user has access to</li> <li>I also expect when viewing a Note  to show the other users with access to that note  a reverse lookup</li> </ul>,azure-storage
56393355,Unable to build solution in VSTS pipeline <p>I am working on a service fabric solution and I am able to build and test the changes in my local machine whereas in VSTS pipeline and facing a minor issue saying that the interface method is not implemented.</p>  <p>If anyone of you face a similar issue  Can you guys suggest or help me out on how to fix or resolve this issue in the build pipeline.</p>  <p>Here is my scenario.</p>  <p><strong>Interface</strong></p>  <pre><code>public interface IStudent {     void PrintFullName(); } </code></pre>  <p><strong>Base Class</strong></p>  <pre><code>public class BaseStudent {     public void PrintFullName()     {         // Implementation     } } </code></pre>  <p><strong>MainClass</strong></p>  <pre><code>public class Student : BaseStudent  IStudent {     public void PrintName()     {         // Implementation     } } </code></pre>,azure-devops
49369681,Limit the number of messages processed by a queue triggered frunction <p>I have a queue triggered function that POSTs to a server. I want to limit the number of posts made to the server to 1 post/ every 3 seconds. Is there a way to do this? If so  how?</p>,azure-functions
52099198,"How to prevent a development staging website  hosted on Azure  from being indexed by search engines <p>Specific to Web Apps hosted on <code>Microsoft Azure</code>  is there a way to prevent the <code>mydomain.azurewebsites.net</code> URL from being indexed by search engines? I'm planning to use a web app as a staging website  and don't want it to accidentally get indexed. </p>  <p>I know I could add a <code>robots.txt</code> file to the project with everything set to <code>no-index</code>  but I don't want to ever accidentally publish it to the production site (or alternatively  forget to publish it to the staging website). </p>  <p>Is there a setting in Azure that will prevent the \.azurewebsites.net\"" domain from being indexed? Or if the <code>robots.txt</code> file is the only way  how do you keep it organized so that the right <code>robots.txt</code> file is published to staging and production  using <code>ASP.NET Core</code>.</p>""",azure-web-app-service
45330982,"Failed comunication between Logstash and RabbitMQ (both in one separate MS Azure Virtual machine) <p>I have created two service in Azure \<strong>RabbitMQ</strong>\"" and \""<strong>ELK</strong>\"" (both in one separate <em>MS Azure Virtual machine</em>).</p>  <p>My MVC ASP.net application write in RabbitMQ (I have to configure an endpoint (inbound security rule) RabbitMQ (TCP/5672) and I can see in RabbitMQ webadmin my queue.  Logstash (in vm ELK) write correct index for \""logstash-*\"" collect data from apache log.</p>  <p>I think I missing some endpoint configuration in vm. But I don't know what. Or I have put some incorrect configuration my logstash config /opt/bitnami/logstash/conf/logstash.conf :</p>  <hr>  <pre><code>input { rabbitmq { type =&gt; \""myqueuelog\"" host =&gt; \""x.x.x.x\"" # ip address to vm rabbitmq port =&gt; 5672 vhost =&gt; \""myvhost\"" queue =&gt; \""myqueuelog\"" auto_delete =&gt; false codec =&gt; \""plain\"" exclusive =&gt; false heartbeat =&gt; 30 durable =&gt; true password =&gt; \""mypass\"" user =&gt; \""user\"" } rabbitmq { type =&gt; \""myqueueerror\"" host =&gt; \""x.x.x.x\"" # ip address to vm rabbitmq port =&gt; 5672 vhost =&gt; \""myvhost\"" queue =&gt; \""myqueueerror\"" auto_delete =&gt; false codec =&gt; \""plain\"" exclusive =&gt; false heartbeat =&gt; 30 durable =&gt; true password =&gt; \""mypass\"" user =&gt; \""user\"" } beats { ssl =&gt; false host =&gt; \""0.0.0.0\"" port =&gt; 5044 } gelf { host =&gt; \""0.0.0.0\"" port =&gt; 12201 } http { ssl =&gt; false host =&gt; \""0.0.0.0\"" port =&gt; 8888 } tcp { mode =&gt; \""server\"" host =&gt; \""0.0.0.0\""      mode =&gt; \""server\""     host =&gt; \""0.0.0.0\""     port =&gt; 5010 } udp {     host =&gt; \""0.0.0.0\""     port =&gt; 5000 } }  filter { if [type] == \""myqueuelog\"" { # split the message field (in json format) json { source =&gt; \""message\"" # where is the json } } if [type] == \""myqueueerror\"" { # split the message field (in json format) json { source =&gt; \""message\"" # where is the json } } }  output {  if [type] == \""myqueuelog\"" {         elasticsearch         {             codec =&gt; \""json\""             hosts =&gt; [\""127.0.0.1:9200\""]             document_id =&gt; \""%{logstash_checksum}\""             index =&gt; \""myqueuelog-%{+YYYY}\""            # protocol =&gt; \""http\""             manage_template =&gt; false         }     } if [type] == \""myqueueerror\"" { elasticsearch { codec =&gt; \""json\"" hosts =&gt; [\""127.0.0.1:9200\""] document_id =&gt; \""%{logstash_checksum}\"" index =&gt; \""myqueueerror-%{+YYYY}\"" # protocol =&gt; \""http\"" manage_template =&gt; false } }  } </code></pre>  <hr>  <p>and I have found a log error in LOGSTASH:</p>  <pre><code>[ERROR][logstash.pipeline] Error registering plugin {:plugin=&gt;\""false  host=&gt;\\\""0.0.0.0\\\""  port=&gt;8888  id=&gt;\\\""ccfb769a49le707254a6d272716b8aa18d57dfec-18\\\""  enable_metric=&gt;true  codec=&gt;\\\""plain_0045le0e-9c30-4d95-b400-97843e19022e\\\""  enable_metric=&gt;true  charset=&gt;\\\""UTF-8\\\""&gt;  threads=&gt;4  verify_mode=&gt;\\\""none\\\""  additional_codecs=&gt;{\\\""application/json\\\""=&gt;\\\""json\""}  response_headers=&gt;{\\\""Content-Type\\\""text/plain\\\""}&gt;  :error=&gt;\""Address already in use - bind - Address already in use\""} [ERROR][logstash.agent] Pipeline aborted due to error {:exception=&gt;#  :backtrace=&gt;[\""org/jruby/ext/socket/RubyTCPServer.java:118:in 'initialize'\""  \""org/jruby/RubyIO.java:871 ...etc... </code></pre>  <p>Thanks in advance</p>""",azure-virtual-machine
48012689,Azure App Service Plan CPU spikes for no obvious reason <p>We're experiencing CPU spikes on our Azure App Service Plan for no obvious reason. Its not something that stops the service  but we'd like to have an understanding of when&amp;how that kind of things happen.</p>  <p>For example  CPU percentage sits at 0-1% range for days but then all of the sudden it spikes to 98%  45%  60% and comes back to 0-1% range very quickly. Memory stays unchanged at comfortable 40-45% level  no incoming requests to it  no web jobs  nothing unusual in logs  no failures  service health ok  nothing we could point our finger to as a reason. We tried to find out through kudu > support > analyze (metrics)...but we couldn't get request submited. It just keeps giving error to try later.</p>  <p>There is only one web app running in that app service plan  its a asp.net core 2.0. web api.</p>  <p>Could someone shed some light on this kind of behavior? Is this normal  expected? If so  why it happens? Is there a danger that it spikes to 90% and don't immediately come back?</p>  <p>Just  what's going on?</p>,azure-web-app-service
21256636,"How do I add a blob to Windows Azure? <p>I created a storage account on Windows Azure. Then I added a container called <code>rubicon</code> to my storage account and got to the following screen: </p>  <p><img src=\https://i.stack.imgur.com/yN2x3.jpg\"" alt=\""enter image description here\""></p>  <p>I don't see any button/link that allows me to add a blob. Would be nice to see a \""<em>Click here to add blob</em>\"" link on this page  but there is nothing. I did have a look on <a href=\""http://www.windowsazure.com/en-us/documentation/articles/storage-dotnet-how-to-use-blobs-20/\"" rel=\""nofollow noreferrer\"">How to use blob storage</a>  but that only shows how do do it though code. </p>  <p>Where do I add a blob on the Windows Azure portal?</p>""",azure-storage
48903289,"web API in Azure: Authorization has been denied for this request <p>I have a SQL Azure database up and running. The connection string I'm using for one web api application.</p>  <p>When I'm running the application through Visual Studio using SQL Azure connection string  I'm not getting any Authorization denied response.</p>  <p>Now I deployed my web api application to Azure and when I'm trying to access any API controller  it's saying <code>Authorization has been denied for this request.</code></p>  <p>I also checked Authentication / Authorization settings for my App Service and it's.... Anonymous access is enabled on the App Service app. Users will not be prompted for login.</p>  <p><a href=\https://i.stack.imgur.com/Zk0gn.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Zk0gn.png\"" alt=\""enter image description here\""></a></p>  <p>Why I'm getting  Authorization denied response. Is there any settings I'm missing?</p>""",azure-web-app-service
19530753,How to get system time using windows azure powershell <p>How to find system time using windows azure powershell? I want time only and it should be in 24 hour format. I have tried get-date and [system.datetime]::now I want only time. I don't want date.</p>,azure-storage
32297378,"How can I parameterise Azure's TableOperation.Retrieve<TElement> in a method in c# .NET <p>I have a class  something like the following:</p>  <pre><code>public class Table : ITable     {         private CloudStorageAccount storageAccount;         public Table()         {             var storageAccountSettings = ConfigurationManager.ConnectionStrings[\AzureStorageConnection\""].ToString();             storageAccount = CloudStorageAccount.Parse(storageAccountSettings);         }         public async Task&lt;TableResult&gt; Retrieve(string tableReference  string partitionKey  string rowKey)         {             var tableClient = storageAccount.CreateCloudTableClient();             var table = tableClient.GetTableReference(tableReference);             TableOperation retrieveOperation = TableOperation.Retrieve&lt;SomeDomainModelType&gt;(partitionKey  rowKey);             TableResult retrievedResult = await table.ExecuteAsync(retrieveOperation);             return retrievedResult;         }     } </code></pre>  <p>This class is a wrapper to retrieve a single entity from an Azure table. It's wrapped up and conforms to an interface so that it can be stubbed out with Microsoft Fakes during testing. It works at the moment  however it would be more elegant if the following was more generic:</p>  <pre><code>TableOperation retrieveOperation = TableOperation.Retrieve&lt;SomeDomainModelType&gt;(partitionKey  rowKey); </code></pre>  <p>My question is how can I parameterise <code>&lt;SomeDomainModelType&gt;</code> so that I can use the method with any type in the domain model ? Any ideas?</p>""",azure-storage
49107284,"Cannot create a VSTS webhook subscription for punlisherId = tfs and eventId tfvc.checkin via the REST API <p>I am trying to create a VSTS webhook subscription for publisherId= tfs and eventType= tfvc.checkin. Here's the sample Post request :</p>  <p>Url : <a href=\https://testvstsaccount.visualstudio.com/_apis/hooks/subscriptions?api-version=1.0\"" rel=\""nofollow noreferrer\"">https://testvstsaccount.visualstudio.com/_apis/hooks/subscriptions?api-version=1.0</a></p>  <p>Request Body :</p>  <pre><code>{   \""publisherId\"": \""tfs\""    \""eventType\"": \""tfvc.checkin\""    \""resourceVersion\"": \""1.0-preview.1\""    \""consumerId\"": \""webHooks\""    \""consumerActionId\"": \""httpRequest\""    \""publisherInputs\"": {     \""path\"": \""$/\""   }    \""consumerInputs\"": {     \""url\"": \""https://myservice/myhookeventreceiver\""   } } </code></pre>  <p>I am getting 400 Bad Request in response.</p>  <p>Response body :</p>  <pre><code>{   \""$id\"": \""1\""    \""innerException\"": null    \""message\"": \""Subscription input 'path' is not supported at scope 'collection'.\""    \""typeName\"": \""Microsoft.VisualStudio.Services.ServiceHooks.WebApi.SubscriptionInputException  Microsoft.VisualStudio.Services.ServiceHooks.WebApi  Version=14.0.0.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a\""    \""typeKey\"": \""SubscriptionInputException\""    \""errorCode\"": 0    \""eventId\"": 4501 } </code></pre>  <p>Can someone please help me understand the correct way to create this webhook.</p>""",azure-devops
53458687,"Get instanceID in Http triggered orchestration Starter function in NodeJS <p><a href=\https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-instance-management\"" rel=\""nofollow noreferrer\"">InstanceId: (Optional) The unique ID of the instance. If not specified  a random instance ID will be generated.</a></p>  <p>is there a way to get the random generated instance ID in Http triggered orchestration Starter function in nodeJs language?</p>""",azure-functions
49931526,Need to setup port forwarding to port 5552 on azure VM <p>I am doing penetration testing with a RAT (Remote Access Tool) program and it requires a listening  port to be open for its use (no preference  but i'm using port 5552). I was looking for that function on the Microsoft Azure Portal but I couldn't find anything. </p>  <p>Basically  I want to keep open my RDP port (3389) and at the same time forward incoming requests for port 5552 to the VM (I don't know if this makes sense to anyone but...). </p>  <p>Thanks in advance!</p>,azure-virtual-machine
43346822,"Using azure function output parameters with Dropbox connector <p>My flow is very simple: I want to have an azure function that runs once a day and they use its output to create a file in Dropbox.</p>  <p>The function does some processing and returns an object with 2 properties  a FileName and a FileContent  both are strings.: </p>  <pre><code>return new AzureFunctionResponse {     FileName = $\TestFile-{DateTimeOffset.UtcNow.ToUnixTimeMilliseconds()}\""      FileContent = \""This is the file content\"" }; </code></pre>  <p>My problem is that I don't know how to use those 2 properties to setup my Dropbox connector</p>  <p>Here's my LogicApp flow:</p>  <p><a href=\""https://i.stack.imgur.com/4qAvC.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/4qAvC.png\"" alt=\""enter image description here\""></a></p>  <p><strong>I'd like to use the FileName and FileContent returned from my AzureFunction to populate the respective field in the Dropbox connector</strong> but I have no idea how to set this up. I've looked for documentation  but maybe I'm not looking at the right place because I'm not finding anything.</p>  <p>Also here are the bindings in my function.json file  if that can be of any help.</p>  <pre><code>{   \""disabled\"": false    \""bindings\"": [   {       \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""webHookType\"": \""genericJson\""        \""name\"": \""req\""     }      {       \""type\"": \""http\""        \""direction\"": \""out\""        \""name\"": \""res\""     } } </code></pre>""",azure-functions
56477337,".NET Core WebApp  multiple domains  changing SQL connection string based on hostname  can't inject httpcontext into DB Context.cs file <p>I am using Azure .NET core WebApp  MVC  Entity Framework  scaffolded in an existing external MS SQL database. </p>  <p>I register the DB in the startup ConfigureServices like this:</p>  <pre class=\lang-cs prettyprint-override\""><code>services.AddDbContext&lt;MyDbContext&gt;(options =&gt; options.UseSqlServer()); </code></pre>  <p>And it works fine so long as I set the connection string in the MyDbContext.cs OnConfiguring() method like this:</p>  <pre class=\""lang-cs prettyprint-override\""><code>        protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)         {                 optionsBuilder.UseSqlServer(\""Server=10.10.10.10;Database=MyDb;user id=username;password=password;\"");         }  </code></pre>  <p>Then I can simply in a Controller say:</p>  <pre class=\""lang-cs prettyprint-override\""><code>        private readonly MyDbContext _context;         public HomeController()         {             _context = new MyDbContext();         }          public IActionResult Index()         {             var item = _context.TableName.FirstOrDefault(d =&gt; d.Id &gt; 0);         } </code></pre>  <p>And this works fine - data flows in.</p>  <p>My problem is that I need to change the SQL connection string depending on what hostname is connecting. So  either in the startup ConfigureServices() I can pass the connection if I can establish the hostname being used  or in the DB's MyDbContext.cs file's OnConfiguring() method.</p>  <p>I can get the hostname only from the httpcontext  and that isn't available to query in the startup so far as I can tell? </p>  <p>If I try and inject it into the context.cs DB file  like this:</p>  <pre class=\""lang-cs prettyprint-override\""><code>    public partial class MyDbContext : DbContext     {         private readonly IHttpContextAccessor _httpContextAccessor;          public MyDbContext()         {         }          public MyDbContext(IHttpContextAccessor httpContextAccessor)         {             _httpContextAccessor = httpContextAccessor;         // For context/url         }          public MyDbContext(DbContextOptions&lt;MyDbContext&gt; options  IHttpContextAccessor httpContextAccessor)             : base(options)         {             _httpContextAccessor = httpContextAccessor;         // For context/url         } </code></pre>  <p>Then the startup ConfigureServices line services.AddDbContext can't pass the httpcontext (it doesn't exist at that point?) none of the constructor methods match - I can't inject the IHttpContextAccessor httpContextAccessor into the DB context method no matter how I try! </p>  <pre class=\""lang-cs prettyprint-override\""><code>services.AddDbContext&lt;MyDbContext&gt;(options =&gt; options.UseSqlServer(\""some-connection-string\"")); // Doesn't pass httpcontext services.AddDbContext&lt;MyDbContext&gt;()); // Doesn't pass httpcontext services.AddDbContext&lt;MyDbContext&gt;(is there way to pass it?);   </code></pre>  <p>It doesn't seem to work like injecting it into Controllers  which does work fine as there's no constructor there...</p>  <p>Any ideas on how I can find the hostname and change the SQL connection string given this setup?</p>  <p>For various reasons this needs to be a single WebApp that multiple domains use by the way.</p>  <h2>edit</h2>  <p>After a sleepless night I woke up and decided to simply connect to all (three) databases I need and then decide which context to use in the controller  as I have the httpcontext there to decide what host is connecting. It's not ideal  but this is a low overhead WebApp so I'm happy enough to go with it like that. I think perhaps there is/was a solution out there though...</p>""",azure-web-app-service
45909870,"Azure function - VS2017 Tooling - Missing binding in function.json <p>I created a simple HttpTrigger Azure function using VS 17 15.3 (with the nuget package Microsoft.NET.Sdk.Functions 1.0.2) with the wizard. It gave me the following code:</p>  <pre class=\lang-cs prettyprint-override\""><code>public static class Function1 {     [FunctionName(\""Function1\"")]     public static HttpResponseMessage Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = \""HttpTriggerCSharp/name/{name}\"")]HttpRequestMessage req  string name  TraceWriter log)     {         log.Info(\""C# HTTP trigger function processed a request.\"");          // Fetching the name from the path parameter in the request URL         return req.CreateResponse(HttpStatusCode.OK  \""Hello \"" + name);     } } </code></pre>  <p>When I run the function in debug mode with VS and calling it with Postman  it's working fine  I have the body response.</p>  <p>When I start the same function  using the CLI: func host start and calling it with post man  the function doesnt return the body. I have an Http 200 with an empty content. :(</p>  <p>I found  that in the generated <code>function.json</code>  there is no http out binding. My generated <code>function.json</code></p>  <pre class=\""lang-json prettyprint-override\""><code>{      \""generatedBy\"": \""Microsoft.NET.Sdk.Functions-1.0.0.0\""       \""configurationSource\"": \""attributes\""       \""bindings\"": [          {              \""type\"": \""httpTrigger\""               \""route\"": \""HttpTriggerCSharp/name/{name}\""               \""methods\"": [ \""get\""  \""post\"" ]               \""authLevel\"": \""anonymous\""               \""name\"": \""req\""          }      ]       \""disabled\"": false       \""scriptFile\"": \""..\\\\bin\\\\FunctionApp1.dll\""       \""entryPoint\"": \""FunctionApp1.Function1.Run\""  } </code></pre>  <p>When I add the http out binding  It's working fine using func host start</p>  <pre class=\""lang-json prettyprint-override\""><code>{      \""generatedBy\"": \""Microsoft.NET.Sdk.Functions-1.0.0.0\""       \""configurationSource\"": \""attributes\""       \""bindings\"": [          {              \""type\"": \""httpTrigger\""               \""route\"": \""HttpTriggerCSharp/name/{name}\""               \""methods\"": [ \""get\""  \""post\"" ]               \""authLevel\"": \""anonymous\""  \""name\"": \""req\""          }           {              \""type\"": \""http\""               \""direction\"": \""out\""               \""name\"": \""res\""          }      ]       \""disabled\"": false       \""scriptFile\"": \""..\\\\bin\\\\FunctionApp1.dll\""       \""entryPoint\"": \""FunctionApp1.Function1.Run\""  } </code></pre>  <p>It's very strange that in debug mode  it's work and not using cli directly...</p>  <p>Thanks for your help</p>""",azure-functions
50825960,Azure - Uninstall IaaSDiagnostics Extension after manually deleting Storage account <p>I need to uninstall the IaaSDiagnostics Extension for my VM.</p>  <p>However I have manually deleted the diagnostic storage account and now when I try to uninstall the diagnostic extension I get an error saying:</p>  <blockquote>   <p>Provisioning state Provisioning failed. </p>      <p>StorageAccount 'xxxxxdiag160' associated with VM 'xxxxxx' for boot   diagnostics encountered an error. Please look at the error code for   more information about the error.. StorageAccountNotFound</p>      <p>Provisioning state error code ProvisioningState/failed/StorageAccountNotFound</p> </blockquote>  <p>How can I delete the IaaSDiagnostics Extension now with the Storage Account associated already deleted?</p>,azure-storage
49269908,"Repository info in Visual Studio Solution <p>I copied and pasted an existing solution with multiple projects into a new folder. The original solution is bound to a repository on VSTS.</p>  <p>I was careful to copy only the actual project files I created along with the <code>sln</code> file. When I opened the new version  I got the following messages.</p>  <p><a href=\https://i.stack.imgur.com/PoZTY.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/PoZTY.png\"" alt=\""enter image description here\""></a></p>  <p><a href=\""https://i.stack.imgur.com/pgyeu.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/pgyeu.png\"" alt=\""enter image description here\""></a> In the <code>sln</code> file  I don't see any information about the repo. Where is the repo information stored? What file do I need to edit to remove all references to a repository?</p>  <p>P.S. I'm using Visual Studio 2017 on my computer and on VSTS  I'm using TFVC for version control.</p>  <p>Update: When I go to File > Source Control > Advanced > Change Source Control  I see no bindings. See image below. <a href=\""https://i.stack.imgur.com/bis1y.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/bis1y.png\"" alt=\""enter image description here\""></a></p>  <p>When I click the \""Team Explorer\""  I get the following message. <a href=\""https://i.stack.imgur.com/dJENi.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/dJENi.png\"" alt=\""enter image description here\""></a></p>  <p>I don't think I have any workspaces configured. See below: <a href=\""https://i.stack.imgur.com/Oqs2D.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Oqs2D.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
9186200,How can I automate publishing and referencing static content to Azure Blob Storage? <p>To optimise the speed of my MVC3 Azure site it has been suggested that I should host my JS  CSS and image files (basically any static content) in Azure public containers with CDN enabled. These should then be linked to instead of being stored on the web role.</p>  <p>Is there anyway to automate this as part of a publishing the solution? So that I get underlining etc in VS2010?  </p>  <p>Effectively anything that is stored in the local MVC3 content &amp; scripts folder should be copied to Azure storage and referenced from there.</p>  <p>It seems like something that should be a straightforward option. Am I missing something obvious</p>  <p>Thanks</p>,azure-storage
41951912,Azure functions experimental templates <p>I am trying to use Azure functions and I see that there are Sample and Experimental type of templates.  Can I trust experimental templates in production environment? </p>,azure-functions
43781176,Best option to schedule payments: azure scheduler  WebJob or Azure Functions or a Worker Role? <p>I've hosted my website on azure and now I want to schedule payments on a monthly basis. I am using Authorize.net for payments but I cannot use their recurring billing feature as it gives very little control. I've to perform checks in the database  make payments and update records. What should I use Azure Scheduler  Azure WebJob or Azure Functions a Worker Role?</p>,azure-functions
28840249,Set expiry limit for blob <p>I'm using Azure-Storage for storing information like a cache mechanism. So  for given input I'm doing the job for first time and after that I'll save the result in the cache for further use. When I'll need to solve the problem with same given input  I'll get it directly the already ready solution from storage. This all is implemented. </p>  <p>I'm trying to add a expiry limit for file in my cache. Each result will be stored for maximum 30 days. After that  they will be automatically deleted. </p>  <p><strong>The naive solution</strong> is to implement also an background worker that will run one time per day and will run over all files and delete them  according to their creation time. </p>  <p>There are better solution?</p>,azure-storage
47348450,"Build exe and webapp using msbuild commandline <p>I am trying to build a solution using ms-build command line  which contains multiple projects.</p>  <p>Four of them are creating an exe file as output and rest are creating a single web application.</p>  <p>Now when I try to build them together using msbuild  it throws out error-</p>  <pre><code>/p:WebPublishMethod=Package /p:DeployOnBuild=true /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true  /p:outdir=\$(build.artifactstagingdirectory)\\\\\"" </code></pre>  <p>Error - </p>  <pre><code>error MSB4057: The target \""ResolveWebJobFiles\"" does not exist in the  project. </code></pre>  <p>Note - If I remove property \""/p:WebPublishMethod=Package\"" then it runs well but doesn't create the zip file.</p>  <p>Can anyone please suggest me any property by which I can create the zip file?</p>""",azure-devops
55024741,Can I run multiple instances of an azure function listening to the same queue <p><strong>Background:</strong> I have been running into an issue recently that my function can not handle the load and the queue messages are building up.  In the long term I am looking at the code to find where there are bottle necks but in the short term I need to solve this problem.<br> <strong>Question:</strong> <strong>Can I add multiple instances of the same azure function (even if it is a rename myjobrunner1  myjobrunner2) etc that all listen to the same queue?  Would this help in my situation?</strong></p>  <p><strong>Some caveats:</strong><br> The premium plan looks good but I can not test a preview while in production at the moment.<br> Adding a dedicated AppService is an option but it is a longer term fix.  I am having the trouble now.<br> Code fixes are in process to handle the load better and improve performance but the fact that the outside services are what is holding them up is a factor.</p>,azure-functions
43810248,"Powershell for an Advanced Application Restart on an Azure Web App <p>It is possible to use Restart-​Azure​Rm​Web​App PowerShell to restart a web app but this will restart all servers in the plan simultaneously  giving a short downtime.</p>  <p>The Azure Portal has an \Advanced Application Restart\"" feature that uses a time delay between restarting individual instances.</p>  <p>Is there any way to invoke that from PowerShell?</p>""",azure-web-app-service
51513795,"Create instance of an object in a new app domain in azure function throws a FileNotFoundException <p>I need to run some code in a new app domain. So I am trying to create an instance of my object in the new app domain... Here te code I am using:</p>  <pre><code>public static class Program {     private static ITemplateEngineProvider _templateEngineProvider;      static Program()     {         AppDomain ad = AppDomain.CreateDomain(\New domain\"");          ObjectHandle handle = ad.CreateInstance(                 assemblyName: typeof(RazorTemplateEngineProvider).Assembly.FullName                  typeName: \""RazorTemplateEngineProvider\""                 //ignoreCase: false                  //bindingAttr: BindingFlags.CreateInstance                  //binder: null                  //args: new object[] { new string[] { templatePath  layoutPath } }                  //culture: CultureInfo.InvariantCulture                  //activationAttributes: null                 );              _templateEngineProvider = (RazorTemplateEngineProvider)handle.Unwrap();     } } </code></pre>  <p><code>RazorTemplateEngineProvider</code> is a custom public class that has a public constructor. It has been implemented in a class library (<code>MyCustomLib.dll</code>) I referenced inside the azure function.  The class implements an interfaces defined in another class library (<code>IMyCustomLib.dll</code>) referenced only by the previous class library  not by azure function.</p>  <p>At the moment there is no code inside the <code>RazorTemplateEngineProvider</code> class:</p>  <pre><code>public class RazorTemplateEngineProvider : MarshalByRefObject  ITemplateEngineProvider {     public RazorTemplateEngineProvider()     { } } </code></pre>  <p>When I try to do <code>ad.CreateInstance</code> a <code>FileNotFoundException</code> has been thrown:</p>  <blockquote>   <p>Could not load file or assembly 'MyCustomLib.dll  Version=1.0.0.0  Culture=neutral  PublicKeyToken=...' or one of its dependencies. The system cannot find the file specified.</p> </blockquote>  <p>But the file exists and it should be already correctly loaded... Infact if I run this 'query'</p>  <pre><code>IEnumerable&lt;string&gt; loadedAssemblies = AppDomain.CurrentDomain.GetAssemblies()    .Where(a =&gt; !a.IsDynamic &amp;&amp; !a.FullName.Contains(\""Version=0.0.0.0\"") &amp;&amp; File.Exists(a.Location) &amp;&amp; !a.Location.Contains(\""CompiledRazorTemplates.Dynamic\"") &amp;&amp;  a.FullName.Contains(\""My\""))    .Select(f =&gt; f.FullName)    .ToArray(); </code></pre>  <p>I see both my dll. So  why do I get that error?</p>  <p>Thank you</p>  <p><strong>UPDATE</strong></p>  <p>I think problem is azure because I copied and pasted my code in a console application and thereit works.</p>  <p><strong>UPDATE</strong></p>  <p>I am watching the fusionlong and it seem it is trying to load the assembly from a  \""wrong\"" path: <code>file:///C:/Users/csimb/AppData/Local/Azure.Functions.Cli/1.0.12/MyCustomLib.dll</code>.. I expected the path was the bin folder...</p>""",azure-functions
51346603,"Visual Studio Team Explorer sync and pull error <p>I am trying to push my change code to a VSTS git repository. When I am trying to sync  I get an error in my output window</p>  <blockquote>   <p>Git failed with a fatal error. ArgumentNullException encountered.<br>   Value cannot be null. Parameter name: path From   <a href=\https://xxxxxxxxxxxxxxxxxxxx.visualstudio.com/_git/xxxxxxxxxxxxx\"" rel=\""nofollow noreferrer\"">https://xxxxxxxxxxxxxxxxxxxx.visualstudio.com/_git/xxxxxxxxxxxxx</a>  =   [up to date]      master     -> origin/master</p> </blockquote>  <p>but the code is successfully pushed to my VSTS repository And this error only comes when I tried to pull on VSTS</p>""",azure-devops
18765900,"Subdomain on Azure VM IIS (x.y.cloudapp.net) <p>Im pretty new with azure  but iv'e set up a VM running windows 2008 server  with IIS hosting  a Umbraco Solution...</p>  <p>I can browse the site perfectly using \x.cloudapp.net\"". But i have setup some hostnames in Umbraco for subsites.</p>  <p>Fx. i got \""y.x.cloudapp.net\"". and its also added to IIS bindings. But this is not browsable at all?</p>""",azure-virtual-machine
48318536,"Cloning repository using GIT on Powershell ISE - Proxy issues <p>I am getting proxy errors using PowerShell ISE with Git-Posh.</p>  <p>When using GIT only (Bash)  cloning goes fine. I had to add these to the .gitconfig file</p>  <pre><code>[http]     proxy = http://localhost:1800  [https]     proxy = http://localhost:1800 </code></pre>  <p>However  when using Git-posh on a PowerShell ISE script I get exceptions:</p>  <p>1) Command one generates this exception.</p>  <pre><code>$resp = Invoke-WebRequest -Headers $headers -Uri (\{0}/_apis/git/repositories?api-version=1.0\"" -f $url) $json = convertFrom-JSON $resp.Content </code></pre>  <blockquote>   <p>Invoke-WebRequest : Proxy Authorization Required       Description: Authorization is required for access to this proxy</p> </blockquote>  <p>2) Cloning generates this exception</p>  <pre><code> git clone --mirror $url </code></pre>  <blockquote>   <p>fatal: unable to access   '<a href=\""https://pn%fastCars.onmicrosoft.com:3kfokgwgwgwiigjiwjgjwigiiqegqegewrwghdasdasfggaffaa@fastCars.visualstudio.com/Ferrari/_git/FerrariF50-PerformanceTests/\"" rel=\""nofollow noreferrer\"">https://pn%fastCars.onmicrosoft.com:3kfokgwgwgwiigjiwjgjwigiiqegqegewrwghdasdasfggaffaa@fastCars.visualstudio.com/Ferrari/_git/FerrariF50-PerformanceTests/</a>':   Failed to        connect to localhost port 1800: Connection refused</p> </blockquote>  <p>Does anyone know which command can turn this around?</p>""",azure-devops
49283453,Azure portal. What is the best practise way to store and make deal with not single line application settings <p>Could someone advise  what is the best way to work with big application configurations which look like <code>xml</code>/<code>json</code> data? These data contain diff information(mostly static  but rarely it can be changed)  but all of these data don't have security value.  For instance  it can be item options for an user control(like dropdown) in an application page or static data which is used as markup on the basis of which an web page creates a user control for page and so on.</p>  <p>I have several approaches for this:</p>  <ol> <li><code>Key vault</code>. As I can undestand  the main idea of this storage is to work with security data like connection string  passwords and so on. How about using it to work with bigger and wider settings? The big plus for me  that this way contains built-in cache functionality  but it doesn't look like best practise way for me. </li> <li><code>Storage account</code>/<code>Cosmos db</code>  - as far as I see  both of these ways are used similar and can be used for my target. The question is what is the most economic and productive way for me and will these ways better then the <code>Key Vault</code> way? </li> </ol>  <p>So  what is the most common solution for this target?</p>  <p>Thanks.</p>,azure-storage
41869897,"Error when calling method in custom assembly from Azure functions <p>see screenshot for the express version:<br> <a href=\https://i.stack.imgur.com/pFD73.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/pFD73.png\"" alt=\""screenshot for the express version\""></a></p>  <p>I have an Azure function (in Visual Studio)  that triggers correctly an Service Bus event. In its run-method I want to call a method in a custom assembly. This works ok  until I use any method that uses Dynamics CRM assemblies. (I have tried both the assemblies from the downloadable sdk and the nuget package. I get the exact dll it asks for in the error message.  As soon as I call the my method I get the error below. I can run this exact method from a console app. (my custom assembly is a standard (not core) class library... </p>  <blockquote>   <p>Additional information: Could not load file or assembly 'Microsoft.Xrm.Sdk  Version=8.0.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35' or one of its dependencies. The system cannot find the file specified.</p> </blockquote>""",azure-functions
42661047,start VM on RDP request <p>I have a windows 10 VM in azure. I connect to this machine RDP. Because most of the time this machine is not in use (I'm not using it) I'd like  in order to save the costs  to shut down it.  My issue is to get back  to connect to it RDP after that. How do I start the machine remotely?</p>,azure-virtual-machine
45325736,"PartitionKey was not specified in azure table storage <p>I am trying to load/import the data into table storage from a csv file via azure storage explorer   but I am getting the following error as </p>  <p><code>An error occurred while opening the file 'D//sample.csv'.the required property 'Partitionkey' was not specified.</code></p>  <p><a href=\https://i.stack.imgur.com/E5Cs2.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/E5Cs2.jpg\"" alt=\""enter image description here\""></a></p>  <p>Kindly clarify the importance of Partitionkey and Rowkey in azure table storage? </p>""",azure-storage
23518078,"store nlog generated logs to Azure Blob Storage  in seperate columns <p>I've enabled diagnostics logging to Blob Storage for an Azure Website I am trying on.  I've also set Nlog to write to <code>Trace</code>  so that they are then in turn written to the Azure blob.  Nlog layout is set to CSV.  This works  and the generated logs are outputted to the blob storage.  If this was logging to a traditional file  that file would be a CSV file which I can open in excel  to analyse better the log files.</p>  <p>Nlog configuration file copied below:</p>  <pre><code>&lt;?xml version=\1.0\"" encoding=\""utf-8\"" ?&gt; &lt;nlog xmlns=\""http://www.nlog-project.org/schemas/NLog.xsd\""       xmlns:xsi=\""http://www.w3.org/2001/XMLSchema-instance\""&gt;    &lt;!--    See http://nlog-project.org/wiki/Configuration_file    for information on customizing logging rules and outputs.    --&gt;   &lt;targets&gt;     &lt;!-- add your targets here --&gt;      &lt;!--     &lt;target xsi:type=\""File\"" name=\""f\"" fileName=\""${basedir}/logs/${shortdate}.log\""             layout=\""${longdate} ${uppercase:${level}} ${message}\"" /&gt;     --&gt;     &lt;target xsi:type=\""Trace\"" name=\""trace\"" &gt;       &lt;layout xsi:type=\""CsvLayout\"" &gt;         &lt;column name=\""shortdate\"" layout=\""${shortdate}\"" /&gt;         &lt;column name=\""time\"" layout=\""${time}\"" /&gt;         &lt;column name=\""logger\"" layout=\""${logger}\""/&gt;         &lt;column name=\""level\"" layout=\""${level}\""/&gt;         &lt;column name=\""machinename\"" layout=\""${machinename}\""/&gt;         &lt;column name=\""processid\"" layout=\""${processid}\""/&gt;         &lt;column name=\""threadid\"" layout=\""${threadid}\""/&gt;         &lt;column name=\""threadname\"" layout=\""${threadname}\""/&gt;         &lt;column name=\""message\"" layout=\""${message}\"" /&gt;         &lt;column name=\""exception\"" layout=\""${exception:format=tostring}\"" /&gt;        &lt;/layout&gt;     &lt;/target&gt;   &lt;/targets&gt;    &lt;rules&gt;     &lt;!-- add your logging rules here --&gt;     &lt;logger name=\""*\"" minlevel=\""Trace\"" writeTo=\""trace\"" /&gt;     &lt;!--     &lt;logger name=\""*\"" minlevel=\""Trace\"" writeTo=\""f\"" /&gt;     --&gt;   &lt;/rules&gt; &lt;/nlog&gt; </code></pre>  <p>Windows Azure diagnostics saves the diagnostics info as a CSV file in the blob storage.  The CSV file has the below columns.</p>  <pre><code>date level applicationName instanceId eventTickCount eventId pid tid message activityId </code></pre>  <p>However  the entire NLog message is written in the <code>Message</code> column.  This is probably because it saves the <code>Diagnostics.Trace</code> message there  in which NLog is saving it'slogs. For example:</p>  <pre><code>2014-05-07T12:18:49 Information KarlCassarTestAzure1 10cd67 635350619297036217 0 2984 1 \""2014-05-07 12:18:49.6254 TestAzureWebApplication1.MvcApplication Info RD0003FF410F59 2984 1  Application_Start \""  </code></pre>  <p>The NLog message is the below:</p>  <pre><code>\""2014-05-07 12:18:49.6254 TestAzureWebApplication1.MvcApplication Info RD0003FF410F59 2984 1  Application_Start \"" </code></pre>  <p>It is escaped  and fits entirely in the CSV column  which I wouldn't wish.  Any idea if there is something to do about this?</p>""",azure-storage
55299880,"Azure functions TypeScript decorator <p><strong><a href=\https://azure.microsoft.com/en-us/blog/improving-the-typescript-support-in-azure-functions/\"" rel=\""nofollow noreferrer\"">Recently Azure functions released support for TypeScript</a></strong>:</p>  <pre><code>import { AzureFunction  Context  HttpRequest } from '@azure/functions';  @some_decorator - ??? const httpTrigger: AzureFunction = async function (context: Context   req: HttpRequest): Promise&lt;void&gt; {         }  export default httpTrigger; </code></pre>  <p>I'm looking for a good approach to implement a pre-function call. For instance  the pre-function could do authorization checks or whatever else is necessary before the function in question is executed.</p>  <p>I'm wondering which TypeScript decorators would be the best and cleanest option but not sure about the implementation.</p>""",azure-functions
52320153,"Unable to install the DependencyAgent Azure VM extension <p>I have an environment with about a dozen VMs each of which has the Microsoft Monitoring Agent reporting to a central OMS Workspace. In addition  these VMs have the DependencyAgent installed.</p>  <p>Five of the VMs have the DependencyAgent extension reporting their state on the portal as \Provisioning succeeded\"" and I can see them in the Service Map workspace solution in Log Analytics. However  for some reason  the other six show the extension as \""Transitioning\"".</p>  <p>When I log into one of those VMs and view the logs for the extension in  <code>C:\\WindowsAzure\\Logs\\Plugins\\Microsoft.Azure.Monitoring.DependencyAgent.DependencyAgentWindows\\9.6.2.1366</code></p>  <p>I see:</p>  <blockquote>   <p>Execution Output: Start-Service : Failed to start service 'Microsoft   Dependency Agent (MicrosoftDependencyAgent)'</p> </blockquote>  <p>I try to manually start the service  but get \""The Microsoft Dependency Agent service on Local Computer started an then stopped.\"" and in the Event Viewer I see \""The Microsoft Dependency Agent service entered the stopped state.\""</p>  <p>Any idea what I could possibly be doing wrong or where I can get additional logs?</p>""",azure-virtual-machine
39856227,"Unable to retrieve image blob with encoded & (ampersand) in SAS part of url <p>I have image blob url in following form: <a href=\https://my-storage.blob.core.windows.net/my-container/my-virtual-directory/image-name.png?sv=2015-12-11&amp;sr=b&amp;si=my-policy&amp;sig=ZiKivSYXr63vBtdY7IsxVQ01WmrFnK%2FC9xABVrho6sY%3D&amp;se=2016-10-04T15%3A37%3A11Z\"" rel=\""nofollow\"">https://my-storage.blob.core.windows.net/my-container/my-virtual-directory/image-name.png?sv=2015-12-11&amp;sr=b&amp;si=my-policy&amp;sig=ZiKivSYXr63vBtdY7IsxVQ01WmrFnK%2FC9xABVrho6sY%3D&amp;se=2016-10-04T15%3A37%3A11Z</a></p>  <p>I use this image source in my html editor inside tag . Problem is when url get encoded &amp; is replaced with &amp; and after my image is not available from that url. I tried doing it inside browser directly (replacing any &amp; to &amp;) and it returns response \""Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\""</p>  <p>Why is this happening? What might be the solution?</p>""",azure-storage
54686530,"How to check the aks api in Azure Devops Pipeline <p>I have a simple Nodejs API  where have a /health path to valid the result \OK\""</p>  <p>How can i check the /health result within the Azure Devops release pipeline?</p>  <p>My pipeline will pull the artifact from the Azure Container registry and deploy to aks then promote the service in Ingress and API management to access by the public.</p>""",azure-devops
55644026,Azure function - should context.done be called after each loop or at end <p>In an Azure function say I have:</p>  <pre><code>const cosmosDBTrigger: AzureFunction = async function (context: Context  documents: any[]): Promise&lt;void&gt; {     if (!!documents &amp;&amp; documents.length &gt; 0) {         documents.forEach(function (document) {             context.bindings.outputdocuments = document             //1 - SHOULD IT GO HERE         });      } //2 - SHOULD IT GO HERE } </code></pre>  <p>Is the correct place to place <code>context.done</code> be in position 1 or 2. Namely should be after each document in the loop at the very end?</p>  <p>Thanks.</p>,azure-functions
52601259,"How do we trigger a build only for tags matching a pattern <p>I want to create a build script specifically when I push a tag pattern on git (not a branch).</p>  <p>But I cannot find it in the </p>  <ul> <li><a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/process/expressions?view=vsts\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/process/expressions?view=vsts</a></li> <li><a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=vsts&amp;tabs=yaml%2Cbatch\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=vsts&amp;tabs=yaml%2Cbatch</a></li> <li><a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=vsts\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=vsts</a></li> </ul>  <p>I'm looking specifically at \""pattern\"" rather than a static string</p>""",azure-devops
14169539,Proper CloudTableClient instance lifecycle? <p>I'm using the new WindowsAzure.Storage 2.0 (might not be a revelant information)  and I'm implementing data access using CloudTableClient. Most samples I've seen are instanciating a CloudTableClient in the ctor of an ASP MVC Controller (instanciated per web request). Is there any performance penalty doing so? Would it be wise to keep a long running instance in a singleton style?</p>,azure-storage
16199683,Optimize Windows Azure Table Storage? <p>I have about 28GB of Data-In for a little over 13.5 million rows stored in Windows Azure Table Storage.</p>  <p>6 Columns  all ints except 1 decimal and 1 datetime. Partition Key is about 10 characters long. RowKey is a guid.</p>  <p>This is for my sanity check--does this seem about right?  </p>  <p>The Sql Database I migrated the data from has WAY more data and is only 4.9GB.  </p>  <p>Is there a way to condense the size?  I don't suspect renaming properties will put a huge dent on this.</p>  <p>*Note this was only a sampling of data to estimate costs for the long haul.</p>,azure-storage
53105735,"Testing Azure Function With Local Url Error <p>I am building an Azure function and just updated to latest everything  this is my code:</p>  <pre><code>  log.Info($\C# Timer trigger function executed at: {DateTime.Now}\"");    var localCall = httpClient.GetAsync(urls[EnvironmentNames.LOCAL]);   var localCallResult = await localCall;    log.Info($\""{EnvironmentNames.LOCAL} call status code {localCallResult.StatusCode}\""); </code></pre>  <p>The url is:</p>  <p><code>{EnvironmentNames.LOCAL  $\""local.mysite.net:5050/doThings\""} </code></p>  <p>I am getting the following error when testing locally in Visual Studio:</p>  <blockquote>   <p>System.ArgumentException: Only 'http' and 'https' schemes are allowed.</p>      <p>Parameter name: requestUri</p> </blockquote>  <p>Can I not test Azure calls locally?</p>""",azure-functions
32083889,"Not able to check in project to Visual Studio Online due to missing files <p>I'm trying to check in an existing project to Visual Studio Online (VSO) for the first time but I keep getting errors due to missing files. These files appear to be items that we removed. I keep adding them to \Exclude\"" list but there are too many of them e.g. simple PNG images  JS files  etc.</p>  <p>I'm not sure where the \""inventory\"" of files are kept in Visual Studio 2015.</p>  <p>Is there a quick and easy way to remove these missing files' records from Visual Studio so that I can check my project into VSO?</p>""",azure-devops
49501542,"Azure Create Container <p>After creating an Azure Storage account using Python SDK when proceeding to create a storage blob container its throws the following error : <Code>ResourceNotFound</Code>The specified resource does not exist. RequestId:508e8df1-301e-004b-224e-c5feb1000000 Time:2018-03-26T22:03:46.0941011Z</p>  <p>Code snippet:</p>  <pre><code>def create_blob_container(self  storage_account_name  storage_account_key  version):     try:         account = BlockBlobService(account_name = storage_account_name  account_key = storage_account_key.value)                   container_name = \dummy container\""         container = account.create_container(container_name)         if container:             print 'Container %s created' %(container_name)         else:             print 'Container %s exists' %(container_name)     except Exception as e:         print e </code></pre>  <p>Does anybody have any idea how to go about this?</p>  <p>P.S.: I am waiting for provisioning state of storage account to be succeeded and then proceeding to create a container. </p>  <p>Any help is greatly appreciated.</p>""",azure-storage
38951062,"Unable to execute IIS Administration commands on remote machine from Visual Studio Team Services (was Visual Studio Online) Build <p>I have a set of power-shell scripts for managing the entire deployment. We migrated our entire codebase to Visual Studio Team Services (previously VS Online) and I am trying to get the entire deployment automation. </p>  <p>The steps I am following on high level are :</p>  <ul> <li>Restore the packages and build the solutions</li> <li>Package the artifacts required in to a single folder (includes binaries  scripts  dacpac etc)</li> <li>Copy the package to a azure vm using azure file copy</li> <li>Execute the scripts on target machine</li> </ul>  <p><a href=\https://i.stack.imgur.com/Jto1y.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Jto1y.png\"" alt=\""Build Steps\""></a></p>  <p>The issue I am facing is - none of the IIS Administration commands are executing on the remote machine.  e.g. Remove-WebSite/Remove-WebAppPool are not working. </p>  <p>I do not see any error also being thrown by these commands.</p>  <p>Is there anything specific which needs to be enabled to run these commands. </p>  <p><strong>NOTE :</strong> I am able to get the same scripts working fine when I run from the server directly. The issue is only when I am using the run 'powershell on target machine' on build steps of Team Services.</p>""",azure-devops
42645408,Rails and Azure VM: where to set environment variables (mailer) <p>I have a Rails app hosted on an Azure virtual machine.</p>  <p>Every mailer tutorial recommends to store your domain and settings for incoming and outgoing emails in environment variables.</p>  <p>Is it safe then just to set them as normal linux env variables in the virtual machine? Or better use the Azure portal?</p>,azure-virtual-machine
53964647,"Azure DevOps: create a comment on behalf of another user <p>I'm looking for a way to add a comment to a work item on behalf of another user (impersonate another user).</p>  <pre><code>        VssConnection connection = new VssConnection(new Uri(url)  new VssClientCredentials());         WorkItemTrackingHttpClient client = connection.GetClient&lt;WorkItemTrackingHttpClient&gt;();          patchDocument.Add(             new JsonPatchOperation()             {                 Operation = Operation.Add                  Path = \/fields/System.History\""                  Value = \""Sample comment 1\""             }         );          await client.UpdateWorkItemAsync(patchDocument  id); </code></pre>""",azure-devops
52798199,"Access Is Denied error pushing package into my azure devops artifacts nuget feed <p>In <a href=\https://stackoverflow.com/questions/52772765/how-do-i-set-up-azure-dev-ops-to-build-dev-express-xaf-xpo-project\"">my question here</a> I managed to push one package to my feed  however I now get an Access is denied error.</p>  <p>According to <a href=\""https://stackoverflow.com/questions/48511512/authenticating-to-vsts-package-management?rq=1\"">this question</a> I should be prompted for user name and password.  This did occur for the package I managed to push  but it no longer occurs.</p>  <p>What do I need to do?</p>  <p>Studying the <a href=\""https://docs.microsoft.com/en-us/azure/devops/artifacts/nuget/nuget-exe?view=vsts&amp;tabs=new-nav\"" rel=\""nofollow noreferrer\"">docs</a></p>  <p><a href=\""https://github.com/MicrosoftDocs/vsts-docs/issues/757\"" rel=\""nofollow noreferrer\"">this issue on Git is relevant</a></p>  <p>[Update]</p>  <p>Something strange has happened to my folder. I get the error if I just type Nuget at the dos prompt. If I create a new folder and extract nugetcredentialprovider.zip into it  then run Nuget I don't get the error</p>  <p><a href=\""https://docs.microsoft.com/en-us/nuget/tools/nuget-exe-cli-reference\"" rel=\""nofollow noreferrer\"">the cli reference</a></p>  <p><a href=\""https://docs.microsoft.com/en-us/nuget/tools/cli-ref-push\"" rel=\""nofollow noreferrer\"">push reference</a></p>  <p><a href=\""https://docs.microsoft.com/en-us/nuget/consume-packages/configuring-nuget-behavior\"" rel=\""nofollow noreferrer\"">configuring nuget behaviour</a></p>""",azure-devops
55236470,mapreduce job on yarn exited with exitCode: -1000 beacuse of resource changed on src filesystem <pre><code>    Application application_1552978163044_0016 failed 5 times due to AM Container for appattempt_1552978163044_0016_000005 exited with exitCode: -1000 </code></pre>  <p>Diagnostics: </p>  <blockquote>   <p>java.io.IOException: Resource   abfs://xxx@xxx.dfs.core.windows.net/hdp/apps/2.6.5.3006-29/mapreduce/mapreduce.tar.gz   changed on src filesystem (expected 1552949440000  was 1552978240000   Failing this attempt. Failing the application.</p> </blockquote>,azure-storage
55685233,I want to integrate oauth code grant flow for and spa and back end is hosted on azure functions <p>I am working on an SPA in angular and azure functions as back end. and using Azure active directory for single sign on. I have implemented Implicit Flow and it works fine. but the issue is that I do not want to expose the <code>access_token</code> in the browser.</p>  <p>I want to implement code grant flow with <code>PKCE</code> validation. I need recommendations how to do it properly in azure functions.</p>,azure-functions
43610911,"Azure Web App web.config Rewrite not working <p>I use Azure Web App as a reverse proxy. When I typed URL like \www.ABC.com\""  it was working. If I change to \""www.ABC.com/abc\""  it wasn't working. Then it will change my URL to the \""www.ABC.com/abc\"". I just want to keep this URL on Azure Web App like \""<a href=\""http://ABC.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://ABC.azurewebsites.net</a>\"". Does anybody know how to solve this problem?</p>  <pre><code> &lt;rule name=\""Proxy\"" stopProcessing=\""true\""&gt;         &lt;match url=\""(.*)\"" /&gt;         &lt;action type=\""Rewrite\"" url=\""https:/www.ABC.com/abc/{R:1}\"" /&gt;         &lt;serverVariables&gt;             &lt;set name=\""HTTP_X_UNPROXIED_URL\"" value=\""https:/www.ABC.com/abc/{R:1}\"" /&gt;              &lt;set name=\""HTTP_X_ORIGINAL_ACCEPT_ENCODING\"" value=\""{HTTP_ACCEPT_ENCODING}\"" /&gt;              &lt;set name=\""HTTP_X_ORIGINAL_HOST\"" value=\""{HTTP_HOST}\"" /&gt;             &lt;set name=\""HTTP_ACCEPT_ENCODING\"" value=\""\"" /&gt;         &lt;/serverVariables&gt;     &lt;/rule&gt; </code></pre>""",azure-web-app-service
46678070,"SQL Lite on Azure App Service - Inserts Slow and Timeout <p>We have a process that needs to create a sql lite database with a couple tables with about 750k records/100mb.  It gets uploaded somewhere else (Azure Storage Blob).  I know Azure App's have very slow disk I/O and when running this locally it takes a few seconds  it always times out on Azure.   I've tried setting the <code>WEBSITE_LOCAL_CACHE_OPTION</code> to <code>always</code> and using the temp folder but that didn't help.  </p>  <p>I looked into using a sql lite in memory database but there seems to be no way to avoid the file system if I want to convert that into a byte array (or stream) which is slow in an azure app.  Ideally getting access to the in memory database to stream to a blog would be best case scenario.</p>  <p>Are there any tweaks in sql lite or in the azure app service that would allow this to finish in a reasonable amount of time?</p>  <p>Using service stack's ormlite.  Here is an example:</p>  <pre><code> using (var trans = dba.OpenTransaction( System.Data.IsolationLevel.ReadUncommitted))                 {                     dbLite.InsertAll(locs);                     foreach (var s in sales)                     {                         dbLite.Insert&lt;Sales&gt;(s);                     }                      trans.Commit();                 } </code></pre>  <p>Interesting enough I got the time down from never working (10 minutes it has written 5mb so I know it will never finish) to 4-5 minutes with </p>  <pre><code>dbLite.ExecuteSql(\pragma page_size = 8192\""); dbLite.ExecuteSql(\""pragma synchronous = OFF\""); dbLite.ExecuteSql(\""PRAGMA journal_mode = OFF\""); </code></pre>  <p>This is compared to 1 second locally.  The synchronous mode set to off seems to help the most in my scenario.</p>""",azure-web-app-service
39244265,"Azure web app redirect http to https <p>I use Azure cloud with web app and my server side written on <code>nodejs</code>. When web app receive a http request I want to redirect the request to https I found the solution. I put that to my web.config file inside the <code>rules</code> tag </p>  <pre><code>        &lt;rule name=\Force HTTPS\"" enabled=\""true\""&gt;           &lt;match url=\""(.*)\"" ignoreCase=\""false\"" /&gt;           &lt;conditions&gt;             &lt;add input=\""{HTTPS}\"" pattern=\""off\"" /&gt;           &lt;/conditions&gt;           &lt;action type=\""Redirect\"" url=\""https://{HTTP_HOST}/{R:1}\"" appendQueryString=\""false\"" redirectType=\""Permanent\"" /&gt;         &lt;/rule&gt; </code></pre>  <p>The problem is when I type in the browser \""<a href=\""https://myURL.com\"" rel=\""noreferrer\"">https://myURL.com</a>\"" it redirect to main screen every thing ok  but when I change https to http \""<a href=\""http://myURL.com\"" rel=\""noreferrer\"">http://myURL.com</a>\"" it redirect to <a href=\""https://myURL.com/\"" rel=\""noreferrer\"">https://myURL.com/</a>\"" and add to the url \""bin/www\"" according that the url looks like that \""<a href=\""http://myURL.com/bin/www\"" rel=\""noreferrer\"">http://myURL.com/bin/www</a>\""  the response is: page doesn't find.</p>  <p>The question is how to redirect a clear url without added data to the url?</p>  <p>Part of my web.config file:</p>  <pre><code>&lt;rewrite&gt;       &lt;rules&gt;         &lt;!-- Do not interfere with requests for node-inspector debugging --&gt;         &lt;rule name=\""NodeInspector\"" patternSyntax=\""ECMAScript\"" stopProcessing=\""true\""&gt;           &lt;match url=\""^bin/www\\/debug[\\/]?\"" /&gt;         &lt;/rule&gt;         &lt;!-- First we consider whether the incoming URL matches a physical file in the /public folder --&gt;         &lt;rule name=\""StaticContent\""&gt;           &lt;action type=\""Rewrite\"" url=\""public{REQUEST_URI}\"" /&gt;         &lt;/rule&gt;         &lt;!-- All other URLs are mapped to the node.js site entry point --&gt;         &lt;rule name=\""DynamicContent\""&gt;           &lt;conditions&gt;             &lt;add input=\""{REQUEST_FILENAME}\"" matchType=\""IsFile\"" negate=\""True\"" /&gt;           &lt;/conditions&gt;           &lt;action type=\""Rewrite\"" url=\""bin/www\"" /&gt;         &lt;/rule&gt;         &lt;!-- Redirect all traffic to SSL --&gt;          &lt;rule name=\""Force HTTPS\"" enabled=\""true\""&gt;           &lt;match url=\""(.*)\"" ignoreCase=\""false\"" /&gt;           &lt;conditions&gt;             &lt;add input=\""{HTTPS}\"" pattern=\""off\"" /&gt;           &lt;/conditions&gt;           &lt;action type=\""Redirect\"" url=\""https://{HTTP_HOST}/{R:1}\"" appendQueryString=\""false\"" redirectType=\""Permanent\"" /&gt;         &lt;/rule&gt;       &lt;/rules&gt;     &lt;/rewrite&gt;     &lt;!-- 'bin' directory has no special meaning in node.js and apps can be placed in it --&gt;     &lt;security&gt;       &lt;requestFiltering&gt;         &lt;hiddenSegments&gt;           &lt;remove segment=\""bin\"" /&gt;         &lt;/hiddenSegments&gt;       &lt;/requestFiltering&gt;     &lt;/security&gt; </code></pre>  <p>Thanks for answers  Michael.</p>""",azure-web-app-service
42851059,Strategies to encrypt on Azure without using KeyVault <p>Need to store some content in Azure Blob Storage  and want to encrypt prior to storing it on Azure Blob (we don't want to rely on Azure storage encryption on-rest). The issue is we do not want to store our encryption keys on Azure (e.g. Key vault)  and store it outside of Azure. Any suggestion on strategies for achieving this? </p>,azure-storage
55244735,"Host Serial Port forward to Azure VM Client <p>I am writing a barcode program using a VM in Azure. The software on my local machine emulates a serial port using a USB port.</p>  <p>Is there a way to forward data from  for example  comm port 3  to the azure VM.</p>  <p>******* edited 3/21/19 - in response to my realization and SumanthMarigowda-MSFT</p>  <p><a href=\https://i.stack.imgur.com/TgEGV.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/TgEGV.jpg\"" alt=\""enter image description here\""></a></p>  <p>but in the Azure VM I am only seeing com1 and com2:</p>  <p><a href=\""https://i.stack.imgur.com/5lSFk.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/5lSFk.jpg\"" alt=\""enter image description here\""></a></p>  <p>Gina</p>""",azure-virtual-machine
54755278,How to set up Azure IP alias directly using DNS name? <p>I'm setting up my website on Azure service. My DNS zone is 'xxx.io' (for example). I can create address such as 'main.xxx.io' or 'web.xxx.io' using Alias record sets and they work well. But I can't access the website directly using 'xxx.io' as address. How do I achieve this?<br> PS: my colleague says it used to work but now it doesn't  and he doesn't know how either.</p>,azure-web-app-service
52111269,"How to backup Azure Cosmos DB with Azure Function App <p><strong>Problem:</strong></p>  <p>I try to build a backup solution for Azure Cosmos DB that gives us DB dumps on a regular basis in case we programmatically corrupt the data in our database. The issue is that Data Factory does not (yet) exist for Azure Germany and we cannot rely on the automatic backups from Azure (that are only available for 8 hours). I do not want to use any extra applications outside the cloud.</p>  <p><strong>What I found so far:</strong></p>  <p><a href=\https://www.npmjs.com/package/mongo-dump-stream\"" rel=\""nofollow noreferrer\"">https://www.npmjs.com/package/mongo-dump-stream</a></p>  <p>Mongo Dump Stream should be able to connect to our DB and read from it.</p>  <p>My idea is to use this npm from within Azure Functions and send the result of the dump to a blob storage.</p>  <p><strong>My question:</strong></p>  <p>How can I send the result to a blob storage?</p>  <p>Can you give an example for concrete implementation?</p>""",azure-functions
43990866,"How to check if an Azure VM is running at a specific time via some kind of alert? <p>I would like to know how to create an alert for an Azure VM which tells me if the server(s) is running at a specific time.</p>  <p>The scenario: Servers for the Azure network need to start at 7:30am to be ready for the users as they shut down at 7:30pm each day to save $$. Today the azure automation script could not find any vms for the resource group! So that meant the servers where not started. I want to create an alert that will only tell me if the server(s) are not running at say 7:45am. So I can start them.  <em>(Running the script now does find all of the servers now but didn't before for some reason... maybe Azure was moving the vms in the resource group?)</em></p>  <p>I have looked at: - Microsoft Operations Management Suit > Log Search > Add Alert Rule. - Resource Manager > Virtual Machines > Monitoring > Alert Rules > Add metic alert &amp; Add activity log alert. But I can't see where to only run the alert at a specific time.</p>  <p><strong>Update/Edit:</strong> Script used:</p>  <pre><code>param (      [Parameter(Mandatory=$false)]       [String]$AzureCredentialAssetName = 'AzureCred'        [Parameter(Mandatory=$false)]       [String]$AzureSubscriptionIDAssetName = 'AzureSubscriptionId' )   # Setting error and warning action preferences  $ErrorActionPreference = \SilentlyContinue\""  $WarningPreference = \""SilentlyContinue\""   # Connecting to Azure  $Cred = Get-AutomationPSCredential -Name $AzureCredentialAssetName -ErrorAction Stop  $null = Add-AzureAccount -Credential $Cred -ErrorAction Stop -ErrorVariable err  $null = Add-AzureRmAccount -Credential $Cred -ErrorAction Stop -ErrorVariable err   # Selecting the subscription to work against  $SubID = Get-AutomationVariable -Name $AzureSubscriptionIDAssetName  Select-AzureRmSubscription -SubscriptionId $SubID   # Getting all resource groups  $ResourceGroup = \""Servers\""  # Getting all virtual machines  $RmVMs = (Get-AzureRmVM -ResourceGroupName $ResourceGroup -ErrorAction $ErrorActionPreference -WarningAction $WarningPreference).Name   # Managing virtual machines deployed with the Resource Manager deployment model \""Loop through all VMs in resource group $ResourceGroup.\"" if ($RmVMs)  {      foreach ($RmVM in $RmVMs)      {          \""`t$RmVM found ...\""          $RmPState = (Get-AzureRmVM -ResourceGroupName $ResourceGroup -Name $RmVM -Status -ErrorAction $ErrorActionPreference -WarningAction $WarningPreference).Statuses.Code[1]         if ($RmPState -eq 'PowerState/deallocated')          {              \""`t$RmVM is starting up ...\""              $RmSState = (Start-AzureRmVM -ResourceGroupName $ResourceGroup -Name $RmVM -ErrorAction $ErrorActionPreference -WarningAction $WarningPreference).IsSuccessStatusCode               if ($RmSState -eq 'True')              {                  \""`t$RmVM has been started.\""              }              else              {                  \""`t$RmVM failed to start.\""              }          }                    }  }      else {     \""No VMs for $ResourceGroup deployed with the Resource Manager deployment model.\""   } \""Runbook Completed.\"" </code></pre>  <p>I just want a fail safe to know if the servers are not running when they should be.</p>  <p>Expected output:</p>  <pre><code>Loop through all VMs in resource group Servers.      DOMAINCONTROLLER found ...      SQLSERVER found ...      GATEWAY found ...      APPLICATIONHOST found ...  Runbook Completed. </code></pre>  <p>instead of:</p>  <pre><code>Loop through all VMs in resource group Servers.  No VMs for Servers deployed with the Resource Manager deployment model.  Runbook Completed. </code></pre>  <p>I.e. rerunning the same script manually gave expected results.</p>""",azure-virtual-machine
17216584,Is it possible to have a webservice over an Azure Servicebus? <p>I have a virtual machine on Azure which will listen to messages over the servicebus of Azure. And another developer needs to connect to this servicebus to send messages to my service. To do so  we need to come up with some protocol for this communication system. And I was thinking about using WSDL to make the server something webservice-like  but instead of listening to the standard HTTP ports it would connect to the service bus and within it a topic with subscription  or whatever. I'm still not sure what would be best.  </p>  <p>So  is it possible? Has anyone done something similar before? Are there some examples?</p>,azure-virtual-machine
56560727,"Dependency Injection for Azure Functions V1 DI <p>I have a new issue regarding the <em>dependency injection in azure <strong>function v1</em></strong>.</p>  <p><em>Actual situation:</em></p>  <p>I have an azure <strong>function V1</strong> <code>http triggered</code> in which I want to reference my business services the way I can use my services without reinventing the wheel. I searched on the internet and I found this interesting <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-dotnet-dependency-injection\"" rel=\""nofollow noreferrer\"">article</a>  from Microsoft.</p>  <p>However  it seems like it only works with <strong>azure function v2</strong> (.net core) because whenever I try to install the  <code>Microsoft.Azure.Functions.Extensions</code>  I always get the following error : </p>  <blockquote>   <p>NU1107    Version conflict detected for Microsoft.Azure.WebJobs.   Install/reference Microsoft.Azure.WebJobs 3.0.5 directly to project   FunctionApp2365431 to resolve this issue.  FunctionApp2365431 ->   Microsoft.Azure.Functions.Extensions 1.0.0 -> Microsoft.Azure.WebJobs   (>= 3.0.5)  FunctionApp2365431 -> Microsoft.NET.Sdk.Functions 1.0.28   -> Microsoft.Azure.WebJobs (>= 2.2.0 &amp;&amp; &lt; 2.4.0)</p> </blockquote>  <p>Following  a comparison between the dlls of two project (one in .net core (in which i could implement DI) and the other in Net framework 461)</p>  <p><a href=\""https://i.stack.imgur.com/3vveh.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/3vveh.png\"" alt=\""Comparison\""></a></p>  <p>You can see that versions are different  the .net core <strong>V2 azure function is 3.5</strong> and the <strong>V1 is 2.2</strong></p>  <p>I tried to <strong>reference/install manually</strong> the package version as asked in the error  and I was asked to update NewtonSoft.Json package too  I did that too  and I could after that force the installation of the <code>Microsoft.Azure.Functions.Extensions</code> <strong>BUT </strong> it broke the project and I <strong>couldn’t stop getting errors</strong>.</p>  <p>Here is the build result after doing the steps mentioned above:</p>  <p><a href=\""https://i.stack.imgur.com/ojO9h.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ojO9h.png\"" alt=\""Build errors\""></a></p>  <p>My question here is   How can I setup <strong>DI in Net framework project eg. For Azure functions V1</strong>?</p>  <p>Then  Why there <strong>is only documentation for azure function V2 to setup DI</strong>? </p>  <p>Are V1 deprecated or is Microsoft not supporting the V1 azure functions anymore?Because this is weird!</p>  <p>Thanks in advance </p>  <p><strong>EDIT</strong> : My question is not a duplicate of this <a href=\""https://stackoverflow.com/questions/45912224/di-in-azure-functions\"">StackOverFlow thread</a> because it's a complicated way and outdated comparing to the solution that Microsoft is providing for v2 azure functions.</p>  <p>I also watched this interesting <a href=\""https://www.youtube.com/watch?v=ZsNSf5TG4yc\"" rel=\""nofollow noreferrer\"">video</a> (still didn't test it)  and the only problem here is that i want to use something provided by Microsoft (official) as for az func v2  and not the package that he has developed.</p>""",azure-functions
49851795,Move files from Azure Storage blob to an Ftp server <p>I need to upload a few files from Azure Storage to  an external Ftp server. </p>  <p>Is there any way with Azure to uplodad these files directly without download them before ? </p>,azure-storage
19583608,"Azure Storage browsing client software options <p>As far as I know  these are the only clients available to browse Azure Table Storage  Queues and Blobs:</p>  <ul> <li><a href=\http://msdn.microsoft.com/en-us/library/windowsazure/ff683677.aspx\"">Visual Studio Server Explorer</a>:  This is great  but we need standalone software (for testers  analysts  etc.)</li> <li><a href=\""http://www.cerebrata.com/labs/azure-explorer\"">Cerebrata Azure Explorer</a>: $125 per license. We cannot afford this as of yet.</li> <li><a href=\""http://clumsyleaf.com/products/cloudxplorer\"">CloudXplorer</a>: $50 per license. We cannot afford this as of yet.</li> <li><a href=\""http://clumsyleaf.com/products/tablexplorer\"">TableXplorer</a>: Free but very limited (also no queue or blob storage)</li> <li><a href=\""http://azurestorageexplorer.codeplex.com/\"">Azure Storage Explorer 4</a>:  Many people suggest this but I find it to be very poorly written. </li> <li><a href=\""http://azurestorageexplorer.codeplex.com/\"">Azure Storage Explorer 5</a>:  Still in preview.</li> </ul>  <p>Are there any other clients out there that I am unaware of?</p>""",azure-storage
56855931,push updates from azure to github <p>i am new to azure devops and facing problem to integrate between azure devops and github  may be you could help. my question is how can i push commits that are done on the azure devop repo to corresponding repo which resides on my github account?</p>  <p>For example: 1)i import a file abc.py from github private repo 2)i make changes to abc.py in azure devops repo and commits it. 3)now all the commits i made to abc.py on master branch of azure repo should be pushed to abc.py of master branch in my private github repo from where it was previously imported.</p>  <p>thanks for your help.</p>,azure-devops
45354889,"clustering node on iisnode using nodeProcessCountPerApplication <p>I have a web app in Azure which is using node.js and socket.io  and I decided to use the clustering supported by IISNODE  using nodeProcessCountPerApplication as below in my web.config</p>  <pre><code>&lt;iisnode nodeProcessCountPerApplication=\0\"" /&gt; </code></pre>  <p>However  when I apply this  I got 500.1013 internal server error  which states:</p>  <blockquote>   <p>Most likely causes:   IIS received the request; however  an internal error occurred during the processing of the request. The root cause of this error depends on which module handles the request and what was happening in the worker process when this error occurred.   IIS was not able to access the web.config file for the Web site or application. This can occur if the NTFS permissions are set incorrectly.   IIS was not able to process configuration for the Web site or application.   The authenticated user does not have permission to use this DLL.   The request is mapped to a managed handler but the .NET Extensibility Feature is not installed.</p> </blockquote>  <p>I looked for examples but couldn't find anything similar. I am wondering what I am doing wrong here. I want to be able to use all processors of my machine.  Thanks !</p>""",azure-web-app-service
52446562,Is there a way do undo pipeline deletion in VSTS? <p>After a release pipeline is deleted  is there a way to undo that deletion? One of our critical pipelines was deleted and while we had backed up the definition  it would be nice to know if Azure DevOps has the undo functionality built in. </p>,azure-devops
57035835,"Azure Functions: how to efficiently send batch of messages to Service Bus using bindings? <p>I'm working with Azure Functions 2.0 and trying to send a collection of messages to Azure Service Bus Topic. Currently I'm using <code>IAsyncCollector&lt;T&gt;</code> as output binding :</p>  <pre><code>[FunctionName(\MyFunction\"")] public static async Task MyFunction([ServiceBus(MyTopicName  EntityType.Topic  Connection = ServiceBusConnection) outTopic]) {     var messages = await GetMessages();     foreach(var message in messages)     {         await outTopic.AddAsync(message);     } } </code></pre>  <p>Such approach is pretty convenient (declarative code  no boilterplate) but brings one significant issue: for large number of messages the performance is unacceptable. Is there any other recommended way to work with large batches that need to be sent to Azure Service Bus ?</p>""",azure-functions
43946750,"duplicate herocard response in proactive bot <p>I want to display an api response as a card  but the response duplicates - what am I doing wrong  is this a valid use of for hero card?</p>  <pre><code>bot.dialog('/receipt'  [     function(session){         bot.on('trigger'  function (message) {         var queuedMessage = message.value;         var msg = new builder.Message()              .address(queuedMessage.address)              .attachments([                 new builder.HeroCard(session)                     .title(\Good news - I can book this for you:\"")                     .subtitle(\""Customer: \"" + queuedMessage.name)                     .images([                         builder.CardImage.create(session  \""\"")                     ])                     .buttons([                         builder.CardAction.dialogAction(session  \""bookIt\""  \""\""  \""Book it?\"")                          builder.CardAction.dialogAction(session  \""help\""  \""\""  \""Start again?\"")             ])             ]);             session.send(msg);         })     }    ]); </code></pre>""",azure-functions
44898939,In VSTS  How to constraint/restrict a team member's working capacity in case working in multiple projects <p>Assume a team member A works with multiple projects/applications(P1 P2 P3). While doing Capacity planning  i'm able to allocate him with 8hrs per day in each project(P1 P2 P3). Is there any availability to freeze/constraint a team member's capacity to 8hrs in all projects combined(capacity should be restricted to 8hrs in combined). Any provision to create such a rule/restriction on account level?</p>,azure-devops
57477342,"Azure function to convert encoded json IOT Hub data to csv on azure data lake store <p>I have simulated devices which is sending messages to IoT Hub blob storage and from there I am copying data(encoded in JSON format) to Azure Data Lake Gen2 by creating a pipeline using Azure Data Factory.</p>  <p>How to convert these json output file to CSV file using Azure function and store it again on Azure Data Lake Store.</p>  <hr>  <p>@Adam </p>  <p>Thank You so much for your all the answer and I implemented those successfully in my azure account. But  this does not actually given me the desired output which I was looking for.</p>  <p>Hope this make things clear and my requirement.</p>  <p>My Input file which sent to IOT Hub is:-</p>  <p><a href=\https://i.stack.imgur.com/mmKJN.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/mmKJN.png\"" alt=\""enter image description here\""></a></p>  <p>Below is the sample records of the data which is stored in IOT Hub endpoints(Blob Storage):- (Json - Set of Objects):-</p>  <blockquote>   <p>{\""EnqueuedTimeUtc\"":\""2019-08-06T10:46:39.4390000Z\"" \""Properties\"":{\""$.cdid\"":\""Simulated-File\""} \""SystemProperties\"":{\""messageId\"":\""d48413d2-d4d7-41bb-9470-dc0483466253\"" \""correlationId\"":\""a3062fcb-5513-4c09-882e-8e642f8fe38e\"" \""connectionDeviceId\"":\""Simulated-File\"" \""connectionAuthMethod\"":\""{\\\""scope\\\"":\\\""device\\\"" \\\""type\\\"":\\\""sas\\\"" \\\""issuer\\\"":\\\""iothub\\\"" \\\""acceptingIpFilterRule\\\"":null}\"" \""connectionDeviceGenerationId\"":\""637001643970703748\"" \""contentType\"":\""UTF-8\"" \""enqueuedTime\"":\""2019-08-06T10:46:39.4390000Z\""} \""Body\"":\""eyIiOiI1OCIsInJvdGF0ZSI6IjQ2Mi4wMjQxODE3IiwiZGF0ZXRpbWUiOiIxLzMvMjAxNSAxNjowMCIsIm1hY2hpbmVJRCI6IjEiLCJ2b2x0IjoiMTU2Ljk1MzI0NTkiLCJwcmVzc3VyZSI6IjEwNi4zNDY3MTc5IiwidmlicmF0aW9uIjoiNDguODIwMzAwODYifQ==\""}</p>      <p>{\""EnqueuedTimeUtc\"":\""2019-08-06T10:46:40.5040000Z\"" \""Properties\"":{\""$.cdid\"":\""Simulated-File\""} \""SystemProperties\"":{\""messageId\"":\""9da638d9-fdba-41d3-86df-3ea6cedc44e7\"" \""correlationId\"":\""aeb20305-6fee-4a59-9053-5fa1d0c780a9\"" \""connectionDeviceId\"":\""Simulated-File\"" \""connectionAuthMethod\"":\""{\\\""scope\\\"":\\\""device\\\"" \\\""type\\\"":\\\""sas\\\"" \\\""issuer\\\"":\\\""iothub\\\"" \\\""acceptingIpFilterRule\\\"":null}\"" \""connectionDeviceGenerationId\"":\""637001643970703748\"" \""contentType\"":\""UTF-8\"" \""enqueuedTime\"":\""2019-08-06T10:46:40.5040000Z\""} \""Body\"":\""eyIiOiI1OSIsInJvdGF0ZSI6IjQyOS44MjIxNDM1IiwiZGF0ZXRpbWUiOiIxLzMvMjAxNSAxNzowMCIsIm1hY2hpbmVJRCI6IjEiLCJ2b2x0IjoiMTY0LjE0ODA5NDYiLCJwcmVzc3VyZSI6IjEwNC41MzIxMjM2IiwidmlicmF0aW9uIjoiNDMuNzg4NjgxNTUifQ==\""}</p> </blockquote>  <p>**The Json \""Body\"" field contains the actual IOT device data  which is encoded in JSON format with some system and message properties.</p>  <p>**By creating pipeline to JSON to CSV  does not extract the actual data to Data Lake Store.</p>  <p>Output CSV is exact copy of the JSON file(real data is not extracted)after running the ADF pipeline.</p>  <p>[![enter image description here][2]][2]</p>  <blockquote>   <p><a href=\""https://i.stack.imgur.com/mmKJN.png\"" rel=\""nofollow noreferrer\"">1</a>: <a href=\""https://i.stack.imgur.com/iCBvi.png\"" rel=\""nofollow noreferrer\"">https://i.stack.imgur.com/iCBvi.png</a></p>      <p>[2]: <a href=\""https://i.stack.imgur.com/HaBMn.png\"" rel=\""nofollow noreferrer\"">https://i.stack.imgur.com/HaBMn.png</a></p> </blockquote>  <p><code>using System.Net; using System.Text; using Microsoft.Azure.WebJobs; using Microsoft.Extensions.Logging;</code></p>  <p>namespace BlobTrigger {     public static class ExtractJson     {         [FunctionName(\""BlobTriggerCSharp\"")]<br>         public static void Run(             [BlobTrigger(\""blobcontainer/{name}\"")] Stream myBlob               [Blob(\""bloboutput/{name}\"")  FileAccess.Write] Stream outputBlob             string name  ILogger log)         {             // var len = myBlob.Length;             // myBlob.CopyTo(outputBlob);</p>  <pre><code>        // parse JSON with JsonConvert          var jsonObject = JObject.Parse(myBlob);          var frequency = jsonObject.SelectToken(\""metadata.frequency\"").ToString();          var rssi = jsonObject.SelectToken(\""metadata.gateways[0].rssi\"").ToString();          foreach (var p in jsonObject) // properties         {             Console.WriteLine(p.Key);  // eg. port             Console.WriteLine(p.Value.Type); // eg. integer         }          var port = Convert.ToInt32(jsonObject.SelectToken(\""port\"").ToString());         // parse using base64 decode from SystemProperties.contentType field         var base64EncodedBytes = System.Convert.FromBase64String(SystemProperties.contentType);         return System.Text.Encoding.UTF8.GetString(base64EncodedBytes);          // write parsed output to outputBlob stream      } } </code></pre>  <p>}</p>  <p><a href=\""https://i.stack.imgur.com/mmKJN.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/mmKJN.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
19599819,"Azure Blob 400 Bad request on Creation of container <p>I'm developing an ASP.Net MVC 4 app and I'm using Azure Blob to store the images that my users are going to upload.  I have the following code:</p>  <pre><code> var storageAccount = CloudStorageAccount.Parse(ConfigurationManager.ConnectionStrings[\StorageConnection\""].ConnectionString);   var blobStorage = storageAccount.CreateCloudBlobClient();  //merchantKey is just a GUID that is asociated with the merchant  var containerName = (\""ImageAds-\"" + merchant.merchantKey.ToString()).ToLower();  CloudBlobContainer container = blobStorage.GetContainerReference(containerName);  if (container.CreateIfNotExist())     {        //Upload the file     }  </code></pre>  <p>as soon as the if statement is excecuted I'm getting the following exception:</p>  <pre><code>  {\""The remote server returned an error: (400) Bad Request.\""} </code></pre>  <p>I thought it was the container's name but I don't see anything wrong with it. The connection string seems to create a good storage with all details for the blob. I'm at a loss. I've researched the web and everyone is saying it's a naming problem but I can't find anything wrong with it.</p>  <p>Test Container name that I used:  <code>imageads-57905553-8585-4d7c-8270-be9e611eda81</code></p>  <p>The Container has the following uri: <code>{http://127.0.0.1:10000/devstoreaccount1/imageads-57905553-8585-4d7c-8270-be9e611eda81}</code></p>  <p><strong>UPDATE:</strong>  I have changed the container name to just <code>image</code> and I still get the same exception. also the development connection string is as follows: <code>&lt;add name=\""StorageConnection\"" connectionString=\""UseDevelopmentStorage=true\"" /&gt;</code></p>""",azure-storage
53443880,"CallerFilePathAttribute not returning file path with valid directory separators on azure's linux container app service <p>I have the following method in a  netcore2.1 web app:</p>  <pre><code>public static void Information(string message  [CallerFilePath] string filePath = \\"") {     var fileNameWithoutExtn = Path.GetFileNameWithoutExtension(filePath);     . . . } </code></pre>  <p>When running on azure app service (windows host) it behaves as expected:</p>  <blockquote>   <p>filePath =   C:\\web\\src\\production\\MyWebsite\\Controllers\\ChallengeController.cs</p>      <p>fileNameWithoutExtn = ChallengeController</p> </blockquote>  <p><br><br> But  when I run this on azure's linux container app service:</p>  <blockquote>   <p>filePath =   C:\\web\\src\\production\\MyWebsite\\Controllers\\ChallengeController.cs</p>      <p>fileNameWithoutExtn  =   C:\\web\\src\\production\\MyWebsite\\Controllers\\ChallengeController</p> </blockquote>  <p>And</p>  <blockquote>   <p>Path.DirectorySeparatorChar = /</p>      <p>Path.AltDirectorySeparatorChar = /</p>      <p>Path.PathSeparator = :</p>      <p>Path.VolumeSeparatorChar = / </p> </blockquote>  <p>Why is CallerFilePath giving me a path which does not match with DirectorySeparatorChar or AltDirectorySeparatorChar  ?</p>  <p>PS: I posted the same in <a href=\""https://social.msdn.microsoft.com/Forums/en-US/1923fe26-2ff9-4f33-bfa4-60dbe71fd252/callerfilepathattribute-not-returning-file-path-with-valid-directory-seperators-on-azures-linux\"" rel=\""nofollow noreferrer\"">msdn forum</a> but did not get any response  hence posting here. I will update here if I hear there.</p>""",azure-web-app-service
50275510,"How Often Is The Azure Functions Beta Host Updated on the Azure Portal <p>I'm using the Azure Functions v2 in a project that I've started recently and I'm trying to use a proxy to redirect a request to /.well-known to one of my functions.</p>  <p>Proxies do not work on Azure Functions v2 (<a href=\https://github.com/Azure/azure-functions-host/wiki/Azure-Functions-runtime-2.0-known-issues\"" rel=\""nofollow noreferrer\"">as stated here</a>). They have now been fixed in release <a href=\""https://github.com/Azure/azure-functions-host/releases/tag/v2.0.11737-alpha\"" rel=\""nofollow noreferrer\"">v2.0.11737-alpha</a> but the Azure Portal is still using <a href=\""https://github.com/Azure/azure-functions-host/releases/tag/v2.0.11651-alpha\"" rel=\""nofollow noreferrer\"">v2.0.11651.0</a></p>  <p>Does anyone know how long it takes after a beta release is created in GitHub for it to be available in the Azure portal?</p>""",azure-functions
36064904,"How to run Azure VM CustomScriptExtension as domain user? (part 2) <p><strong>Updated</strong> to explain my root problem: If Azure has extensions for VM's  <em>as they are being provisioned</em>  to join a domain  and to run scripts  <em>how can I run a script as a domain user?</em></p>  <p>The script needs to be run as a domain user in order to access a file share to retrieve installation files and other scripts that are neither part of the VM template image nor can (reasonably) be uploaded to Azure blob storage and downloaded as part of provisioning.</p>  <p>I split <a href=\https://stackoverflow.com/questions/35992329\"">this question</a> in two because the 2nd half (represented here) didn't get solved.</p>  <p>What I have working is a Powershell script that takes a JSON file to create a new VM; the JSON file contains instructions for the VM to join a domain and run a custom script. Both things do happen  but the script runs as the user <code>workgroup\\system</code> and therefore doesn't have access to a network drive.</p>  <ul> <li>How can I best provide a specific user's credentials for such a script?</li> </ul>  <p>I'm trying to have the script spawn a new Powershell session with the credentials of a different user  but I'm having a hard time figuring out the syntax -- I can't even get it to work on my development workstation. Naturally  security is a concern but if I could get this to work using encrypted stored credentials  this might be acceptable.</p>  <p>... but don't limit your answers -- maybe there's an <em>entirely</em> different way to go about this and achieve the same effect?</p>  <pre><code>Param(     [switch]$sudo  # Indicates we've already tried to elevate to admin     [switch]$su # Indicates we've already tried to switch to domain user )  try {      # Pseudo-constants     $DevOrProd=(Get-Item $MyInvocation.MyCommand.Definition).Directory.Parent.Name     $PsScriptPath = Split-Path -parent $MyInvocation.MyCommand.Definition     $pathOnPDrive = \""\\\\dkfile01\\P\\SoftwareTestData\\Azure\\automation\\$DevOrProd\\run-once\""     $fileScriptLocal = $MyInvocation.MyCommand.Source     $fileScriptRemote = \""$pathOnPDrive\\run-once-from-netdrive.ps1\""     # $filePw = \""$pathOnPDrive\\cred.txt\""     $fileLog=\""$PsScriptPath\\switch-user.log\""     $Myuser=\""mohican\""     $Myuserpass=\""alhambra\""     $Mydomainuser=\""mydomain\\$Myuser\""     $Mydomain=\""mydomain.com\""      # Check variables     write-output(\""SUDO=[$SUDO]\"")     write-output(\""SU=[$SU]\"")      # Functions     function Test-Admin {       $currentUser = New-Object Security.Principal.WindowsPrincipal $([Security.Principal.WindowsIdentity]::GetCurrent())       return ($currentUser.IsInRole([Security.Principal.WindowsBuiltinRole]::Administrator))     }      # Main     write-output(\""Run-once script starting ...\"")      # Check admin privilege     write-output(\""Checking admin privilege ...\"")     if (Test-Admin) {         write-output(\""- Is admin.\"")     } else {         write-output(\""- Not an admin.\"")         if ($sudo) {             write-output(\""  - Already tried elevating  didn't work.\"")             write-output(\""Run-once script on local VM finished.\"")             write-output(\""\"")             exit(0) # Don't return failure exit code because Azure will report it as if the deployment broke...         } else {             write-output(\""  - Attempting to elevate ...\"")             $arguments = \""-noprofile -file $fileScriptLocal\""             $arguments = $arguments +\"" -sudo\""             try {                 Start-Process powershell.exe -Verb RunAs -ArgumentList $arguments                 write-output(\""    - New process started.\"")             } catch {                 write-output(\""    - New process failed to start.\"")             }             write-output(\""Run-once script on local VM finished.\"")             write-output(\""\"")             exit(0) # The action will continue in the spawned process         }     }     write-output(\""Checked admin privilege ... [OK]\"")      # Check current user     write-output(\""Checking user account ...\"")     $hostname = $([Environment]::MachineName).tolower()     $domainname = $([Environment]::UserDomainName).tolower()     $thisuser = $([Environment]::UserName).tolower()     write-output(\""- Current user is \""\""$domainname\\$thisuser\""\"" on \""\""$hostname\""\"".\"")     write-output(\""- Want to be user \""\""$Myuser\""\"".\"")     if ($Myuser -eq $thisuser) {         write-output(\""  - Correct user.\"")     } else {         write-output(\""  - Incorrect user.\"")         if ($su) {             write-output(\""  - Already tried switching user  didn't work.\"")             write-output(\""Run-once script on local VM finished.\"")             write-output(\""\"")             exit(0) # Don't return failure exit code because Azure will report it as if the deployment broke...         } else {             write-output(\""  - Attempting to switch to user \""\""$Mydomainuser\""\"" with passwond \""\""$Myuserpass\""\"" ...\"")             # FIXME -- This does not work... :-(             $MyuserpassSecure = ConvertTo-SecureString $Myuserpass -AsPlainText -Force             $credential = New-Object System.Management.Automation.PSCredential $Mydomainuser  $MyuserpassSecure             $arguments = \""-noprofile -file $fileScriptLocal\""             $arguments = $arguments +\"" -sudo -su -Credential $credential -computername $hostname\""             try {                 Start-Process powershell.exe -Verb RunAs -ArgumentList $arguments                 write-output(\""    - New process started.\"")             } catch {                 write-output(\""    - New process failed to start.\"")             }             write-output(\""Run-once script on local VM finished.\"")             write-output(\""\"")             exit(0) # The action will continue in the spawned process         }     }     write-output(\""Checked user account ... [OK]\"")      # Run script from P: drive (finally!)     write-output(\""Attempting to run script from P: drive ...\"")     write-output(\""- Script file: \""\""$fileScriptRemote\""\""\"")     if (test-path $fileScriptRemote) {         write-output(\""Running script from P: drive ...\"")         $arguments = \""-noprofile -file $fileScriptRemote\""         try {             Start-Process powershell.exe -Verb RunAs -ArgumentList $arguments             write-output(\""    - New process started.\"")         } catch {             write-output(\""    - New process failed to start.\"")         }         write-output(\""Run-once script on local VM finished.\"")         write-output(\""\"")         exit(0) # The action will continue in the spawned process     } else {         write-output(\""- Could not locate/access script file!\"")         write-output(\""Ran script from P: drive ... [ERROR]\"")     }      write-output(\""Run-once script on local VM finished.\"")     write-output(\""\"")  } catch {     write-warning(\""Unhandled error in line $($_.InvocationInfo.ScriptLineNumber): $($error[0])\"")     write-output(\""ABEND\"")     write-output(\""\"") } </code></pre>""",azure-virtual-machine
53309468,TFS to Azure DevOps Migration <p>I am undergoing the process of going from a very old TFS to Azure DevOps.  There is a consideration whether to use TFVC or GIT.  I used the git tfs deep clone feature to create a repo and it was about 3 GB.  Does that mean the repo is too large to use as a git repo?  If I cannot logically break it into smaller repos  does this mean I have to continue using TFVC instead?</p>,azure-devops
53559981,Event Hub Connection Pooling <p>I have an azure function that is receiving some payloads from a service  doing some basic operations on it and then forwarding it to an event hub. The solution works fine  but there are spikes in latency occurring quite often(every 10 minutes or so).</p>  <p>My initial assumption was that this is because of the high cost on creating an event hub connection  so I proceeded to creating a simple pooling class that can create multiple resources. That has led to some improvements  but because of the inconsistent nature of the stream  I still face issues when there are spikes in usage.</p>  <p>Looking at the event hub logs  I can see that the connections get closed after 5 minutes. Is there any way of keeping the connection alive for longer. The access method for the pool is FIFO  so being able to keep the connections alive for just a small amount longer would allow me to cycle trough more of them and as a result be better prepared for the spikes in the stream. I have being going trough Microsoft's documentation for Event Hub and I can't see any setting or way of keeping the connection alive for longer.</p>  <p>Any help would be greatly appreciated.</p>,azure-functions
57512171,"azure virtual machine linux diagnostic agent unable to find its event hub <p>I'm tasked by my company to integrate \azure audit logs\"" for some of important services e.g virtual machine and azure activity logs. </p>  <p>I'm new to whole azure technology  and i'm doing my best to get it done.</p>  <p>So far I have setup   \""virtual machine linux diagnostic agent\"" using </p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/virtual-machines/extensions/diagnostics-linux\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/virtual-machines/extensions/diagnostics-linux</a></p>  <p>The output in json is given in link here</p>  <p><a href=\""https://jmp.sh/Xbs1SXg\"" rel=\""nofollow noreferrer\"">https://jmp.sh/Xbs1SXg</a></p>  <p>My objective is to get those events read / process by \""event hubs\"". In the JSON  i see now mention of \""sinks\"" or \""eventhub\"" entry. I don't know where this data is shipped.</p>  <p>for e.g</p>  <pre><code>\""sink\"": [     {         \""name\"": \""sinkname\""          \""type\"": \""EventHub\""          \""sasURL\"": \""https SAS URL\""     }      ... ] </code></pre>  <p>Where and how can i use this? because in my json i don't see this code block.</p>  <p>I have created  a event-hub workspace and instance  but I don't know how to connect the two. </p>  <p>I'm attaching some of errors  I'm getting on \""export template tab\"".</p>  <p><a href=\""https://i.stack.imgur.com/x5z54.png\"" rel=\""nofollow noreferrer\"">export template error</a> <a href=\""https://i.stack.imgur.com/NuiHS.png\"" rel=\""nofollow noreferrer\"">export template error 2</a></p>""",azure-virtual-machine
31415705,Windows Azure behind NATed router <p>I am working on a project and am attempting to run a FTP daemon on an azure vm running the Technical Preview 2.  The Daemon reports that it is behind a NATed router  and as such I can not connect in via another means but the remote desktop connection. (I will be running other daemons on this server as well  and they also have this problem)</p>  <p>I need some way to access this router that my Azure server is behind to configure it to allow for the range of ports that i need to access.</p>  <p>The fine folks at MVA instructed me to ask here  so here I am.</p>,azure-virtual-machine
48914632,Azure Application SQL Database slow spin up time <p>I've got a little bit problematic task at work  maybe someone will be able to help.</p>  <p>We've got <strong>two identical</strong> applications running on Azure AppService. Both using Standard (S1) AppService  both using S2 Azure SQL Databases.</p>  <p>They're really identical  two apps running for different clients  doing the same things  using identical db-schema  which we have checked two times  manually and automatically via Visual Studio 2017 schema comparer.</p>  <p>Problem appears when we try to run app2 using db2. App1 with db1 works fine  App2 with db1 also works fine. App1 with db2 needs 10 seconds to handle ANY request  same for App2 with db2.</p>  <p>But... Both db's have the same schema  are hosted on (basically) the same logical Azure server  sharing exactly the same configuration. Even if it was for performance issues - db2 has less data in it  so should be even faster (single table diff of 746k vs 1.6k records)</p>  <p>We have exhausted basically every option available  we tried:</p>  <ul> <li>Recreating and redeploying the app on different AppServices and AppService sizes  with the same result</li> <li>Recreating and redeploying SQL Database to new/another SQL Server inside Azure  even with upgrade from S2 to P2 performance</li> <li>Running app locally with debugger on to see what's going on - the same result ~10.1s of spin up time for every request.</li> </ul>  <p>I couldn't find anything responsible for it  either in Azure infrastructure or Application itself (app1/db1 pair works fine).</p>  <p>Any input is greatly appreciated.</p>,azure-web-app-service
11720243,"How is Geo Redundant Storage charged on Microsoft Azure? <p>SO I have been using the azure 3 month trial  to test out whether I want to use Microsoft Azure to host a project I am working on  however I have been very confused as I have run out of \Geo Redundant Storage\"" in the first month and I don't really understand why.</p>  <p>I have read this: <a href=\""https://www.windowsazure.com/en-us/pricing/details/\"" rel=\""nofollow noreferrer\"">https://www.windowsazure.com/en-us/pricing/details/</a> and the only thing I can make of it  is that it takes an average of how much storage you are using across a month  eg as long as I am using less then 35gb (for a 35gb limit) on average of storage space I am in the clear. </p>  <p>So under my Azure Subscriptsions 'STORAGE (GB/MONTH) - GEO REDUNDANT' it says '101.027% of 35 GB/month' (so I have reached my cap).</p>  <p>But I don't understand why this would be happening  all I have is a simple server with a nodejs web application and a redis database (pretty much an empty at the moment)  all running on an ubuntu VM  and as I can't login and check storage now because it is disabled  but I am pretty sure it is nowhere <strong><em>even near</em></strong> 35gb total storage and never has been?</p>  <p>I am hoping someone can explain how the azure storage is charged or if I have missed something silly? </p>  <p><strong>Edit:</strong> It just hit me that it could be redis  doing crazy things with IO? not sure if this is possible  but if it is  would I be better to use locally redundant storage and pay for locally redundant storage transactions?</p>  <p><strong>Edit 2:</strong> On my graph it says I had been using 1.96gb / day. So that means its not the total harddrive space per month  is it harddrive space / day? (using 2gbs of data probably sounds about right with the OS included  if this is the case  that means they give you less then 2gb space on the trial  seems minute??)</p>  <p><img src=\""https://i.stack.imgur.com/1felR.png\"" alt=\""Azure Disk Usage Chart\""> </p>""",azure-storage
54922750,"delete specific resource i.e  vm nic nsg using terraform <p>I have created azure vm  nic  nsg inside the firewall. Now i need to delete specific created vm nic nsg inside the firewall. This i will be doing continuously.</p>  <p>When i try i delete with specific vm ns nic with below  but it is deleting total resource group.</p>  <pre><code>terraform init terraform apply -no-color -auto-approve terraform destroy -force </code></pre>  <p>My code:</p>  <pre><code># Configure the Microsoft Azure Provider provider \azurerm\"" {     subscription_id = \""xxxxx\""     client_id       = \""xxxxx\""     client_secret   = \""xxxxx\""     tenant_id       = \""xxxxx\"" }  # Locate the existing custom/golden image data \""azurerm_image\"" \""search\"" {   name                = \""AZLXSPTDEVOPS01_Image\""   resource_group_name = \""RG-EASTUS-SPT-PLATFORM\"" }  output \""image_id\"" {   value = \""/subscriptions/xxxxxxx/resourceGroups/RG-EASTUS-SPT-PLATFORM/providers/Microsoft.Compute/images/AZLXSPTDEVOPS01_Image\"" }  # Create a Resource Group for the new Virtual Machine. resource \""azurerm_resource_group\"" \""main\"" {   name     = \""RG-PF-TEST\""   location = \""eastus\"" }  # Create a Subnet within the Virtual Network resource \""azurerm_subnet\"" \""internal\"" {   name                 = \""SNET-IN\""   virtual_network_name = \""VNET-PFSENSE-TEST\""   resource_group_name  = \""${azurerm_resource_group.main.name}\""   address_prefix       = \""192.168.2.0/24\"" }  # Create a Network Security Group with some rules resource \""azurerm_network_security_group\"" \""main\"" {   name                = \""RG-Dev-NSG\""   location            = \""${azurerm_resource_group.main.location}\""   resource_group_name = \""${azurerm_resource_group.main.name}\""    security_rule {     name                       = \""allow_SSH\""     description                = \""Allow SSH access\""     priority                   = 100     direction                  = \""Inbound\""     access                     = \""Allow\""     protocol                   = \""Tcp\""     source_port_range          = \""*\""     destination_port_range     = \""22\""     source_address_prefix      = \""*\""     destination_address_prefix = \""*\""   } }  # Create a network interface for VMs and attach the PIP and the NSG resource \""azurerm_network_interface\"" \""main\"" {   name                      = \""NIC-Dev\""   location                  = \""${azurerm_resource_group.main.location}\""   resource_group_name       = \""${azurerm_resource_group.main.name}\""   network_security_group_id = \""${azurerm_network_security_group.main.id}\""    ip_configuration {     name                          = \""primary\""     subnet_id                     = \""${azurerm_subnet.internal.id}\""     private_ip_address_allocation = \""static\""     private_ip_address            = \""192.168.2.6\""   } }  # Create a new Virtual Machine based on the Golden Image resource \""azurerm_virtual_machine\"" \""vm\"" {   name                             = \""AZLXSPTDEVOPS01\""   location                         = \""${azurerm_resource_group.main.location}\""   resource_group_name              = \""${azurerm_resource_group.main.name}\""   network_interface_ids            = [\""${azurerm_network_interface.main.id}\""]   vm_size                          = \""Standard_DS12_v2\""   delete_os_disk_on_termination    = true   delete_data_disks_on_termination = true    storage_image_reference {     id = \""${data.azurerm_image.search.id}\""   }    storage_os_disk {     name              = \""AZLXSPTDEVOPS01-OS\""     caching           = \""ReadWrite\""     create_option     = \""FromImage\""     managed_disk_type = \""Standard_LRS\"" }    os_profile {     computer_name  = \""APPVM\""     admin_username = \""devopsadmin\""     admin_password = \""admin#2019\""   }    os_profile_linux_config {     disable_password_authentication = false   } } </code></pre>  <p>I need to delete only specific vm nic and nsg .Could anyone help me please</p>""",azure-virtual-machine
39034354,"Azure VM Resource Deployment Failed: \The system is not authoritative for the specified account\"" <p>I have been using an Azure VM for several weeks: (Windows 10  Visual Studio Developer VM)  But have been unable to login for several hours. </p>  <p>The machine is reported as running  RDP finds the machine and presents the login box  but Login fails: (Your credentials did not work)</p>  <p>The VM can be restarted  but the same error occurs. Boot diagnostics shows the Windows 10 'beach cave' image</p>  <p>Attempts to reset the password give errors in the event log: </p>  <blockquote>   <p>Failed to reset password At lease one resource deployment operation   failed. Please list deployment operations for details. see   <a href=\""https://aka.ms/arm-debug\"" rel=\""nofollow\"">https://aka.ms/arm-debug</a> for usage details.</p> </blockquote>  <p>Then Deployment operations has this error:</p>  <blockquote>   <p>Deployment failed Deployment to resource group 'MY_AZURE_GROUP'   failed. Additional details from the underlying API that may be   helpful.  At least one deployment operation failed. Please list   deployment operations for details.</p> </blockquote>  <p>Then this error expands to:</p>  <p>Status: Conflict Provisioning State: Failed</p>  <p>Type: Microsoft.Compute/virtualMachines/extensions</p>  <p>StatusMessage:</p>  <pre><code>{   \""status\"": \""Failed\""    \""error\"": {     \""code\"": \""ResourceDeploymentFailure\""      \""message\"": \""The resource operation completed with terminal provisioning state 'Failed'.\""      \""details\"": [       {         \""code\"": \""VMExtensionProvisioningError\""          \""message\"": \""VM has reported a failure when processing extension 'enablevmaccess'. Error message: \\\""Cannot update Remote Desktop Connection settings for built-in Administrator account. Error: The system is not authoritative for the specified account and therefore cannot complete the operation. Please retry the operation using the provider associated with this account. If this is an online provider please use the provider's online site.\\r\\n\\\"".\""       }     ]   } } </code></pre>  <p>So I then tried Redeploying the VM: Which gave this error Failed to redeploy the virtual machine 'MY_AZURE_VM'. Error: VM has reported a failure when processing extension 'enablevmaccess'. Error message: \""Cannot update Remote Desktop Connection settings for built-in Administrator account. <strong>Error: The system is not authoritative for the specified account</strong> and therefore cannot complete the operation. Please retry the operation using the provider associated with this account. If this is an online provider please use the provider's online site.</p>  <p>The message \""<strong>The system is not authoritative for the specified account</strong>\"" hints at some permissions failure somewhere.</p>  <p>What does this mean - and how can I fix it?</p>""",azure-virtual-machine
54836251,"Azure Load Balancing Solution - Application Gateway or Azure Load Balancer <p><strong>Note</strong>: I'm still in learning phase.</p>  <p><strong>Question</strong>: For the scenario described below  in the <code>Load Balancing Settings</code> for the two <code>VMs</code> for the <code>FrontEnd subnet</code> should I choose <code>Application Gateway</code> or <code>Azure Load Balancer</code>?</p>  <p>In Azure portal  when I create the <code>VMs</code> for <code>FrontEnd</code>  the <code>Networking</code> tab of the wizard  gives me two choices shown below:</p>  <p><a href=\https://i.stack.imgur.com/JlPre.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/JlPre.png\"" alt=\""enter image description here\""></a></p>  <p><strong>Why the confusion</strong>:</p>  <p>For <code>Load Balancing Internet Traffic</code> to VMs  <a href=\""https://docs.microsoft.com/en-us/azure/load-balancer/tutorial-load-balancer-standard-manage-portal\"" rel=\""nofollow noreferrer\"">this tutorial</a> does not choose <code>Application Gateway</code>. But the 5th bullet of the following scenario seems to indicate I should choose <code>Application Gateway</code></p>  <p><strong>Scenario</strong></p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/virtual-machines/windows/infrastructure-example\"" rel=\""nofollow noreferrer\"">This</a> tutorial from official Azure team describes designing an infrastructure for a simple online store as follows:</p>  <p><a href=\""https://i.stack.imgur.com/3Ojno.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/3Ojno.png\"" alt=\""enter image description here\""></a></p>  <p>The above configuration incorporates:</p>  <ul> <li>A cloud-only virtual network with two subnets (FrontEnd and BackEnd)</li> <li>Azure Managed Disks with both Standard and Premium disks</li> <li>Four availability sets  one for each tier of the online store</li> <li>The virtual machines for the four tiers</li> <li>An external load balanced set for HTTPS-based web traffic from the Internet to       the web servers</li> <li>An internal load balanced set for unencrypted web traffic from the web servers to the application servers A single resource group</li> </ul>""",azure-virtual-machine
46750128,10 Inserts by 10 Threads at the same time in Azure table storage using c# <p>What will happen if I get responses from 10 threads and few of them simultaneously or at the same time  try to insert the responses in the table located in azure table storage. Will it break or throw error? If yes  how to handle that in c#?</p>,azure-storage
42366988,"Pass variables at queue time to build when triggered by continuous integration <p>In VSTS I have a build definition configured to use Continuous Integration. In this definition I defined some custom variables which are allowed to set at queue time. However  I only can set these variables when I manually trigger a build.</p>  <p>Is there a way to set <a href=\https://i.stack.imgur.com/InuLv.png\"" rel=\""nofollow noreferrer\"">these variables</a> each build when using Continuous Integration?</p>""",azure-devops
39833020,Multiple Azure Sql Databases with one Web App Instance <p>Hi I'm working on an application that has 200+ SQL Azure databases and one Web App instance.</p>  <p>The web application is frequently calling all these databases depending on the request (only one database connection is used per request).</p>  <p>The problem we have seen lately is that timeouts/other connectivity issues is happening more frequently.</p>  <p>I'm starting to think that it could be all the tcp/connections that needs to be maintained by the connection pool. Because of Azure SQL there will be one database connection per database in the pool  they can't share connection.</p>  <p>Is my assumption correct or could there be anything else?</p>,azure-web-app-service
54162952,Which is the default web server running on NodeJS based Azure Web App(Linux)? <p>Trying to deploy and access reactjs mono repo application on Azure WA.  Which is the default web server running on NodeJS based Azure Web App(Linux)? How fo I run node.js apps?</p>,azure-devops
56355802,"Terraform deploying azure function resulting in \FAILED TO DOWNLOAD ZIP FILE.txt\"" <p>Im trying to Deploy azure functions using terraform  but i keep getting just a file named \""FAILED TO DOWNLOAD ZIP FILE.txt\"" instead of actual function deployed.</p>  <p>It works if i paste the actual SAS blob string extracted from azure(from previous deployed storage account)  but the terraform script fails. the zip file seems to get deployed correctly to blob.</p>  <p>I pretty much copy pasted theis example here: <a href=\""http://vgaltes.com/post/deploying-azure-functions-using-terraform/\"" rel=\""nofollow noreferrer\"">http://vgaltes.com/post/deploying-azure-functions-using-terraform/</a></p>  <p>Im new to terraform so there may be something obvious im missing here...</p>  <pre><code> resource \""azurerm_resource_group\"" \""rg\"" {  name = \""myName\""  location = \""northEurope\"" }  resource \""random_string\"" \""storage_name\"" {  length = 16  special = false  upper = false } resource \""random_string\"" \""function_name\"" {  length = 16  special = false  upper = false } resource \""random_string\"" \""app_service_plan_name\"" {  length = 16  special = false }  resource \""azurerm_storage_account\"" \""storage\"" {  name = \""${random_string.storage_name.result}\""  resource_group_name = \""${azurerm_resource_group.rg.name}\""  location = \""${azurerm_resource_group.rg.location}\""  account_tier = \""Standard\""  account_replication_type = \""LRS\"" } resource \""azurerm_storage_container\"" \""storage_container\"" {  name = \""func\""  resource_group_name = \""${azurerm_resource_group.rg.name}\""  storage_account_name = \""${azurerm_storage_account.storage.name}\""  container_access_type = \""blob\"" }  resource \""azurerm_storage_blob\"" \""storage_blob\"" {  name = \""HelloWorld.zip\""  resource_group_name = \""${azurerm_resource_group.rg.name}\""  storage_account_name = \""${azurerm_storage_account.storage.name}\""  storage_container_name = \""${azurerm_storage_container.storage_container.name}\""  type = \""block\""  source = \""./../FunctionAppZip/HelloWorld.zip\"" } data \""azurerm_storage_account_sas\"" \""storage_sas\"" {  connection_string = \""${azurerm_storage_account.storage.primary_connection_string}\""  https_only = false resource_types {  service = false  container = false  object = true  } services {  blob = true  queue = true  table = true  file = true  } start = \""2019–05–21\""  expiry = \""2029–05–21\"" permissions {  read = true  write = true  delete = true  list = true  add = true  create = true  update = true  process = true  } }  resource \""azurerm_app_service_plan\"" \""plan\"" {  name = \""${random_string.app_service_plan_name.result}\""  location = \""${azurerm_resource_group.rg.location}\""  resource_group_name = \""${azurerm_resource_group.rg.name}\""  kind = \""functionapp\"" sku {  tier = \""Dynamic\""  size = \""Y1\""  } }  resource \""azurerm_function_app\"" \""function\"" {   name = \""${random_string.storage_name.result}\""   location = \""${azurerm_resource_group.rg.location}\""   resource_group_name = \""${azurerm_resource_group.rg.name}\""   app_service_plan_id = \""${azurerm_app_service_plan.plan.id}\""   storage_connection_string = \""${azurerm_storage_account.storage.primary_connection_string}\""   app_settings {     FUNCTIONS_WORKER_RUNTIME = \""dotnet\""     FUNCTION_APP_EDIT_MODE = \""readwrite\""     https_only = false     HASH = \""${base64sha256(file(\""./../FunctionAppZip/HelloWorld.zip\""))}\""     WEBSITE_RUN_FROM_PACKAGE = 1         WEBSITE_USE_ZIP = \""https://${azurerm_storage_account.storage.name}.blob.core.windows.net/${azurerm_storage_container.storage_container.name}/${azurerm_storage_blob.storage_blob.name}${data.azurerm_storage_account_sas.storage_sas.sas}\""   } } </code></pre>  <p>When i download azure function content its just a file there named \""FAILED TO DOWNLOAD ZIP FILE.txt\""</p>  <p>containing this: </p>  <p>% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                  Dload  Upload   Total   Spent    Left  Speed</p>  <p>0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 curl: (22) The requested URL returned error: 403 Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.</p>  <p>Any suggestions what im doing wrong?</p>""",azure-functions
55694797,How To Create Database Index Without Waiting To Complete <p>I'm using Azure Functions to insert lots of data into a SQL Server database once per month but at the same time I want to create an index on one of the tables.</p>  <p>Is it possible to kick off the create index and have it run until complete without it tying up the rest of the function.</p>  <p>In other words can the function complete and the index carries on building in the background?</p>  <p>Thanks</p>,azure-functions
46561839,"How to RDP connect to an Azure VM <p>I would like to run some tests on some VM machines. The machines belong to different users with different MSDN accounts  which means private passwords.</p>  <p>What I did was so far is to create an Azure VM for each MSDN account and set a similar user name/password for the machine.</p>  <p>What I would like to do is to:</p>  <ol> <li><p>Connect to any of these VMs. My problem: I don't know the machine name. I tried to connect using the rdp file provided by Azure  and it's working  but the problem is that it's using an IP instead of a name. I tried finding the machine name  but all documentation about this seems to be outdated. <a href=\https://i.stack.imgur.com/D4pg6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/D4pg6.png\"" alt=\""This is how my machine description looks like\""></a>. I tried to connect to amam10x64.westeurope.cloudapp.azure.com but without success.</p></li> <li><p>Copy a file to/from the VM. My hope is that I can use the following snippet:  </p>  <p>$commandStr = [string]::Format(\""Copy-VMFile \""\""{0}\""\"" -SourcePath \""\""{1}\""\"" - DestinationPath \""\""{2}\""\"" -CreateFullPath -FileSource Host -Force\""  $VM   $SessionPath  $RemoteFullPath) $commandBlock = [scriptblock]::Create($commandStr) Invoke-Command -Session $sess -ScriptBlock $commandBlock</p></li> <li><p>Run a command on the VM. Hopefully  I can use same command from Pt. 2.</p></li> </ol>""",azure-virtual-machine
56682112,"How I can update test case execution status in DevOps using API <p>I need to update the test case execution status (\Pass\"" or \""Fail\"") once the test case is executed. This needs to be done through pytest execution. I looked into a couple of resources but I don't get any way to update the Test Case execution status like \""Pass\"" or \""Fail\"" through API. Along with that  I can get the execution detail with Execution ID but there is no reference found using I can get execution details of a Test Case by Test Case ID.</p>  <p>Please guide me here.</p>""",azure-devops
49337761,"Debug high CPU usage in Azure WebApp (Linux) <p>I have set up an Azure WebApp (Linux) to run a WordPress and an other handmade PHP app on it. All works fine but I get this weird CPU usage graph (see below).</p>  <p>Both apps are PHP7.0 containers.</p>  <p>SSHing in to the two containers and using top I see no unusual CPU hogging processes.</p>  <p>When I reset both apps the CPU goes back to normal and then starts to raise slowly as shown below.</p>  <p>The amount of HTTP requests to the apps has not relation to the CPU usage at all.</p>  <p>I tried to use apache2ctl to see if there are any pending requests but that seems not possible to do inside a docker container.</p>  <p>Anybody got an idea how to track down the cause of this?</p>  <p><a href=\https://i.stack.imgur.com/BTWJB.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/BTWJB.png\"" alt=\""CPU usage\""></a></p>  <p>This is the top output. The instance has 2 cores. Lots of idle time but still over 100% load and none of the processes use the CPU ...</p>  <p><a href=\""https://i.stack.imgur.com/Atldy.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Atldy.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
25235117,How to ask/reply questions in a work item in Visual Studio Online? <p>In Visual studio online  someone created a work item for me  but I didn't quite understand. How to ask questions in a work item?</p>,azure-devops
50944583,"Azure Function - Could not load file or assembly <p>Im running an Azure Function .NET Standard 2.0 and get following error:</p>  <blockquote>   <p>An exception of type 'System.IO.FileLoadException' occurred in Function.dll but was not handled in user code   Could not load file or assembly 'Microsoft.WindowsAzure.Storage  Version=9.2.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35'.</p> </blockquote>  <p><a href=\https://i.stack.imgur.com/YbHCv.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/YbHCv.png\"" alt=\""Reference\""></a></p>  <p>The assembly file exist in the bin/debug folder. Been reading some threads about this but without a solution (<a href=\""https://github.com/Azure/azure-functions-core-tools/issues/322#issuecomment-352233979\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-functions-core-tools/issues/322#issuecomment-352233979</a>)  anyone know what to do?</p>  <p>I'm using code from another .NET Standard 2.0 project but all my projects have a reference to Microsoft.WindowsAzure.Storage 9.2.0.0 and that nuget package installed.</p>  <p>Thanks!</p>""",azure-functions
51402803,sync data between two storage accounts in azure <p>Consider I have two Storage account i e. Storage 1  Storage 2. When there is an entry to the Storage 1  the entry should be automatically synced to Storage 2 in Azure for all(table  file  blob). Is there anyway?</p>,azure-storage
16692109,"How do you deploy an EXE file into my Azure account? <p>I have an exe file which  when called  opens a pdf viewer... i used it in my web application and and tried to deploy it on my azure cloud as a service. every thing worked fine but when i clicked the link or button under which i called it .it gives a runtime error as \location changed or moved\""...all i want to open that viewer application to run on my azure cloud.</p>  <p>i m sorry if i asked a wrong question at this place .but my only need is that i want to deploy that exe in working condition . i m new to the cloud environment plzzz help me ..dont mark this question as ambiguous or can not be answered. plzz suggest me any way by which i will be able to do so .eiher cloud service or cloud website or virtual machine etc. any single word from your wise mind will help me a lot. </p>  <p>the code that i used to call that exe is.</p>  <pre class=\""lang-cs prettyprint-override\""><code>protected void Button1_Click(object sender  EventArgs e)     {        // Create An instance of the Process class responsible for starting the newly process.          System.Diagnostics.Process process1 = new System.Diagnostics.Process();          // Set the directory where the file resides          process1.StartInfo.WorkingDirectory = Request.MapPath(\""~/\"");          // Set the filename name of the file you want to open          process1.StartInfo.FileName = Request.MapPath(\""ProjectViewer.exe\"");          // Start the process         process1.Start();     } </code></pre>""",azure-storage
53375193,"Azure storage not finding csv file <p>I am trying to read a csv file from my azure storage account. To convert each line into an object and build a list of those objects. It keeps erring  and the reason is it cant find the file (Blob not found). The file is there  It is a csv file. </p>  <p><a href=\https://i.stack.imgur.com/rPot0.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/rPot0.jpg\"" alt=\""File in azure storage\""></a></p>  <p>Error:</p>  <blockquote>   <p><strong>StorageException: The specified blob does not exist.</strong>   BatlGroup.Site.Services.AzureStorageService.AzureFileMethods.ReadCsvFileFromBlobAsync(CloudBlobContainer container  string fileName) in AzureFileMethods.cs   +                   await blob.DownloadToStreamAsync(memoryStream);</p> </blockquote>  <pre><code> public async Task&lt;Stream&gt; ReadCsvFileFromBlobAsync(CloudBlobContainer container  string fileName)     {         // Retrieve reference to a blob (fileName)         var blob = container.GetBlockBlobReference(fileName);          using (var memoryStream = new MemoryStream())         {             //downloads blob's content to a stream              await blob.DownloadToStreamAsync(memoryStream);             return memoryStream;          }      } </code></pre>  <p>I've made sure the file is public. I can download any text file that is stored there  but none of the csv files.</p>  <p>I am also not sure what format to take it in as I need to iterate through the lines.</p>  <p>I see examples of bringing the whole file down to a temp drive and working with it there but that seems unproductive as then I could just store the file in wwroot folder instead of azure.</p>  <p>What is the most appropriate way to read a csv file from azure storage.</p>""",azure-storage
55964626,"Node cannot read environmental variable from Azure <p>I'm following an introductory course on Azure Web Apps. One specific tutorial shows how to get an environmental parameter  previously set from the Azure portal  and display it in your webpage  but this doesn't work for me.</p>  <p>The code is really simple and I'm only pasting the server response where the env parameter should go</p>  <pre><code>var server = http.createServer(function(request  response) {     response.writeHead(200  {\Content-Type\"": \""text/html\""});     response.write(\""&lt;!DOCTYPE html&gt;\"");     response.write(\""&lt;html&gt;\"");     response.write(\""&lt;head&gt;\"");     response.write(\""&lt;title&gt;Hello&lt;/title&gt;\"");     response.write(\""&lt;/head&gt;\"");     response.write(\""&lt;body&gt;\"");     response.write(`Hello from ${process.env.MyParameter}!`);  //PROBLEM HERE     response.write(\""&lt;/body&gt;\"");     response.write(\""&lt;/html&gt;\"");     response.end(); }); </code></pre>  <p>Of course  I've set up a new <em>application setting</em> in my Azure app Configuration that is called <em>MyParameter</em>.<br> Now if I want to display some plain text such as <code>response.write(\""Hello world\"");</code> it works perfectly  but when I try to get the env variable I get a <strong>HTTP ERROR 500 - This page isn't working</strong> error.</p>  <p>What am I doing wrong?</p>""",azure-web-app-service
49981159,"Calling Azure function from Angular 1.6  CORS problems <p>I'm trying to call an Azure function of mine  failing:</p>  <pre><code>$http.post(url  {data: data  headers: headers})   .success(function (jSendResponse  status  headers) {     console.warn(\worked\"");   })   .error(function (errResponse) {     console.warn('failed')   }); </code></pre>  <p><code>Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin '&lt;Origin domain&gt;' is therefore not allowed access. The response had HTTP status code 400.</code></p>  <p>I have changed the CORS setting for this particular Azure function. First by specifying my exact domain. And then by adding <code>*</code> as a last entry in the list of allowed origins.</p>  <p>But the error message remains.</p>  <p>What am I doing wrong?</p>""",azure-functions
42831038,"ARM Template containing config settings for web app <p>I am encountering strange behavior when deploying an ARM template.</p>  <p>I have the following template: (Note that sasUrl value 'xxx' has a real  working value in my file)</p>  <pre><code>{   \name\"": \""[variables('webAppServiceName')]\""    \""type\"": \""Microsoft.Web/sites\""    \""location\"": \""[resourceGroup().location]\""    \""apiVersion\"": \""2016-08-01\""    \""dependsOn\"": [     \""[concat('Microsoft.Web/serverfarms/'  variables('appServicePlanName'))]\""   ]    \""tags\"": {     \""[concat('hidden-related:'  resourceGroup().id  '/providers/Microsoft.Web/serverfarms/'  variables('appServicePlanName'))]\"": \""Resource\""      \""displayName\"": \""[variables('webAppServiceName')]\""   }    \""properties\"": {     \""name\"": \""[variables('webAppServiceName')]\""      \""serverFarmId\"": \""[resourceId('Microsoft.Web/serverfarms'  variables('appServicePlanName'))]\""   }    \""resources\"": [     {       \""apiVersion\"": \""2014-11-01\""        \""name\"": \""appsettings\""        \""type\"": \""config\""        \""dependsOn\"": [         \""[concat('Microsoft.Web/sites/'  variables('webAppServiceName'))]\""          \""[concat('Microsoft.Web/certificates/'  variables('certificateName'))]\""       ]        \""tags\"": {         \""displayName\"": \""WebAppSettings\""       }        \""properties\"": {         \""WEBSITE_LOAD_CERTIFICATES\"": \""[reference(resourceId('Microsoft.Web/certificates'  variables('certificateName'))  providers('Microsoft.Web'  'certificates').apiVersions[0]).thumbprint]\""       }     }      {       \""apiVersion\"": \""2016-08-01\""        \""name\"": \""Microsoft.ApplicationInsights.Profiler.AzureWebApps\""        \""type\"": \""siteextensions\""        \""dependsOn\"": [         \""[resourceId('Microsoft.Web/Sites'  variables('webAppServiceName'))]\""       ]        \""properties\"": {}     }      {       \""apiVersion\"": \""2015-08-01\""        \""name\"": \""logs\""        \""type\"": \""config\""        \""dependsOn\"": [         \""[resourceId('Microsoft.Web/Sites'  variables('webAppServiceName'))]\""       ]        \""properties\"": {         \""applicationLogs\"": {           \""fileSystem\"": {             \""level\"": \""Off\""           }            \""azureTableStorage\"": {             \""level\"": \""Off\""           }            \""azureBlobStorage\"": {             \""level\"": \""[parameters('applicationLogLevel')]\""              \""sasUrl\"": \""xxx\""           }         }          \""httpLogs\"": {           \""fileSystem\"": {             \""enabled\"": false           }            \""azureBlobStorage\"": {             \""enabled\"": true              \""sasUrl\"": \""xxx\""           }         }          \""failedRequestsTracing\"": {           \""enabled\"": \""[parameters('enableFailedRequestTracing')]\""         }          \""detailedErrorMessages\"": {           \""enabled\"": \""[parameters('enableDetailedErrorMessages')]\""         }       }     }   ] } </code></pre>  <p>When deploying this template without modifying anything  the config section 'logs' is not deployed correctly +- 1 on 2 times. I have just tested the ARM template again  and the first deployment  the web app had not the correct settings for diagnostics logging. The second time neither  but the third time they were ok. But the fourth time  the settings were not correct anymore. It looks like this part of the template has no consistent behavior. </p>  <p>Am I overseeing something?</p>""",azure-web-app-service
41781174,"Update work item relations/links in VS Team Services <p>I am trying to use the VSTS API to remove all parent links on items  and set those parents as related items.</p>  <p><a href=\https://www.visualstudio.com/en-us/docs/integrate/api/wit/work-items#update-work-items\"" rel=\""nofollow noreferrer\"">https://www.visualstudio.com/en-us/docs/integrate/api/wit/work-items#update-work-items</a></p>  <p>I do not fully understand how the \""Path\"" needed to remove relations work – I am getting inconsistent results where sometimes it works  sometimes not (so  im clearly doing it wrong)</p>  <p>I am making an assumption that its simply the <strong>order</strong> returned by the API. So  for example:</p>  <ul> <li>Index[0] item </li> <li>Index[1] item  </li> <li><p>Index[2] item &lt;- this is the one I want to remove  so I use index 2</p>  <pre><code>    public void RemoveParentLink(int pathIndex  int itemToUpdate  string link) {      JsonPatchDocument patchDocument = new JsonPatchDocument();      patchDocument.Add(        new JsonPatchOperation()        {            Operation = Operation.Remove             Path = $\""/relations/{pathIndex}\""         }     );      WorkItem result = witClient.UpdateWorkItemAsync(patchDocument  itemToUpdate).Result;  } </code></pre></li> </ul>  <p>The documentation states that Path is:</p>  <p>Path to the value you want to add  replace  remove  or test. For a specific relation  use \""relations/Id\"". For all relations  use \""/relations/-\"".</p>  <p>Index is NOT the Id of course  but how do I get the relation/Id exactly?</p>""",azure-devops
40606892,Prevent a public service from overusing <p>I have a web api 2 that I want to host on azure-app-service. The service should be called by javascript applications so as far as I know it has to be open to public (right?).</p>  <p>However  if I let it be totally open it is vulnerable to DOS. What is the best way to do that?</p>  <p>The first thing that came to my mind was to implement a custom IP Filter that keeps requests from last x minutes and let the one with less than y occurrence pass.</p>  <p>Is there any other way? Is there any specific way to do it on the azure without writing code?</p>  <hr>  <p><strong>This is not a broad question! I think it is clear what I am asking!  I have a service on Azure and I want to protect it from overusing. How broad is that?!?!</strong> </p>,azure-web-app-service
47281734,"Azure ML Web Service + Python for Querying Pandas Data Frame <p>I want to use Azure ML Web Service for a non machine learning task with Python. The goal is the following:</p>  <p>I have a Pandas DF like this:</p>  <pre><code>   Id   Value 0  111  0.1 1  222  7.3 2  333  3.1 3  444  5.0 </code></pre>  <p>I can query this DF successfully (what is the value of a certain row by Id?):</p>  <pre><code>float(df.loc[pot['Id'] == 222  'Value']) </code></pre>  <p>Now  I want to deploy a function in Azure ML Web Service with this functionality where a function uses an uploaded data set as fix lookup table. I constructed the function which gets an Id number as argument  looks for the value in the pre-uploade dataset and gives it back as a float:</p>  <pre><code>from azureml import services import pandas as pd  @services.publish(workspace_id  workspace_token) @services.types(id=int) @services.returns(float) def my_func(id):     my_df = ws.datasets[\uploaded_df.csv\""].to_dataframe()     return float(my_df.loc[cent['Id'] == id  'Value']) </code></pre>  <p>I can deploy it on Azure Web Services but when I try to run a test query It gets stuck (no way even to peep into the details). What is the problem here?</p>""",azure-web-app-service
47328693,Fail over from Azure VM to Azure Web App <p>We want to fail over from <strong>Azure VM</strong> (Windows Server) to <strong>Azure Web App</strong>. VM hosts the web application  and Web App is just a page informing Website Under Maintenance message. This is for planned/un-planned maintenance events of the server. Once the maintenance is over  how to retract it back. Thanks in advance.</p>,azure-virtual-machine
47762970,"How to cancel an upload started with BlobService.createBlockBlobFromBrowserFile? <p>I'm using Microsoft Azure Storage Client Library's <a href=\https://azure.github.io/azure-storage-node/BlobService.html#createBlockBlobFromBrowserFile__anchor\"" rel=\""nofollow noreferrer\""><code>BlobService.createBlockBlobFromBrowserFile</code></a> to allow users to upload files to an Azure Storage container. I'd like to provide a way for them to cancel an in-progress upload  e.g. in case it's big and taking too long or they chose the wrong file. Is there any way I can do this though? I can't see anything obvious in the API. </p>  <p>My code is based on <a href=\""https://dmrelease.blob.core.windows.net/azurestoragejssample/samples/sample-blob.html#step5\"" rel=\""nofollow noreferrer\"">these samples</a>  e.g.</p>  <pre><code>var file = document.getElementById('fileinput').files[0];  var customBlockSize = file.size &gt; 1024 * 1024 * 32 ? 1024 * 1024 * 4 : 1024 * 512; blobService.singleBlobPutThresholdInBytes = customBlockSize;  var finishedOrError = false; var speedSummary = blobService.createBlockBlobFromBrowserFile('mycontainer'  file.name  file  {blockSize : customBlockSize}  function(error  result  response) {     finishedOrError = true;     if (error) {         // Upload blob failed     } else {         // Upload successfully     } }); refreshProgress(); </code></pre>  <p>The <code>SpeedSummary</code> object returned from <code>createBlockBlobFromBrowserFile</code> is I think <a href=\""https://github.com/Azure/azure-sdk-for-node/blob/c98fd8ff9310f688a7ff6a227015876cd1f722ab/lib/services/legacyStorage/lib/blob/internal/speedsummary.js\"" rel=\""nofollow noreferrer\"">this one</a>  which doesn't have anything like that available.</p>  <p>Also asked on <a href=\""https://social.msdn.microsoft.com/Forums/azure/en-US/e343fca8-a1f5-445b-b7a3-92ad0b210f64/azure-storage-client-library-for-js-how-to-cancel-an-upload-started-with?forum=windowsazuredata\"" rel=\""nofollow noreferrer\"">MSDN here</a>.</p>""",azure-storage
42642833,Could not load file or assembly 'Microsoft.Owin.Host.SystemWeb on VSTS <p>Locally all my test run fine but when do a build on VSTS I get this error. </p>  <pre><code>##[error]System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---&gt; System.IO.FileNotFoundException: Could not load file or assembly 'Microsoft.Owin.Host.SystemWeb  PublicKeyToken=31bf3856ad364e35' or one of its dependencies. The system cannot find the file specified.WRN: Assembly binding logging is turned OFF. </code></pre>  <p>Though the nuget restore build step says:</p>  <pre><code>Restoring NuGet package Microsoft.Owin.Host.SystemWeb.3.0.1. </code></pre>  <p>and</p>  <pre><code>Adding package 'Microsoft.Owin.Host.SystemWeb.3.0.1' to folder 'D:\a\1\s\packages' Added package 'Microsoft.Owin.Host.SystemWeb.3.0.1' to folder 'D:\a\1\s\packages' </code></pre>,azure-devops
54347532,AI (Internal): Reached message limit. End of EventSource error messages <p>I am performing activities as EventHubTrigger with Azure Function.</p>  <p>This trace message is popping up all over our AppInsights instance. I don't know what is means  or what could be the cause. I'm happy to provide any details that can help debug. </p>  <p>Trace message</p>  <blockquote>   <p>2019-01-24T04:12:33.467   AI (Internal): Reached message limit. End of EventSource error messages.</p> </blockquote>  <p>sdkVersion : dotnet:2.7.2-23439</p>  <blockquote>   <p>2019-01-24T04:12:33.467   AI (Internal): [Microsoft-ApplicationInsights-Core] Reached message limit. End of EventSource error messages.</p> </blockquote>  <p>sdkVersion : dotnet:2.8.1-22898</p>,azure-functions
7118942,In Windows Azure: What are web role  worker role and VM role? <p>The application I work on contains a web role: it's a simple web application.  I needed to host the application in Windows Azure  so I created a web role.  I actually want to know what these roles are for.  What is their significance coding wise or storage wise?</p>,azure-virtual-machine
52521171,"What determines which projects in VisualStudio are consider to be publish artifacts in Azure Devops Build <p>I have a solution with multiple projects(.NET). Most of them Web applications and one Console Application. </p>  <p>I have created a new solution configuration in Visual Studio called QA.</p>  <p>On my Azure DevOps CI Build I have set up my BuildConfiguration to QA. </p>  <p>Everything builds but when I check in my Publish Artifact I don't see my Console Application project artifact. </p>  <p>Anybody else having this issue ?</p>  <p>What determines what projects get publish as an Artifact ? </p>  <p>Thanks In advance<a href=\https://i.stack.imgur.com/jFr8v.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/jFr8v.png\"" alt=\""Build publish artifacts log\""></a></p>""",azure-devops
51145124,"How to list all blobs inside of a specific subdirectory in Azure Cloud Storage using Python? <p>I worked through the example code from the Azure docs <a href=\https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python</a></p>  <pre><code>from azure.storage.blob import BlockBlobService account_name = \""x\"" account_key = \""x\"" top_level_container_name = \""top_container\""  blob_service = BlockBlobService(account_name  account_key)  print(\""\\nList blobs in the container\"") generator = blob_service.list_blobs(top_level_container_name) for blob in generator:     print(\""\\t Blob name: \"" + blob.name) </code></pre>  <p>Now I would like to know how to get more fine grained in my container walking. My container top_level_container_name has several subdirectories </p>  <ul> <li>top_level_container_name/dir1</li> <li>top_level_container_name/dir2</li> <li>etc in that pattern</li> </ul>  <p>I would like to be able to list all of the blobs that are inside just one of those directories. For instance </p>  <ul> <li>dir1/a.jpg</li> <li>dir1/b.jpg</li> <li>etc</li> </ul>  <p>How do I get a generator of just the contents of dir1 without having to walk all of the other dirs? (I would also take a list or dictionary)</p>  <p>I tried adding /dir1 to the name of the top_level_container_name so it would be <code>top_level_container_name = \""top_container/dir1\""</code> but that didn't work. I get back an error code   <code>azure.common.AzureHttpError: The requested URI does not represent any resource on the server. ErrorCode: InvalidUri</code></p>  <p>The docs do not seem to even have any info on BlockBlobService.list_blobs() <a href=\""https://docs.microsoft.com/en-us/python/api/azure.storage.blob.blockblobservice.blockblobservice?view=azure-python\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/python/api/azure.storage.blob.blockblobservice.blockblobservice?view=azure-python</a></p>  <p>Update: list_blobs() comes from <a href=\""https://github.com/Azure/azure-storage-python/blob/ff51954d1b9d11cd7ecd19143c1c0652ef1239cb/azure-storage-blob/azure/storage/blob/baseblobservice.py#L1202\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-storage-python/blob/ff51954d1b9d11cd7ecd19143c1c0652ef1239cb/azure-storage-blob/azure/storage/blob/baseblobservice.py#L1202</a> </p>""",azure-storage
56547808,"App service to app service auth in Azure using Managed Identity <p>I have set up two App Services in Azure. 'Parent' and 'Child'  both expose API endpoints.</p>  <ul> <li>Child has endpoint 'Get'.</li> <li>Parent has endpoints 'Get' and 'GetChild' (which calls 'Get' on Child using HttpClient).</li> </ul>  <p>I want all Child endpoints to require auth via Managed Identity and AAD  and I want all Parent endpoints to allow anonymous. However in Azure I want to set the Parent App Service to have permission to call the Child App Service. Therefore Child endpoints are only accessible by using Parent endpoints (or if you have permissions on a user account to directly use Child).</p>  <p>In the Azure Portal:</p>  <p><strong>Authentication/Authorization</strong></p>  <ul> <li>I have enabled 'App Service Authentication' on both App Services.</li> <li>Child is set to 'Log in with AAD'.</li> <li>Parent is set to 'Allow Anonymous requests'.</li> <li>Both have AAD configured under 'Authentication Providers'.</li> </ul>  <p><strong>Identity</strong></p>  <ul> <li>Set to 'On' for both App Services</li> </ul>  <p><strong>Access control (IAM)</strong></p>  <ul> <li>Child has Parent as Role Assignment  Type = \App Service or Function App\"" and Role = \""Contributer\""</li> </ul>  <p>With all the above setup:</p>  <ul> <li>Calling Child -> Get  requires me to log in</li> <li>Calling Parent -> Get  returns the expected response of 200 OK</li> <li>Calling Parent -> GetChild  returns \""401 - You do not have permission to view this directory or page\""</li> </ul>  <p>Without the use of Client ids/Secrets/Keys/etc  as I thought the idea behind Managed Identity was to throw that all out the window  given all the above  should Parent be able to call Child? And if so  what have I setup wrong?</p>""",azure-web-app-service
34727829,"How to delete a folder within an Azure blob container <p>I have a blob container in Azure called <code>pictures</code> that has various folders within it (see snapshot below):</p>  <p><a href=\https://i.stack.imgur.com/hAwBc.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/hAwBc.png\"" alt=\""enter image description here\""></a></p>  <p>I'm trying to delete the folders titled <code>users</code> and <code>uploads</code> shown in the snapshot  but I keep the error: <code>Failed to delete blob pictures/uploads/. Error: The specified blob does not exist.</code> Could anyone shed light on how I can delete those two folders? I haven't been able to uncover anything meaningful via Googling this issue.</p>  <p><em>Note: ask me for more information in case you need it</em></p>""",azure-storage
47082856,Azure Function App in PowerShell generating host threshold exceeded errors <p>We just started getting this error yesterday but haven't changed anything in our app.  Any ideas?  If we restart the function app  it will run for a short time and then start giving us this error again.  The function app is in PowerShell.</p>  <pre><code>Host Error: Microsoft.Azure.WebJobs.Script: Host thresholds exceeded: [Connections] </code></pre>,azure-functions
10302396,"Azure Role Environment not initialising <p>My project has suddenly stopped working. I am using local storage and when I try to initialise the role environment  it says:</p>  <blockquote>   <p>\Microsoft.WindowsAzure.ServiceRuntime Error: 102 : Role environment . FAILED TO INITIALIZE\""</p> </blockquote>  <p>and an SEH exception occurs with error code \""-2147467259\"". I start a new instance of the cloud part of my project and then attempt to start a new instance of my WPF application in the same solution. I think when the WPF application is run  it stops the cloud instance deployment. But I am not sure.</p>""",azure-storage
28119248,"detect production or staging in cloud service in azure <p>Is there a way to detect if I am in staging or production ?  there is a RoleInstance class but it doesn't have a field for this metter.</p>  <p>There is a microsoft code but it's complicated. the link is <a href=\https://code.msdn.microsoft.com/windowsazure/CSAzureDeploymentSlot-1ce0e3b5#content\"" rel=\""nofollow noreferrer\"">https://code.msdn.microsoft.com/windowsazure/CSAzureDeploymentSlot-1ce0e3b5#content</a>   but I don't understand if the hostedServiceName in the code is my project name  cloud project name  or cloud service name  and what is thrumbnail  where do I get it from and how do I register it in the azure ?</p>""",azure-web-app-service
45506009,"Event ID 2284 and 2289 logged Azure Web Apps <p>Our event log in Azure Web App has a bunch of Event <a href=\https://technet.microsoft.com/en-us/library/cc735142(v=ws.10).aspx\"" rel=\""nofollow noreferrer\"">2289</a> and <a href=\""https://technet.microsoft.com/en-us/library/dd349265(v=ws.10).aspx\"" rel=\""nofollow noreferrer\"">2284</a> error entries by W3SVC-WP:</p>  <p><a href=\""https://i.stack.imgur.com/V2qP3.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/V2qP3.png\"" alt=\""enter image description here\""></a></p>  <p>The messages are either something like this:</p>  <blockquote>   <p>1<br/>5<br/>\\?\\D:\\home\\LogFiles\\W3SVC442144452\\<br/>02000780</p> </blockquote>  <p>Or like this:</p>  <blockquote>   <p>1<br/>5<br/>50000780</p> </blockquote>  <p>I'm not sure where these come from but they seem to inhibit errors from logging correctly. </p>""",azure-web-app-service
57633009,"How to configure the @CosmosDBtrigger using java? <ol> <li>I'm setting up @CosmosDBTrigger  need help with the below code and also what needs to be in the name field?</li> </ol>  <p>I'm using below Tech stack </p>  <p>JDK 1.8.0-211 apache maven 3.5.3 AzureCLI 2.0.71 .net core 2.2.401</p>  <p>Java:     public class Function {</p>  <pre><code>    @FunctionName(\CosmosTrigger\"")     public void mebershipProfileTrigger(             @CosmosDBTrigger(name = \""?\""  databaseName =              \""*database_name*\""  collectionName = \""*collection_name*\""                leaseCollectionName = \""leases\""                createLeaseCollectionIfNotExists = true                connectionStringSetting = \""DBConnection\"") String[] items               final ExecutionContext context) {                   context.getLogger().info(\""item(s) changed\"");        }    } </code></pre>  <p>What do we need to provide in the name field?</p>  <p>local.settings.json</p>  <pre><code>{   \""IsEncrypted\"": false    \""Values\"": {      \""DBConnection\"": \""AccountEndpoint=*Account_Endpoint*\""   } } </code></pre>  <p>Expected: function starts</p>  <p>Result: \""Microsoft.Azure.WebJobs.Host: Error indexing method 'Functions.Cosmostrigger'. Microsoft.Azure.WebJobs.Extensions.CosmosDB: Cannot create Collection Information for <em>collection_name</em> in database <em>database_name</em> with lease leases in database <em>database_name</em> : Unexpected character encountered while parsing value: &lt;. Path ''  line 0  position 0. Newtonsoft.Json: Unexpected character encountered while parsing value: &lt;. Path ''  line 0  position 0.\""</p>""",azure-functions
56802924,"Unable to Communicate from one azure VM in same virtual net to the secondary NIC of another azure VM <p>I have an azure Linux VM say VM1 having only one network interface with private IP <code>10.3.0.5</code>  I have another azure Linux VM say VM2 with two network interfaces  the private IP on primary network interface is <code>10.3.5.4</code>  the private IP on the secondary network interface is <code>10.3.4.4</code>. Now I am able to ping VM2 from VM1 on primary network interface of VM2 as  <code>ping 10.3.5.4</code> but I am not able to ping it in on secondary network interface as ping <code>10.3.4.4</code>.</p>  <p>After reading azure docs - <a href=\https://docs.microsoft.com/en-gb/azure/virtual-machines/linux/multiple-nics#configure-guest-os-for-multiple-nics\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-gb/azure/virtual-machines/linux/multiple-nics#configure-guest-os-for-multiple-nics</a>  they say that you would have to manually add required routes to achieve this.</p>  <p>Similar problem in windows VM - <a href=\""https://support.microsoft.com/en-in/help/4048050/troubleshooter-for-azure-vm-connectivity-problems\"" rel=\""nofollow noreferrer\"">https://support.microsoft.com/en-in/help/4048050/troubleshooter-for-azure-vm-connectivity-problems</a></p>  <p>here is the result of command <code>route -n</code> on VM2</p>  <pre><code>Kernel IP routing table Destination     Gateway         Genmask         Flags Metric Ref    Use Iface 0.0.0.0         10.3.5.1        0.0.0.0         UG    0      0        0 eth0 10.3.4.0        0.0.0.0         255.255.255.0   U     0      0        0 eth1 10.3.5.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0 168.63.129.16   10.3.5.1        255.255.255.255 UGH   0      0        0 eth0 169.254.169.254 10.3.5.1        255.255.255.255 UGH   0      0        0 eth0 172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0 172.18.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker_gwbridge </code></pre>  <p>Now as per the above azure docs  it is missing an entry something like this</p>  <pre><code>0.0.0.0        10.3.4.1         0.0.0.0        UG     0      0        0  eth1  </code></pre>  <p>I tried adding this route to my VM2 but after running the following command  my vm just stopped responding <code>route add -net 0.0.0.0 netmask 0.0.0.0 gw 10.3.4.1 dev eth1</code></p>  <p>How do I add the correct route for my problem ? Please help !</p>""",azure-virtual-machine
29308219,Azure VM - strange fail <p>I was using my Azure VM and when installing SQL Express the RDP session stopped. Cant reconnect RDP  but asks for password and if wrong denies access. Alsso tried to reboot and shutdown from Azure Web Panel and Azure PowerShell with no success. What can I do more?</p>  <p>Thanks </p>  <p>Paulo</p>,azure-virtual-machine
48875008,"Did it create VM? <p>So i'm new to Azure - Registered about a hour ago.  I created Free Trial account but connected my Card to it so i could get 200$ for Trial. +++ I tried to create UbuntuNC24 VM - Wanted to see its hash rate (NOT for CryptoCurrency).</p>  <p>Its very expensive VM ~ 9$/h but I got that 200$ for testing so I wanted to see how would it perform. </p>  <p>But when I created everything and clicked \Finis\"" or however that last button is called I got some API error. After that I refreshed page and it was on \""Dashboard\"" as creating/starting... And then it disappeared from there.</p>  <p>I looked under VM in menu and on all Resources and its not there. Like I did not created it. </p>  <p>My question is - Did i create it and if I did where did it go?  I guess it would be very expensive mistake to just leave it..</p>  <p>Its debit card with 2$ balance on it but I don't want to hog on VM if I'm not using it or to go in debt with Azure (if it's possible).</p>""",azure-virtual-machine
49301247,"Serving an HTML Page from Azure PowerShell Function <p>I try to serve a HTML Page from an Azure <strong>PowerShell</strong> Function. I am able to return the HTML but I have clue where I can set the <strong>content type to text/htm</strong>l in order that the Browser interprets the HTML. </p>  <p>Here is an <a href=\https://anthonychu.ca/post/azure-functions-serve-html/\"" rel=\""nofollow noreferrer\"">example from Anythony Chu</a> how you can do it in C#:</p>  <pre><code>public static HttpResponseMessage Run(HttpRequestMessage req  TraceWriter log) {     var response = new HttpResponseMessage(HttpStatusCode.OK);     var stream = new FileStream(@\""d:\\home\\site\\wwwroot\\ShoppingList\\index.html\""  FileMode.Open);     response.Content = new StreamContent(stream);     response.Content.Headers.ContentType = new MediaTypeHeaderValue(\""text/html\"");     return response; } </code></pre>  <p>But in a PowerShell function I just return the file using the <code>Out-File</code> cmdlet and don't have the option to set the content type. Here a hello world example:</p>  <pre><code># POST method: $req $requestBody = Get-Content $req -Raw | ConvertFrom-Json $name = $requestBody.name  # GET method: each querystring parameter is its own variable if ($req_query_name)  {     $name = $req_query_name  }  $html = @' &lt;html&gt; &lt;header&gt;&lt;title&gt;This is title&lt;/title&gt;&lt;/header&gt; &lt;body&gt; Hello world &lt;/body&gt; &lt;/html&gt; '@  Out-File -Encoding Ascii -FilePath $res -inputObject $html </code></pre>  <p>Here is how the response looks like in the Browser:</p>  <p><a href=\""https://i.stack.imgur.com/L3dVh.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/L3dVh.png\"" alt=\""enter image description here\""></a></p>  <p>Any idea how I can set the content type so that the Browser <em>interprets</em>  the HTML?</p>""",azure-functions
15294122,"Generic table storage entity retrieval <p>I am playing with azure table storage entity retrieval and got a good ms example</p>  <p><a href=\http://www.windowsazure.com/en-us/develop/net/how-to-guides/table-services-v17/#retrieve-range-entities\"" rel=\""nofollow\"">http://www.windowsazure.com/en-us/develop/net/how-to-guides/table-services-v17/#retrieve-range-entities</a></p>  <p>in case ur bored to check the link</p>  <pre><code>// Retrieve storage account from connection string CloudStorageAccount storageAccount = CloudStorageAccount.Parse( CloudConfigurationManager.GetSetting(\""StorageConnectionString\""));  // Create the table client CloudTableClient tableClient = storageAccount.CreateCloudTableClient();  // Get the data service context TableServiceContext serviceContext = tableClient.GetDataServiceContext();  // Specify a partition query  using \""Smith\"" as the partition key CloudTableQuery&lt;CustomerEntity&gt; partitionQuery = (from e in serviceContext.CreateQuery&lt;CustomerEntity&gt;(\""people\"")  where e.PartitionKey == \""Smith\""  select e).AsTableServiceQuery&lt;CustomerEntity&gt;();  // Loop through the results  displaying information about the entity foreach (CustomerEntity entity in partitionQuery) { Console.WriteLine(\""{0}  {1}\\t{2}\\t{3}\""  entity.PartitionKey  entity.RowKey      entity.Email  entity.PhoneNumber); } </code></pre>  <p>now this works perfect.but i want to generalize it.. so i want to pass customerEntity as a parameter people as parameter(easy string tablename) and make it reusable.</p>  <p>so trick is for passing customerentity as parameter pleas help :)</p>""",azure-storage
51305138,Microsoft Azure - 2 VMs behind a public facing Load Balancer <p>I want to have 2 VMs behind a public facing <code>Load Balancer</code>. Both the VMs are in an <code>Availability Set</code> spread across 2 fault domains and 5 update domains (the defaults set for availability sets on the portal). <br/> Strangely  the <code>Load Balancer</code> does show the <code>Availability Set</code> when I try to configure the <code>Backend Pool</code> and hence I'm unable to configure <code>Inbound NAT Rules</code> for the VMs. <br/> Both the VMs do not have public IPs. They just have their private IPs. <br/> How do I proceed ?</p>,azure-virtual-machine
43982972,"Azure Functions - Shared code across Function Apps <p>Is there a way of sharing common code across two different Function Apps in Azure?</p>  <p>I understand it is possible to share code between two functions under the same Function App like so:</p>  <pre><code>#load \../Shared/ServiceLogger.csx\"" </code></pre>  <p>but I would like to share logging code between two different functions  each under it's own Function App. The reason for the functions being under two different Function Apps is that I need one to run on the Consumption plan and the other run on an App Service plan  unless there is another way of doing this?</p>""",azure-functions
42117135,"send a full brokered message in azure service bus from an azure function <p>I'm facing issue to send a complete brokered message to an azure service bus output in azure function in javascript.  The documentation only show a simple body message <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus</a> without any customerProperties.</p>  <p>My attempts to create a full brokered message failed so far  everything goes into the body.</p>  <p><a href=\""https://i.stack.imgur.com/Nf2hw.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Nf2hw.png\"" alt=\""enter image description here\""></a> <a href=\""https://i.stack.imgur.com/lmEID.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/lmEID.png\"" alt=\""enter image description here\""></a></p>  <pre><code>var message = {'body' : 'test'  'customProperties' : {'fromsystem':'sap'}}; context.bindings.outputSbMsg = message; context.done(null  res); </code></pre>""",azure-functions
54216929,"Uniquely identify disk <p>When I provisioned the Azure VM I explicitly gave a name for each disk based on what type SQL Server files/database it is going to be used for. Please see the image below. <a href=\https://i.stack.imgur.com/WeUXY.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/WeUXY.png\"" alt=\""enter image description here\""></a></p>  <p>However  Get-PhysicalDisk command output as <a href=\""https://i.stack.imgur.com/DGxHb.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/DGxHb.png\"" alt=\""enter image description here\""></a></p>  <p>What I am trying to do is create Storage Pool based on the name I specified during VM creation i.e.  Create a storage pool called TempDB using _TempDBData_1 and _TempDBData2</p>  <p>Thanks</p>""",azure-virtual-machine
43760323,"Node.js Azure sdk - getting the Virtual Machine state <p>I've started to look into the azure sdk for node.js (link below) and interestingly enough I've hit a wall in what I'd image would be one of the most common tasks one would want to achieve using Azure's REST endpoints which is checking the status of a virtual machine.  </p>  <p>I can easily get a list of all machine  or one in particular but the response from this services don't include the current status of the VM (running stopped etc.)</p>  <p>There's absolutely no info out there regarding this particular scenario in the docos or the web other than a blog post (<a href=\https://github.com/Azure/azure-xplat-cli/issues/2565\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-xplat-cli/issues/2565</a>) which is actually in regards of a different library. </p>  <p>Please not that I'm using the azure-arm-compute library which is part of the Node.js azure sdk.</p>  <p>Any help would be very much appreciated</p>  <p>github repo: <a href=\""https://github.com/Azure/azure-sdk-for-node\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-sdk-for-node</a></p>""",azure-virtual-machine
54182432,"HTTP 500.79 Error / System.UriFormatException when deploying ASP.NET App to Azure Web App <p>I am attempting to set up a Staging Environment for an ASP.NET MVC Application  and want to do that as an Azure Web App  but I am really stuck on an HTTP 500 at this point.</p>  <p>The error I get is:</p>  <pre><code>500.79: The request failed because of an unhandled exception in the Easy Auth module. </code></pre>  <p>Using diagnostics logs I was able to get a Stack Trace:</p>  <pre><code>2019-01-14T13:07:22  PID[14448] Critical    System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---&gt; System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---&gt; System.UriFormatException: Invalid URI: The format of the URI could not be determined.    at System.Uri.CreateThis(String uri  Boolean dontEscape  UriKind uriKind)    at System.Uri..ctor(String uriString  UriKind uriKind)    at Microsoft.Azure.AppService.Middleware.ModuleConfig.set_OpenIdIssuer(String value)    --- End of inner exception stack trace ---    at System.RuntimeMethodHandle.InvokeMethod(Object target  Object[] arguments  Signature sig  Boolean constructor)    at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj  Object[] parameters  Object[] arguments)    at System.Reflection.RuntimeMethodInfo.Invoke(Object obj  BindingFlags invokeAttr  Binder binder  Object[] parameters  CultureInfo culture)    at System.Reflection.RuntimePropertyInfo.SetValue(Object obj  Object value  BindingFlags invokeAttr  Binder binder  Object[] index  CultureInfo culture)    at System.Reflection.RuntimePropertyInfo.SetValue(Object obj  Object value  Object[] index)    at Microsoft.Azure.AppService.Middleware.MiddlewareConfig.TryLoadConfig(Type type  HttpContextBase context)    at Microsoft.Azure.AppService.Middleware.ModuleConfig.EnsureConfigLoaded(HttpContextBase context)    --- End of inner exception stack trace ---    at System.RuntimeMethodHandle.InvokeMethod(Object target  Object[] arguments  Signature sig  Boolean constructor)    at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj  Object[] parameters  Object[] arguments)    at System.Reflection.RuntimeMethodInfo.Invoke(Object obj  BindingFlags invokeAttr  Binder binder  Object[] parameters  CultureInfo culture)    at Microsoft.Azure.AppService.Middleware.ModuleManager.LoadModuleConfig(HttpContextBase context)    at Microsoft.Azure.AppService.Middleware.ModuleManager.LoadAllModulesAndGetEnabledModules(HttpContextBase context)    at Microsoft.Azure.AppService.Middleware.HttpModuleDispatcher.EnsureInitialized(HttpContextBase context)    at Microsoft.Azure.AppService.Middleware.HttpModuleDispatcher.&lt;DispatchAsync&gt;d__11.MoveNext() </code></pre>  <p>I've used any other diagnostics tool that I was able to find on Azure  but was not able to figure out a lot more  except one faint hint: Using the Failed Request Tracing feature I noticed that those traces state that the requests were made to very odd and obviously wrong URL's: </p>  <p>URL according to Request Trace: <code>https://Skillmanagementtest:80</code></p>  <p>Actually requested URL: <code>https://skillmanagementtest.azurewebsites.net</code></p>  <p>Screenshot: <a href=\https://i.stack.imgur.com/E0MyW.png\"" rel=\""nofollow noreferrer\"">Failed Request Trace</a></p>  <p>I have absolute no clue where either this URL or the port comes from; I have never specified port 80 anywhere (which is wrong anyway as its HTTPS). \""Skillmanagementtest\"" is the name I have given the Azure Web App  and I don't think that I have used it anywhere else. The Home Page URL and the Reply URL for Authentication (using AAD as Authentication Provider) is set correctly. My assumption is  that it is this gibberish URL that causes the UriFormatException  but I've got no clue where the URL is coming from...</p>  <p>That said  the application seems to start up properly (also things like logging frameworks placing their files on startup works)  and starting it up also does not place any errors into the diagnostic logs  but whenever a request is made  the above error occurs.</p>  <p>Locally and in production (using a \""classical\"" VM  not an Azure Web App) the Web App runs without problem  but I was not able to spot any difference in configuration between those and the Azure Web App (except of course the different file paths and DB connections). Also given the Stack Trace naming an Azure Middleware suggests that the problem originates from the app being run as Azure Web App  and as the only leverage I pretty much have there it oughta be some configuration error...</p>  <p>As a part of setting up the Staging Environment I aim towards having as much as possible automated. Thus I have also set up a CI/CD resp. a Build and a Release Pipeline using Azure DevOps. This seems to work all fine. Configuration-wise I use XML Transformations on the web.config resp. web.Staging.config file. The transformations are all applied correctly.</p>  <p>--</p>  <p>For any ideas on what may be wrong I would be immensly grateful  as I myself have pretty much run out of things to try (third full day I am trying to get this to work...)</p>  <p>~ Finrod</p>""",azure-web-app-service
47674415,Adapting hypermedia links based on environment <p>I have an on-premise ASP.NET Web API that's querying on-premise data. The plan is for the client web application to call an Azure Function which will deal with authentication (Azure AD B2C) and validating the request before actually forwarding the request to the on-premise API itself (over a VPN).</p>  <p>The API is generating Hypermedia links that point to the API itself. This works nicely when querying the API directly as each of the links helps in the discovery of the application.</p>  <p>This API is currently in use locally within the organisation  but we now need to expose it so it can be consumed over the web. We don't want to expose the API directly  we'd rather route it through a Function App that can authenticate  validate and perform any other logic we may need.</p>  <p>The question I have is  how would you translate these URLs to an endpoint in the Azure Function? i.e.  I would really like the consuming web application to be able to use these Hypermedia links directly  and have the Azure Function route them to the correct API endpoint.</p>  <p>In an ideal world  we'd have the links exposed on the client  which would map to the resource. As the API isn't exposed  how do we route it via the Function App?</p>,azure-functions
56441174,"PowerShell Remote from VSTS Pipeline <p>I'd like to invoke PowerShell commands on my VM remotely. I added \Run PowerShell on Target Machines\"" task in my pipeline. I provided: IP  username and password of my remote VM. Here's the error that I'm getting:</p>  <blockquote>   <p>Unable to create pssession. Error: 'Connecting to remote server    failed with the following error message : WinRM   cannot complete the operation. Verify that the specified computer name   is valid  that the computer is accessible over the network  and that a   firewall exception for the WinRM service is enabled and allows access   from this computer. By default  the WinRM firewall exception for   public profiles limits access to remote computers within the same   local subnet. For more information  see the   about_Remote_Troubleshooting Help topic.'</p> </blockquote>  <p>On my remote VM  I did:</p>  <pre><code>Enable-PSRemoting Set-NetFirewallRule -Name \""WINRM-HTTP-In-TCP-PUBLIC\"" -RemoteAddress Any </code></pre>  <p>These commands were mentioned here: <a href=\""https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_remote_troubleshooting?view=powershell-6\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_remote_troubleshooting?view=powershell-6</a></p>  <p>What else can I do?</p>""",azure-devops
54277263,azure App service deploy as code or container? <p>I have apis written in asp .net core which can be easily containerized  i want to deploy these apis in azure app service  but i am not able to decide whether i should containerize these api and deploy as containers in web app or i can deploy directly as code  On what basis this can be decided i see that App service gives scale out capacity for both way of deployment and other factors like continuous deployment also look same   so how shall i decide which approach to take   or it really doesn't matter in this case? </p>,azure-web-app-service
37829602,"remote desktop to an azure VM (created by the new portal - portal.azure.com) over the port 443 <p>I have a Virtual Machine created in the new azure portal (portal.azure.com) Now I can connect to by using the Remote Desktop by the port 3389  without any problems.</p>  <p>I am asking for a guide to setting my virtual machine can be remoted over the port 443 also (since the working network just allows outcoming 443 only)</p>  <p>With the classic portal  I just need to add an \end point\"" and that works. </p>  <p>However with the new portal  in the \""network security group\""  I tried to modify the \""inbound security rules\""  changed the default value 3389 to 443  but I got no luck.</p>  <p>Edited: captured screenshots</p>  <p><a href=\""https://i.stack.imgur.com/9pR0M.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/9pR0M.png\"" alt=\""enter image description here\""></a></p>  <p><a href=\""https://i.stack.imgur.com/6HucY.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6HucY.png\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
43051445,"A property has a space and Href is ignorning everything after it <p>I can download an uploaded file to Azure using a direct link  seemed the quickest and easiest way to do it. By no means the safest or the smartest. However  when I link to it in the Href  it ignores all spaces  meaning that if a user uploads a document with a space in the name  It doesn't search properly. How would I modify my code to replace any Spaces with % instead when searching?</p>  <p>Here is my code; The link clicked to download the file;</p>  <pre><code>  &lt;a href=@ViewBag.LinkToDownload@item.DocumentId@item.RevisionId@item.Attachment&gt;Download&lt;/a&gt; </code></pre>  <p>The controller</p>  <pre><code> [HttpPost]     [ValidateAntiForgeryToken]     public ActionResult Download(string id)     {         string path = @\https://filestorageideagen.blob.core.windows.net/documentuploader/\"";          return View(path + id);     } </code></pre>""",azure-storage
39492140,Build on Azure Web App  Error:Can not find runtime target for framework '.NETStandard Version=v1.6' <p>I have a asp.net core web project that was continuous deployed to Azure well. After I added another .net core class library to the solution  it gives the following build error on Azure: Microsoft.DotNet.Publishing.targets(149 5): error : Can not find runtime target for framework '.NETStandard Version=v1.6' compatible with one of the target runtimes: 'win8-x86  win7-x86'.</p>  <p>However  the solution builds and runs successfully on local box.</p>  <p>Any one experience that before</p>  <p>Thanks Geoff</p>,azure-web-app-service
50737410,Understanding Poison Message Handling in Azure Message Queue and using it in Logic Apps <p>I'm trying to make a workflow using Azure Logic Apps where several Azure Functions are connected. I'm using a blob trigger and im sending its content to the first function  then  that function sends a http req to the next one and so on. However i would like to make sure that the first function processes it correctly. So i figured i could use Message Queue  as it supports Poison Message Handling.</p>  <p>Now  the blob trigger puts a new message in a queue  which is then proccessed by the first function. I've seen many articles about how i can set retry policies (how many times a message should be proccessed  and intervals between retries)  however i can't quite find information about how i can use the Poison Message Handling. So my question is:</p>  <p>How are those poison messages handled after exceeding the retry count </p>  <p>Are they just staying in that queue  but are marked as poison?</p>  <p>Are they put in some other queue  that contains only the poison ones?</p>  <p>How can i take advantage of even finding them? Is it only possible to manage them by hand  or can i set up some kind of trigger that fires when a poison message occurs?</p>  <p>I am also wondering if my approach is correct. Is it fine to connect Azure Functions directly to each other in Logic Apps  or should each has its own Message Queue? Do i even need the message queue to handle Poison Message or is there a good way to do it in Logic Apps directly (I know that it's possible to set retry settings  but i haven't seen anything about automatic poison message handing)</p>,azure-functions
33841565,"Visual Studio Online Build - Visual Studio SDK and Modellng SDK <p>I have included <a href=\https://msdn.microsoft.com/en-us/library/bb166441.aspx\"" rel=\""nofollow\"">Visual Studio SDK</a> and <a href=\""https://msdn.microsoft.com/en-us/library/bb126259.aspx\"" rel=\""nofollow\"">Modeling SDK</a> in my project in order to build my T4 templates. It has been working fine until I wanted to set up the VSO Build  which gives me the following error:</p>  <blockquote>   <p>The imported project \""C:\\Program Files   (x86)\\MSBuild\\Microsoft\\VisualStudio\\v14.0\\TextTemplating\\Microsoft.TextTemplating.targets\""   was not found. Confirm that the path in the &lt;Import> declaration is   correct  and that the file exists on disk.</p> </blockquote>  <p>However  I was unable to find any options or settings to import/include the mentioned SDKs into the build machine.</p>""",azure-devops
35836600,"Azure Storage Blob Put SSL handshake error <p>I have a correctly formed URL for the Blob PUT operation  using Shared Access Signature:</p>  <blockquote>   <p><a href=\http://xyz.blob.core.windows.net:80/container/BLOB_NAME?sv=2015-04-05&amp;sr=b&amp;sig=xtpL3M2WRWILarpojLnjlacpIWs41%2BosFWiTtAPGwIE%3D&amp;se=2016-03-07T06%3A00%3A59Z&amp;sp=w\"" rel=\""nofollow\"">http://xyz.blob.core.windows.net:80/container/BLOB_NAME?sv=2015-04-05&amp;sr=b&amp;sig=xtpL3M2WRWILarpojLnjlacpIWs41%2BosFWiTtAPGwIE%3D&amp;se=2016-03-07T06%3A00%3A59Z&amp;sp=w</a></p> </blockquote>  <p>Using Fiddler's Composer  I am able to successfully upload data (with \""x-ms-blob-type: BlockBlob\"" header).</p>  <p>However  when I change the URL to \""https\"" -- the PUT fails with Status Code 502  and the following message:</p>  <blockquote>   <p>[Fiddler] The connection to 'xyz.blob.core.windows.net' failed.  <br />System.Security.SecurityException Failed to negotiate HTTPS connection with server.fiddler.network.https&gt; HTTPS handshake to xyz.blob.core.windows.net (for #21) failed. System.IO.IOException The handshake failed due to an unexpected packet format.</p> </blockquote>  <p>It surely seems like a problem on Azure's end. How could I get this resolved?</p>  <p>P.S. In Chrome  this problem manifests as \""net::ERR_SSL_PROTOCOL_ERROR\"". In Edge  I get \""XMLHttpRequest: Network Error 0x80070005  Access is denied.\""</p>""",azure-storage
51315104,Is it possible to upgrade an existing IaaS VM OS image from 2012 to 2016 <p>I have several IaaS Vms deployed with windows 2012 datacenter. Is it possible to upgrade to 2016 without re-creating VM?</p>,azure-virtual-machine
55163281,SQL - high CPU consumption <p>(AZURE VM)</p>  <p>We have 1 physical CPU  4 logical processor  1 NUMA node  4 MAXDOP  5 CTOP  56GB ram on the database server. We have 50 databases for our clients and at a particular time  not more than 30 users are online. CDC is enabled for all databases(40 tables under CDC)</p>  <p>We have a normal CPU usage of 40-50% and when clients are online usage jumps to 75-80%. We have observed spikes up to 100% CPU usage.  For daily average CPU consumption is 60% and maximum 96-100%.</p>  <p>All queries are executing in less than a minute.</p>  <p>Is there anything we can do lower the CPU consumption without impacting performance or this is normal.</p>,azure-virtual-machine
35954733,distribute third party application on azure virtual machine <p>I would like to know if there is a process that deploys/distribute third party applications on azure virtual machines. I have these windows applications that will be deployed on newly provisioned virtual machines. May I know if there is a automated process on this one? currently we have our custom template and we want to use images from the marketplace and deploy these applications automatically.</p>  <p>thanks!</p>,azure-virtual-machine
49210524,"Azure Functions Custom ILogger <p>Hopefully some people with a much better understanding of Azure Functions than i do can help.</p>  <p>Out of the box  you can log to Application Insights by using the APPINSIGHTS_INSTRUMENTATIONKEY setting in your app settings... this will log  at a basic level the Function requests  and then allow you to do <code>log.LogInformation</code> etc.</p>  <p>This is simply covered off by either a TraceWriter  or ILogger.</p>  <p>Issue is though  i don't want to store the Key in my config  i want to store it in KeyVault  along with all other keys for the App. I also want to do some other custom logging  so as per this link: <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-monitoring#custom-telemetry-in-c-functions\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-monitoring#custom-telemetry-in-c-functions</a> We can implement a custom <code>TelemetryClient()</code> object to read from KeyVault without much hassle..</p>  <p>However  all the nice free logging you get by using ILogger is now gone  so i guess what i need to do is somehow inject an Application Insights ILogger into my Function...</p>  <p>Can someone help me understand the limitations here  as in how it <em>would</em> be done if it were possible.. i also assume there must be a GitHub open case for it which i would be keen on finding  and lending weight to as i can't imagine I'm the only one that has faced this.</p>""",azure-functions
54149025,"Hide repositories from menu on a project on Azure DevOps <p>I want to hide two repositories (App 1 and 2 below) from the menu on a project on Azure DevOps.</p>  <p>Select a project -> Repos -> below</p>  <p><a href=\https://i.stack.imgur.com/HEuBg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/HEuBg.png\"" alt=\""enter image description here\""></a></p>  <p>The reason is that App 1 and 2 have code  but are not being used at the moment. So we will show them in the future. Thus  we want the ability to show/hide them.</p>  <p>Any idea?</p>""",azure-devops
11662161,"Log info for unhandled exception during Azure initialization? <p>I have deployed a site into Azure using VS 2010's <strong>Publish</strong> function. After VS says the deployment succeeds  I go to the old Azure dashboard and For the status it cycles through a few different status' (Initializing  Recovering  Recycling  etc) but all of them have <strong>Unhandled Exception</strong> at the end. I've seen a <a href=\http://blogs.staykov.net/2009/12/windows-azure-role-stuck-in.html\"" rel=\""nofollow\"">few</a> <a href=\""http://blogs.staykov.net/2009/12/another-common-reason-for-windows-azure.html\"" rel=\""nofollow\"">other</a> posts about this type of error but unfortunately they havent resolved the issue for me so now I just want to see the exception.</p>  <p>How do I see what the exception was? </p>""",azure-storage
56622380,"How to recreate an Agent Pool with the old name in AzureDevOps? <p>I have troubles creating a new agent pool in AzureDevOps.</p>  <p>What I wanted to do was to remove an old Self-Hosted host and deploy a new one. However  the Agent-Pool used by the old host and to be used by the new one was created by a co-worker. This let to the case that I was unable to remove the existing registered agents causing conflicts during deployment of the new host. To resolve this issue I was able to remove the agent pool. </p>  <p>Now  when I want to create a new pool with the same name  I get the error message </p>  <blockquote>   <p>\No agent pool found with identifier 76\"".</p> </blockquote>  <p>Did anybody ever see this error message and or has an idea what I can do about it?</p>  <p><strong>Expected:</strong> A new agent pool with the same name as the old pool is created.</p>  <p><strong>Actual:</strong> I receive the error message \""No agent pool found with identifier 76\"".</p>  <p><a href=\""https://i.stack.imgur.com/4bwlr.png\"" rel=\""nofollow noreferrer\"">Agent creation Image</a></p>  <p><a href=\""https://i.stack.imgur.com/Dndy4.jpg\"" rel=\""nofollow noreferrer\"">Error Message Image</a></p>""",azure-devops
57590336,How to copy azure pipeline artifacts to a docker image which is microsoft dotnetcore runtime image <p>I am building azure devops pipeline for dotnetcore project. After dotnet publish command execution the artifacts get saved in $(artifactStagingDirectory).  I want to build a docker image. How to copy these artifacts from artifacts staging directory to docker? I am not building project in dockerfile. I am executing dotnet publish in pipeline.</p>  <p>I have tried to save artifacts to another folder by using:</p>  <p>dotnet publish --configuration $(BuildConfiguration) --output out</p>,azure-devops
55294689,Delete an Azure Virtual Machine automatically after deployment <p>To deploy my infrastructure I need to deploy a VM with a custom script extension. The only purpose of the VM  is to execute the script. <strong>After the execution of the script the VM should be deleted automatically.</strong></p>  <p>How can this be done?</p>  <p>Additional information:</p>  <ul> <li>This is an azure resource manager deployment</li> <li>the deletion should work in the azure marketplace environment as well.</li> </ul>,azure-virtual-machine
44136929,"WEBSITE_HTTPLOGGING_CONTAINER_URL is a hidden application setting? <p>When swapping slots we get the following message:</p>  <p><a href=\https://i.stack.imgur.com/LDUHw.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/LDUHw.png\"" alt=\""enter image description here\""></a></p>  <p>But the WEBSITE_HTTPLOGGING_CONTAINER_URL setting does not exist in the Application Settings of either web app. I understand that it comes from enabling Web App Diagnostics Logs  but it is somehow hidden.</p>  <p>The issue is that this will cause an IIS restart in the production slot  and thus downtime until it has completed all initialisation tasks. There is no way to configure this settings as a \""Slot Setting\"" (which would prevent an edit to the application settings).</p>  <p>The odd thing is that DIAGNOSTICS_AZUREBLOBCONTAINERSASURL is visible in application settings (it is also a Diagnostics Log configuration).</p>""",azure-web-app-service
54512492,"Azure App Service Kudu Continuous Deployment stopped working  not even showing latest commits <p>Two weeks ago I created 2 App Services  one is a Function App and the other is a PHP website... after having them created  I went to Deployment Center and configured this option to pull the code from an Azure GIT Repo and build &amp; deploy the code using Kudu  everything was working as expected  whenever I made a code change and pushed it  Kudu was taking the latest commit  building and deploying the latest version...</p>  <p>Yesterday it stopped getting the latest commits from the Repo and by the time I tried to re-configure the setup to see if that helps it won't event display the commits anymore.</p>  <p>Here some screenshots showing the Web App and it's continuous deployment setup mapped to the Azure GIT Repo:</p>  <p><a href=\https://i.stack.imgur.com/aTDBZ.jpg\"" rel=\""nofollow noreferrer\"">WebApp Continuous Deployment Setup</a></p>  <p><a href=\""https://i.stack.imgur.com/tkMgp.jpg\"" rel=\""nofollow noreferrer\"">Azure Repo</a></p>  <p>Does anyone have faced this issue before? What could be potentially causing this situation? Could any quota limit be causing it?</p>  <p>NOTE: I have a Pay-as-you-go subscription.</p>""",azure-web-app-service
50656132,"Azure SDK API and JAVA usage - Issue Listing all Containers and BLOBS inside a storage account <p>Issues while using <strong>client.listContainers()</strong> and <strong>container.listBlobs()</strong> functions and getting below JAVA exception. Tried to access them individually with reference methods and it works fine. Not sure why this is happening as there are no access restrictions i.e public access and getting the client reference without any issues of Connection String.</p>  <hr>  <p><strong>Exception:</strong></p>  <pre><code>java.util.NoSuchElementException: An error occurred while enumerating the result  check the original exception for details. java.util.NoSuchElementException: An error occurred while enumerating the result  check the original exception for details. at com.microsoft.azure.storage.core.LazySegmentedIterator.hasNext(LazySegmentedIterator.java:113) at com.company.test.core.handler.AzureHeirarchyGenerator.getAzureFileList(AzureHeirarchyGenerator.java:69) at com.company.test.core.handler.AzureHeirarchyGenerator.main(AzureHeirarchyGenerator.java:18) Caused by: com.microsoft.azure.storage.StorageException: An unknown failure occurred : Connection refused: connect at com.microsoft.azure.storage.StorageException.translateException(StorageException.java:66) at com.microsoft.azure.storage.core.ExecutionEngine.executeWithRetry(ExecutionEngine.java:209) at com.microsoft.azure.storage.core.LazySegmentedIterator.hasNext(LazySegmentedIterator.java:109) ... 2 more Caused by: java.net.ConnectException: Connection refused: connect at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673) at sun.net.NetworkClient.doConnect(NetworkClient.java:175) at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) at sun.net.www.protocol.https.HttpsClient.&lt;init&gt;(HttpsClient.java:264) at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367) at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191) at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156) at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050) at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177) at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1564) at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492) at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:347) at com.microsoft.azure.storage.core.ExecutionEngine.executeWithRetry(ExecutionEngine.java:115) ... 3 more </code></pre>  <hr>  <p><strong>Code Snippet JAVA:</strong></p>  <pre><code>    CloudStorageAccount account = CloudStorageAccount.parse(azureConnectionString);     CloudBlobClient client = account.createCloudBlobClient();     // List all containers of a storage account     Iterable&lt;CloudBlobContainer&gt; containers = client.listContainers();     for (CloudBlobContainer cloudBlobContainer : containers) {         Iterable&lt;ListBlobItem&gt; blobs = cloudBlobContainer.lisBlobs();         System.out.println(\Code to fetch blobs inside container\"");     } </code></pre>""",azure-storage
52890991,Azure App Service: Converting Staging Slot into Standalone App <p>I have an Azure App with a Staging Slot. I'm trying to find a way to convert my Staging Slot into a normal Standalone App</p>  <p>Is there any way to achieve this?</p>  <p><strong>Why do I want to do this?</strong></p>  <p>Because I want to scale down my app from <code>S1-&gt;B1</code></p>  <p>Since <code>B1</code> doesn't <strong>support the deployment slots</strong> now I'm completely blocked from scaling down my App without deleting and recreating it.</p>,azure-web-app-service
35872354,How to startup apps added in Azure VM <p>I have a simple console application runs in Azure VM. What I did is creating a Local Group Policy for this app but it works in the background process.</p>  <p>Is it possible to run the app on windows startup normally. Not in the background??</p>,azure-virtual-machine
51499968,VSTS - External Git <p>I've tried to get VSTS to connect to our enterprise Git repository.</p>  <p>To do this I had to get our firewall opened up  and as a result we found that VSTS does not connect to our network using the VSTS domain  ie ########.visualstudio.com</p>  <p>Instead it connects using the IP address of the build agent  which is in the range specified in the Azure Public IP list.</p>  <p>Does anyone know if this is a bug on MS's part?  We could free up our firewall to all the Azure Public IP's  but this is very fragile (they can/will change)  and presents a significant security risk as anyone using Azure could attempt to connect to our Git repository.</p>  <p>Interestingly  if you install a private build agent  then VSTS connects to this using the VSTS domain  we have observed this.</p>,azure-devops
44195652,Disconnect with Azure ACS form Local Machine <ul> <li>I had pull my <code>azure acs</code> credentials using below command and I can communicate with <code>kubernetes machine</code> on Azure from my local machine <code> az acs kubernetes get-credentials --resource-group=&lt;cluster-resource-group&gt; --name=&lt;cluster-name&gt; </code></li> <li><p>But Now I wanted to disconnect this connection so that my kubctl can connect with other machine   it can be local or any other machine  (I am trying to connect with local).</p></li> <li><p>But everytime I ran <code>kubectl  command</code> it communicate with <code>Azure ACS</code></p></li> </ul>,azure-virtual-machine
44577592,Azure load balancer with single VM <p>I've couple of VMs under same subnet in Azure without any availability set attached to any of the vm. When I try to use load balancer (public) it shows two options to load balance VMs</p>  <ol> <li>Availability set    </li> <li>Single VM</li> </ol>  <p>Is it necessary to use availability set to implement load balancer between VMs and they should be under same availability set?</p>  <p>Also  if above it true  what is the purpose of single vm option where vm is visible to add under load balancer without any availability set?</p>,azure-virtual-machine
47652865,"azure webapps 404 error <p>I have web application developed in Spring boot (REST services) which is deployed on Azure webapps (Azure app service). My plan is Standard: 1 Small.</p>  <p>The application has been running smoothly since 2 weeks. All of a sudden  today  the application went down. Consumer application which calls these REST services started experiencing 404 errors (The origin server did not find a current representation for target resource or it is not willing to disclose that one exists)</p>  <p>When I check the logs  I did not find any root cause which will bring whole application down. This was second time it happened and this time too I am unable to find root cause (Memory usage/CPU usage seems fine). \Always on\"" setting is turned ON.</p>  <p>I have following questions: <em>1) What may be the root cause and Is there a way to find it ?</em></p>  <p>2) <em>Is there way (in azure webapps) to know when application goes down and auto scale ? (I have already set auto scale rules for CPU usage and Memory usage but this did not help).</em></p>""",azure-web-app-service
27751414,"Blob.getCopyState() returning null <p>Is this function not implemented in the java sdk? It appears to always return null. I am copy one page blob to another and want to track the status of the copy.</p>  <pre><code>    CloudPageBlob srcBlob = container.getPageBlobReference(\source.vhd\"";     String newname=\""dst.vhd\"";     CloudPageBlob dstBlob = container.getPageBlobReference(newname);     dstBlob.startCopyFromBlob(srcBlob);      //Get the blob again for updated state     dstBlob = container.getPageBlobReference(newname);     CopyState state = dstBlob.getCopyState(); </code></pre>  <p>Is there any other way to get status? I am using azure-storage-1.2.0.jar</p>""",azure-storage
55811118,"Deeplink to create branch from external site <p>I come from a Jira/Bitbucket environment where I could create a branch from within Jira. Bitbucket has a 'deeplink' that opens a dialog to create a branch:</p>  <p><a href=\http://[bitbucket]/plugins/servlet/create-branch?issueKey=[BugID]&amp;issueType=Bug&amp;issueSummary=[This+is+the+summary]\"" rel=\""nofollow noreferrer\"">http://[bitbucket]/plugins/servlet/create-branch?issueKey=[BugID]&amp;issueType=Bug&amp;issueSummary=[This+is+the+summary]</a></p>  <p>This allows an external app to call this URL (from a template) and start the 'create new branch' dialog in the browser. In this dialog the user can select the source repo / branch if other than default.</p>  <p>How can this be done in Azure DevOps?</p>  <p>In Azure DevOps wherever I click on the 'create branch' button it comes with a popup.</p>""",azure-devops
41403714,Azure cloud service network bandwith <p>I have an Azure web role on 3 Standard_A3s. The web api has a heavy load and it transfers lot of large objects. I am trying to find out at what RPS we might hit network bandwith limit. Is there a way to find this out.</p>,azure-virtual-machine
51032742,Azure Functions Docker Deployment Linux workers are not available in resource group <p>Trying to deploy a nginix container from Azure Container Registry through function app </p>  <p>Getting an error as </p>  <blockquote>   <p>Linux workers are not available in resource group</p> </blockquote>  <p>How to enable linux workers to a resource group?</p>  <p>Dockerfile for deployment </p>  <pre><code>FROM nginx COPY dist /usr/share/nginx/html </code></pre>,azure-functions
35893929,"How can I deploy a html website using Azure Resource Manager <p>I've got a website (basic html) and I want to deploy it using Azure Resource manager.  It doesn't have a visual studio sln file and I don't want to create one.</p>  <p>I've found this tutorial for an angular website that does something along the lines that I am trying to do.  <a href=\http://www.azurefromthetrenches.com/how-to-publish-an-angularjs-website-with-azure-resource-manager-templates/\"" rel=\""nofollow\"">http://www.azurefromthetrenches.com/how-to-publish-an-angularjs-website-with-azure-resource-manager-templates/</a></p>  <p>The problem I want to solve is that I have the Microsoft Azure SDK for .NET (VS 2015) 2.8.2 which allows me to add resources to my resource group project.  The tutorial writes everything itself  rather than use visual studio to create the resources.</p>  <p>Does any one know how to do this?</p>  <p>I've got my application to build the website using a website.publishproj (found at the tutorial) so I have my zip file   what I am now lacking  is how to upload the zip file to azure using the already existing powershell that comes with the 2.8.2 SDK.</p>  <p>So far i've added the below code under the Import-Module statement:</p>  <pre><code>C:\\\""Program Files (x86)\""\\MSBuild\\14.0\\bin\\msbuild.exe 'C:\\Source\\website.publishproj' /T:Package /P:PackageLocation=\"".\\dist\"" /P:_PackageTempDir=\""packagetmp\"" $websitePackage = \""C:\\Source\\dist\\website.zip\"" </code></pre>""",azure-web-app-service
16122160,"Uploading images to azure blob storage with windows phone 7 <p>I have been trying for the longest while to find a way to upload images using windows azure blob storage with windows phone. I tried using windows azure storage client for windows phone but that does not seem to be working any more. I also tried about 2 other nuget packages and I also tried a web service that will handle the upload for but that didn't work out well as I wasn't completely how I should connect the web service to my phone app. I tried also uploading it using windows azure mobile service. Could anyone give me some pointers on how I should go about getting this to work?</p>  <p>Problem with windows azure storage client for windows phone </p>  <p>Install-Package Phone.Storage -Version 1.0.1 Attempting to resolve dependency 'SilverlightActivator (≥ 1.0.3)'. 'Phone.Storage 1.0.1' already installed. ProjectName already has a reference to 'Phone.Storage 1.0.1'.</p>  <p>But no reference added to visible in reference folder</p>  <p>Problem with mobile services  Tried this: <a href=\http://www.windowsazure.com/en-us/develop/mobile/tutorials/upload-images-to-storage-dotnet/\"" rel=\""nofollow\"">http://www.windowsazure.com/en-us/develop/mobile/tutorials/upload-images-to-storage-dotnet/</a></p>  <p>but could not find a Storage client library for Windows phone 7</p>""",azure-storage
52147350,asp.net core 2.0 console application filenotfoundexception system.runtime 4.2.0.0 <p>I created a simple console application using asp.net core 2.0. I published it from vs2017 to a folder and copied the contents to azure vm folder. when i run the console application i am getting the following error:</p>  <pre><code>Unhandled Exception: System.IO.FileNotFoundException: Could not load file or ass embly 'System.Runtime  Version=4.2.0.0  Culture=neutral  PublicKeyToken=b03f5f7f 11d50a3a' or one of its dependencies. The system cannot find the file specified. </code></pre>  <p>Can anyone help me with this?</p>  <p>Thanks</p>,azure-virtual-machine
57195219,"Unable to select GitHub organization in Azure App Service Deployment Center <p>I'm trying to set up GitHub deployments for an ASP.NET Core web application in Azure App Service Deployment Center.</p>  <p>I'm stuck at the step where I'm supposed to select my GitHub organization - the dropdown is empty:</p>  <p><a href=\https://i.stack.imgur.com/uWnsO.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/uWnsO.png\"" alt=\""Deployment Center\""></a></p>  <p>The help says to check Azure App Service permissions on GitHub. However everything looks fine in my <code>GitHub Setttings &gt; Applications &gt; Authorized OAuth Apps &gt; Azure App Service</code> (these permissions were automatically set up when I selected GitHub as Source Control in the Deployment Center):</p>  <p><a href=\""https://i.stack.imgur.com/Egijg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Egijg.png\"" alt=\""GitHub Settings\""></a></p>  <p>I wasn't able to find any other relevant settings page  neither in the global GitHub settings  nor on the specific repository.</p>""",azure-web-app-service
42757214,Random port number appended to URL when browsing Web App in Azure <p>Whenever I browse to an <strong>Azure Web App</strong> I've published  a <strong>random port number</strong> (e.g. <strong>44893</strong>) is appended to the URL  resulting in a <em>Page cannot be displayed</em> error. The web app uses HTTPS.</p>  <p>What causes this?</p>,azure-web-app-service
43749592,"Azure Web App returning wrong SSL certificate <p>We have configured one IP-based SSL certificate for our app (e.g. mydomain.com) and a number of SNI certificates for customers to use at custom domains (e.g. www.theirdomain.com) plus a www for our site (www.mydomain.com). Those domains have CNAME records pointing to oursite.azurewebsites.net. We have been configured this way for quite a while with the exception of recently changing the spoketraining.com from SNI to IP because something over the weekend made that stop working. </p>  <p>We are suddenly having an issue where users are getting the wrong SSL certificates when they make requests from one of the CNAME URLs. They go to <a href=\https://www.theirdomain.com\"" rel=\""nofollow noreferrer\"">https://www.theirdomain.com</a> and get the certificate for <a href=\""https://www.ourdomain.com\"" rel=\""nofollow noreferrer\"">https://www.ourdomain.com</a>. In Chrome this gives an ERR_CERT_COMMON_NAME_INVALID. In Edge they get \""There's a problem with this website's security certificate.\"" Most users get it all the time  but it's not consistent. In our testing  we see that it mostly fails the first few times you go to the site  but then it may load part of the page and reject the API calls  and then it may work completely. Going to an incognito window usually makes it start again. When it does work  the browser shows the right certificate and that everything is good.</p>  <p>The way we've configured should work  right? Is there something more we should be doing to make this work?</p>""",azure-web-app-service
23696914,Getting upload progress using Azure Storage in Android <p>I'm uploading a file in my Android application. The code is pretty simple:</p>  <pre><code>    private boolean UploadFile(String fileLocation) {         try {              if (TextUtils.isEmpty(fileLocation)) {                 return false;             }              File fSrc = new File(fileLocation);              if (!fSrc.exists()) {                 return false;             }              boolean bReturn = AzureManager.init(this);             if (!bReturn) {                 return false;             }              String blobName = fSrc.getName();              InputStream in = new BufferedInputStream(new FileInputStream(fSrc));             CloudBlobContainer container = AzureManager.getCloudBlobClient().getContainerReference(AzureManager.getContainerName());             CloudBlockBlob blob = container.getBlockBlobReference(blobName);             blob.upload(in  fSrc.length());              in.close();             return true;         } catch (Exception e) {             //handle exception         }         return false;     } </code></pre>  <p>When I download from Azure   CloudBlockBlob has a download listener as:</p>  <pre><code>blob.setDownloadListener(eventListener); </code></pre>  <p>But how can I keep track of the progress when uploading?</p>,azure-storage
46154758,"serverless with azure functions and webpack <p>I'm wondering if there is anyone using serverless framework with azure functions and how you handle sharing code across functions &amp; bundling?</p>  <p>I'm converting hapi.js app to <a href=\https://github.com/serverless/serverless\"" rel=\""nofollow noreferrer\"">serverless</a> + <a href=\""https://github.com/serverless/serverless-azure-functions\"" rel=\""nofollow noreferrer\"">serverless-azure-functions</a> and I'm trying to bundle my code before deploying so I can use various <code>require</code> for reusable modules.</p>  <p>I found <a href=\""https://github.com/serverless-heaven/serverless-webpack\"" rel=\""nofollow noreferrer\"">serverless-webpack</a> and It create bundles that probably works on AWS Lambda but there is a problem on azure because of lack of <code>function.json</code> files (ex. <code>list-function.json</code>)  so the functions aren't visible at all inside azure-portal nor I can't invoke them.</p>  <p>Also found <a href=\""https://cmatskas.com/azure-functions-improvements-with-webpack/\"" rel=\""nofollow noreferrer\"">article</a> about this problem but It shows how to handle this with <code>azure-functions-cli</code> which only support Windows platform.</p>  <p>Best  JH</p>""",azure-functions
39430279,"How can I do Routing in Azure Functions? <p>I know that I can use url parameters like this: </p>  <pre><code>\myfunction?p=one&amp;p2=two\"" </code></pre>  <p>and in code that becomes</p>  <pre><code>request.query.p = \""one\""; </code></pre>  <p>but I would prefer to get it like this (express routing style):</p>  <pre><code>\""myfunction/:myvalue\"" </code></pre>  <p>and use this url:</p>  <pre><code>/myfunction/nine </code></pre>  <p>which becomes this in code: </p>  <pre><code>request.params.myvalue = \""nine\"" </code></pre>  <p>but I can't seem to find how to configure a route path like that in Azure Functions  any ideas or docs?</p>""",azure-functions
21356104,"TfvcTemplate.12.xaml missing in Source Control <p>I'm using the the hosted TFS from Microsoft at VisualStudio.com via VS2012</p>  <p>When I create a new Build Definition I'm presented with the following templates choose from:</p>  <p><img src=\https://i.stack.imgur.com/m709g.png\"" alt=\""enter image description here\""></p>  <p>If I select TfVcTemplate.12.xaml</p>  <p>my build comes up with the following warnings:</p>  <p><img src=\""https://i.stack.imgur.com/jjGk7.png\"" alt=\""enter image description here\""></p>  <p>So I'm thinking that I probably need to set some defaults in the template and everything should be fine  however when I go to Build Process Templates in the root of TFS Project I see can't see the template. No amount of get latest/shutdown/restart etc will bring it up.</p>  <p><img src=\""https://i.stack.imgur.com/Nirg8.png\"" alt=\""enter image description here\""></p>""",azure-devops
48955049,"VS Cloud Load Test - Could not locate directory/file <p>I'm trying to load test our application at work and I have created a web-test (coded web-test) that works perfectly locally.</p>  <p>It uses a helper class to create data that's required for the application like name  email etc (which must be unique for each application).</p>  <p>Name is returned by a method that resides in helper class as an object of Name class which is pretty basic contains 2 props First and Last. </p>  <pre><code>public static Name GetRandomName() {     // if (!File.Exists(@\..\\..\\..\\Apps-Load-Performance-Tests\\Data Files\\fNames_1.csv\"")) return new Name();      var allLines = File.ReadAllLines(@\""..\\..\\..\\Apps-Load-Performance-Tests\\Data Files\\fNames_1.csv\"");     var maxLength = allLines.Length;     var random = new Random();     return new Name     {         First = allLines[random.Next(maxLength)]          Last = allLines[random.Next(maxLength)]     }; } </code></pre>  <p>Problem is when I run a load test via Visual Studio cloud - it throws FileNotFoundException (fNames_1.csv)</p>  <p>In my test settings - I have 'Enable Deployment' checked and added the .csv file and the directory that contains the .csv file... but that doesn't seem to solve the problem.</p>  <p>I also tried adding [DeploymentItem()] attribute but no go...</p>  <p>What am I doing wrong? Any help or if someone can point me to right direction - I'd highly appreciate it. </p>  <p>Thanks in advance!</p>""",azure-devops
50488735,Exception during publishing web app to Azure <p>We have created a sample Asp.net Core application. When we tried to publish the application into Azure we got following exception.</p>  <p>Web deployment task failed. (The type initializer for 'Microsoft.Web.Deployment.DeploymentManager' threw an exception.)</p>  <p>We have tried some solutions posted in some blogs but none got the issue resolved. </p>,azure-web-app-service
52668098,"Azure V1 function on CosmosDB change feed triggers all changes when published <p>I have a function app that connects to the cosmosDB change feed  and it works well but I have an issue that when I publish the app  it processes changes for all documents currently in the monitored collection which seems wrong</p>  <p>The function is initialised as follows</p>  <pre><code> [FunctionName(\Function1\"")]         public static async Task RunAsync([CosmosDBTrigger(             databaseName: \""XXX\""              collectionName: \""YYY\""              ConnectionStringSetting = \""CosmosDb\""              LeaseCollectionName = \""leases\""  LeaseCollectionPrefix = \""cloud\"")]IReadOnlyList&lt;Document&gt; documents  TraceWriter log)         { } </code></pre>  <p>the only change I did was to change the LeaseCollectionPrefix  could that cause the trigger to receive changes for all documents in the collection because its seen as a new lease? </p>""",azure-functions
27185330,Upgrading from A-series to D-series Azure virtual machine <p>We have SQL Sever setup on A-series virtual machines. We are wanting to upgrade to the D-series virtual machine. Is it as simple as just upgrading the VM in Azure and clicking save or are there any other things I need to watch out for? I have heard of people having issues upgrading due to the level not being available in the cluster that their Virtual Machines sit in.</p>,azure-virtual-machine
15760152,"Windows Server 2008 R2 SP1 is not pinged <p>I created a VM on Windows Azure. My actions</p>  <p>1) \File and Printer Sharing (Echo Request - ICMPv4-In)\"" set On</p>  <p>2) Windows Wirewall set Off</p>  <p>It still does not ping.</p>  <p>UPD: The network is working properly.</p>""",azure-virtual-machine
55826682,"App Settings not being observed by Core WebJob <p>I have a Core WebJob deployed into an Azure Web App. I'm using <a href=\https://www.nuget.org/packages/Microsoft.Azure.WebJobs/3.0.6\"" rel=\""nofollow noreferrer\"">WebJobs version 3.0.6</a>.</p>  <p>I've noticed that changes to Connection Strings and App Settings (added via the Azure web UI) are not being picked up immediately by the WebJob code. </p>  <p>This seems to correlate with the same Connection Strings and App Settings not being displayed on the app's KUDU env page straight away (although I acknowledge this may be a red herring and could be some KUDU caching thing which I'm unaware of). </p>  <p>I've deployed a few non-Core WebJobs in the past and have not come across this issue so wonder if it's Core related? Although I can't see how that might affect configs showing up KUDU though.</p>  <p>I was having this issue the other day (where the configs were not getting picked up by the WebJob or shown in KUDU) and was getting nowhere  so left it. When I checked back the following day  the configs were now correctly showing in KUDU and being picked up by the WebJob. So I'd like to know what has happened in the meantime which means the configs are now being picked up as expected.</p>  <p>I've tried re-starting the WebJob and re-starting the app after making config changes but neither seem to have an effect. </p>  <p>It's worth also noting that I'm <strong>not</strong> loading <code>appSettings.json</code> during the program setup. That being said  the connection string being loaded was consistenly the connection string from that file i.e. my local machine SQL Server/DB. My understanding was always that the anything in the Azure web UI would override any equivalent settings from config files. <a href=\""https://stackoverflow.com/a/42216887/842238\"">This post from David Ebbo</a> indicates that by calling <code>AddEnvironmentVariables()</code> during the setup will cause the Azure configs to be observed  <strong>but that doesn't seem to be the case here</strong>. Has this changed or is it loading the configs from this file by convention because it can't see the stuff from Azure?</p>  <p>Here's my WebJob Program code:</p>  <pre><code>    public static void Main(string[] args)     {       var host = new HostBuilder()       .ConfigureHostConfiguration(config =&gt;       {         config.AddEnvironmentVariables();       })       .ConfigureWebJobs(webJobConfiguration =&gt;         {           webJobConfiguration.AddTimers();           webJobConfiguration.AddAzureStorageCoreServices();         }       )       .ConfigureServices((context  services) =&gt;       {         var connectionString = context.Configuration.GetConnectionString(\""MyConnectionStringKey\"");          services.AddDbContext&lt;DatabaseContext&gt;(options =&gt;           options             .UseLazyLoadingProxies()             .UseSqlServer(connectionString)         );          // Add other services       })       .Build();        using(host)       {         host.Run();       }     } </code></pre>  <p>So my questions are:</p>  <ul> <li>How quickly should configs added/updated via the Azure web UI be displayed in KUDU?</li> <li>Is the fact they're not showing in KUDU related to my Core WebJob also not seeing the updated configs?</li> <li>Is appSettings.json getting loaded even though I'm not calling <code>.AddJsonFile(\""appSettings.json\"")</code>?</li> <li>What can I do to force the new configs added via Azure to be available to my WebJob immediately?</li> </ul>""",azure-web-app-service
53396173,Azure Service Bus in Azure Function <p>I'm using Service Bus trigger in Azure Functions v2.0. In the previous version i have used Brokered Message and there are no problems with this. But as i moved to v2.0 i need to use Message instead of Brokered Message. And once i called </p>  <pre><code>await queueClient.CompleteAsync(message.SystemProperties.LockToken); </code></pre>  <p>i get an exception which says: </p>  <blockquote>   <p>The lock supplied is invalid. Either the lock expired  or the message has already been removed from the queue  or was received by a different receiver instance.   I have configured my Queue Client as follows:</p> </blockquote>  <pre><code>var queueClient = new QueueClient(serviceBusString  MessageQueueName); </code></pre>  <p>Does anyone face this issue? Are there any workarounds ?</p>,azure-functions
12827059,"Accessing Windows Azure Queues from client side javascript/jquery <p>For a UI feature  I need to read from a Windows Azure queue and update the UI accordingly. </p>  <p>I see plenty of node.js examples  but nothing using pure Javascript or Jquery. (<a href=\http://azurequery.codeplex.com/documentation\"" rel=\""nofollow\"">azureQuery</a> comes close  but no queue functionality yet and it needs a Web API to talk to) </p>  <p>This is a hybrid web app using both asp.net and MVC 4. This particular page is generated  using MVC 4.</p>  <p>Any suggestions would be appreciated.</p>  <p>Roberto (PS. being able to write to the queue would also be nice)</p>""",azure-storage
42201570,how to set retention period for azure storage tables? <p>I have a azure table used for metric data collection and I want to set some retention period for eg: if retention period is 7 then table should have last 7 day data in it.</p>  <p>Is there any option available.</p>,azure-storage
56273370,JavaScript HTTP Trigger Azure fuction <p>I am trying to create a new Azure function (HTTP Trigger) There used to be an option to choose language but now it seems to default to C# and I'f like to create a JavaScript function.</p>  <p>I tried deleting the C# files and replacing them with JavaScript but that then gives me a 404 when I try to run. Any idea how I can create a JavaScript function?</p>,azure-functions
8541242,"Azure Website with User Editable Content <p>I have an ASP.Net MVC website running on a shared IIS7 host that allows users to create their own landing page.  The website allows users to edit the content  style (edit css via a UI) as well as uploading images.</p>  <p>I am considering migrating to Windows Azure to improve scalability and improve database backups (using SQL Azure Data Sync see <a href=\http://social.technet.microsoft.com/wiki/contents/articles/sql-azure-backup-and-restore-strategy.aspx\"" rel=\""nofollow\"">http://social.technet.microsoft.com/wiki/contents/articles/sql-azure-backup-and-restore-strategy.aspx</a>  I am limited in the SQL backup plans offered with my host) </p>  <p>One stumbling block is  since the clients can upload images and edit css files  these files will need to be stored in the blob storage or the database (any other options?).  I don't want to use the database because database storage as it is more expensive.  </p>  <p>However  if these files are stored in blob storage  how will this impact the performance of the website given the files (css  images) are fetched from the blob storage instead of being read from the same disk as the website? I know browser caching will reduce the requests for these files  but what about first time requests?</p>""",azure-storage
52760789,Azure App Service: Method from assembly does not have an implementation at <p>We have a WebAPI which runs locally under IIS  but which errors out when deployed to an Azure App Service. This API used to work  until we upgraded from StackExchange.Redis 1.2 to 2+. I copied the code from the App Service and ran it under local IIS  which worked as expected. Any ideas what might be causing this?</p>  <pre><code>Method 'ExecuteAuthorizationFilterAsync' in type  'ProjectAlpha.Api.Filters.TokenAuthorizationFilterAttribute' from assembly  'ProjectAlpha.Api  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null'  does not have an implementation.at System.Web.HttpApplicationFactory. EnsureAppStartCalledForIntegratedMode(HttpContext context  HttpApplication  app)at System.Web.HttpApplication.RegisterEventSubscriptionsWithIIS(IntPtr  appContext  HttpContext context  MethodInfo[] handlers)at  System.Web.HttpApplication.InitSpecial(HttpApplicationState state   MethodInfo[] handlers  IntPtr appContext  HttpContext context)at  System.Web.HttpApplicationFactory.GetSpecialApplicationInstance(IntPtr  appContext  HttpContext context)at  System.Web.Hosting.PipelineRuntime.InitializeApplication(IntPtr appContext)  Method 'ExecuteAuthorizationFilterAsync' in type  'ProjectAlpha.Api.Filters.TokenAuthorizationFilterAttribute' from assembly  'ProjectAlpha.Api  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null'  does not have an implementation.at  ProjectAlpha.Api.WebApiApplication.Application_Start() </code></pre>,azure-web-app-service
54782922,How to configure mail on Azure SQL Database <p>We are moving from Microsoft SQL Server 2012 (SP1) - 11.0.3128.0 (X64)  to  Microsoft SQL Azure (RTM) - 12.0.2000.8 </p>  <p>Previously we send mail from database mail if a particular table have not updated in a particular time interval.</p>  <p>But i tried to do the same on Azure mail but seems like this functionality is not available on this.</p>,azure-storage
54135528,Azure storage queue max concurrent clients <p>I have an azure function with a servicebus trigger. I only want x numbers og function instances to run concurrently. This is done with the maxConcurrentCalls=x in the host file. Can this also be achieved with Azure Storage Queues?</p>,azure-functions
47431410,"Sub classing MultipartStreamProvider fails in Visual Studio c#? <p>I am trying to subclass MultipartStreamProvider in Visual Studio  </p>  <pre><code>System.TypeLoadException: Method 'GetStream' in type       'Uploadfunction.InMemoryMultipartFormDataStreamProvider' from assembly       'Uploadfunction  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null'       does not have an implementation.   in Microsoft.NET.SDK.Functions.Build.targets line 31 </code></pre>  <p>My line 31 is like this </p>  <pre><code>        &lt;BuildFunctions   TargetPath=\$(TargetPath)\""   OutputPath=\""$(TargetDir)\""/&gt; </code></pre>  <p></p>  <p>I have System.net Assemblies and have also downloaded Microsoft.net.sdk.functions (1.0.6).</p>  <p>My function class looks like this - </p>  <pre><code>public static class UploadFunction {     [FunctionName(\""UploadFunction\"")]     public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = null)]HttpRequestMessage req  TraceWriter log)     {       //Check if the request contains multipart/form-data.         if (!req.Content.IsMimeMultipartContent(\""form-data\""))         {             return req.CreateResponse(HttpStatusCode.UnsupportedMediaType);         }        var provider = await req.Content.ReadAsMultipartAsync(new InMemoryStream());      return req.CreateResponse(HttpStatusCode.OK  \""File Uploaded\"");   } </code></pre>  <p>And my InMemoryStream class looks like this.</p>  <pre><code>public class InMemoryStream : System.Net.Http.MultipartStreamProvider {     public override Stream GetStream(HttpContent parent  HttpContentHeaders headers)     {          MemoryStream s = new MemoryStream();         return s;     }   } </code></pre>""",azure-functions
52746188,"Rewriting default azurewebsites to custom domains <p>I have few web apps (REST service that uses swagger)) hosted on Azure with their default domains as <a href=\https://xyz-test.azurewebsites.net/swagger/ui/index\"" rel=\""nofollow noreferrer\"">https://xyz-test.azurewebsites.net/swagger/ui/index</a>. I need to rewrite them to custom domain (already exists)   example: newdomain.net I tried the adding the following to web.config:</p>  <pre><code>&lt;rewrite&gt;   &lt;rules&gt;     &lt;rule name=\""Redirect requests to default azure websites domain\"" stopProcessing=\""true\""&gt;       &lt;match url=\""(.*)\""/&gt;       &lt;conditions logicalGrouping=\""MatchAny\""&gt;         &lt;add input=\""{HTTP_HOST}\"" pattern=\""^xyz\\.azurewebsites\\.net$\""/&gt;       &lt;/conditions&gt;       &lt;action type=\""Rewrite\"" url=\""https://newdomain.net/{R:0}\"" appendQueryString=\""true\"" redirectType=\""Permanent\""/&gt;     &lt;/rule&gt;        &lt;/rules&gt; &lt;/rewrite&gt; </code></pre>  <p>This code redirects to newdomain.net  however if I try to do <em>newdomain.net/swagger</em>  it would throw the 404 error. I'm new to doing this. </p>  <p>What should be my correct approach so that instead of using <a href=\""https://xyz-test.azurewebsites.net/swagger/ui/index\"" rel=\""nofollow noreferrer\"">https://xyz-test.azurewebsites.net/swagger/ui/index</a>  I should be able to use <a href=\""https://newdomain.net/xyz-test/swagger/ui/index\"" rel=\""nofollow noreferrer\"">https://newdomain.net/xyz-test/swagger/ui/index</a> to make API calls</p>  <p>(note: mydomain.com will be used by more than one service.  example: <a href=\""https://newdomain.net/abc-test/swagger/ui/index\"" rel=\""nofollow noreferrer\"">https://newdomain.net/abc-test/swagger/ui/index</a>)</p>""",azure-web-app-service
48443690,"How to resolve AbstractMethod Error in blob encryption? <p>I want to upload blob into azure blob storage by applying encryption for it. so i have tried to do it using following code:</p>  <pre><code> File f=new File(\/home/prospera-user15/Desktop/test/download.jpeg\"");          CloudStorageAccount account = CloudStorageAccount.parse(storageConnectionString);         CloudBlobClient serviceClient = account.createCloudBlobClient();         // Container name must be lower case.         CloudBlobContainer container = serviceClient.getContainerReference(\""upload1\"");         container.createIfNotExists();         CloudBlockBlob blob = container.getBlockBlobReference(\""megha\"");         final KeyPairGenerator keyGen = KeyPairGenerator.getInstance(\""RSA\"");         keyGen.initialize(2048);         final KeyPair wrapKey = keyGen.generateKeyPair();          RsaKey key = new RsaKey(\""RSA\"" wrapKey);         System.out.println(\""Uploading the encrypted blob.\"");         BlobEncryptionPolicy policy = new BlobEncryptionPolicy(key  null);         BlobRequestOptions options = new BlobRequestOptions();         options.setEncryptionPolicy(policy);         AccessCondition accessCondition = null;         OperationContext opContext = null;         try{             blob.upload(new FileInputStream(f)  f.length()  accessCondition  options  opContext);         }catch (IOException e) {             System.out.println(e.getMessage());         }catch (StorageException e) {             System.out.println(e.getErrorCode());         } </code></pre>  <p><img src=\""https://i.stack.imgur.com/w8g2H.png\"" alt=\""for above code i got following exception:\""></p>""",azure-storage
56179837,"How to get / generate access token from azure OAuth 2.0 token (v2) endpoints? <p>I want to get an access token from given URL: </p>  <pre><code>https://login.microsoftonline.com/{AzureTenantId}/oauth2/v2.0/token </code></pre>  <p>I am passing the following parameters  as mentioned int he Microsoft docs: <code>client_id</code>  <code>scope</code>  <code>client_secret</code>  <code>grant_type</code>.</p>  <p>When I hit this URL  I get a \400 Bad Request\"" response.</p>  <p>When I try the same from Postman  it succeeds and provides me an access token:</p>  <p><a href=\""https://i.stack.imgur.com/LjWKY.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/LjWKY.png\"" alt=\""success postman request\""></a></p>  <p>But not from my code:</p>  <pre><code>public async Task&lt;string&gt; GetAuthorizationToken(string clientId  string ServicePrincipalPassword  string AzureTenantId) {             var result = \""\"";             var requestURL = \""https://login.microsoftonline.com/{AzureTenantId}/oauth2/v2.0/token\"";             var _httpClient = new HttpClient();              var model = new {                 client_id = clientId                  scope = \""{clentID}/.default\""                  client_secret = ServicePrincipalPassword                  grant_type = \""client_credentials\""             };              HttpContent httpContent = new StringContent(JsonConvert.SerializeObject(model)  System.Text.Encoding.UTF8  \""application/x-www-form-urlencoded\"");              var httpRequestMessage = new HttpRequestMessage(HttpMethod.Post  new Uri(requestURL)) {                 Content = httpContent             };              using (var response = await _httpClient.SendAsync(httpRequestMessage)) {                 if (response.IsSuccessStatusCode) {                     var responseStream = await response.Content.ReadAsStringAsync();                     return result;                 } else {                     return result;                 }             } </code></pre>""",azure-devops
49120735,Azure load balancer with NAT rule hiding port for RDP <p>I have internet facing Azure load balancer with public static IP (call it PIP) and I added a NAT rule - forward TCP port 12345 to local (subnet's IP) 10.2.2.2:3389 (VM that doesn't have public IP). And I'm trying to set NSG for subnet and VM's NIC.</p>  <p>subnet's NSG rules (all TCP):</p>  <ul> <li>100: Source PIP:* => 10.2.2.2:3389 (from load balancer IP to VM's local IP)</li> <li>120: Source Internet:12345 => 10.1.2.4:3389</li> </ul>  <p>VM's NSG rules:</p>  <ul> <li>100: PIP:* => 10.2.2.2:3389</li> </ul>  <p>and here's the problem: if I use Network Watcher's IP flow verify and set local IP to 10.2.2.2:3389  Remote IP:[PIP:12345] I get green light. Same with setting both ports (local and remote) to 3389. But when I'm trying to Remote Desktop to that VM from outside I get a connection error!</p>  <p>I have no idea why. The VM is up and running  all good here.</p>,azure-virtual-machine
47217600,"String reference not set to an instance of a String. Parameter name: s <p>After upgrading from VS 2013 Update 4 to Update 5 I am using VSTS 2015. We get the following error in Visual Studio 2013: \String reference not set to an instance of a String. Parameter name: s\""</p>  <p>It happens all the time when doing any of the following in Team Explorer: * Click \""Home\""  \""Refresh\""  then \""Builds\"" * Click \""Home\""  \""Pending changes\"" giving this error message.</p>""",azure-devops
57490505,"Query Azure SQL Database from local Azure Function using Managed Identities <p>I want to query an Azure SQL Database from an Azure Function executing on my machine in debug using Managed Identities (i.e. the identity of my user connected to Visual Studio instead of providing UserId and Password in my connection string).</p>  <p>I followed <a href=\https://docs.microsoft.com/fr-fr/azure/app-service/app-service-web-tutorial-connect-msi\"" rel=\""nofollow noreferrer\"">this tutorial</a> on Microsoft documentation so my Azure SQL Server has an AD user as admin which allowed me to give rights (db_datareader) to an Azure AD group I created with my Azure Function Identity and my user in it (and also my Function App deployed in Azure).</p>  <p>If I deploy and run in Azure my Azure Function  it is able to query my database and everything is working fine. But when I run my Azure Function locally  I have the following error : </p>  <blockquote>   <p>Login failed for user 'NT AUTHORITY\\ANONYMOUS LOGON'.</p> </blockquote>  <p>The code of my function is the following:</p>  <pre class=\""lang-cs prettyprint-override\""><code>    public async Task&lt;IActionResult&gt; Run(         [HttpTrigger(AuthorizationLevel.Function  \""get\""  \""post\""  Route = \""test\"")] HttpRequest req          ILogger log)     {         log.LogInformation(\""C# HTTP trigger function processed a request.\"");           using (var connection = new SqlConnection(Environment.GetEnvironmentVariable(\""sqlConnectionString\"")))         {             connection.AccessToken = await (new AzureServiceTokenProvider()).GetAccessTokenAsync(\""https://database.windows.net\"");             log.LogInformation($\""Access token : {connection.AccessToken}\"");             try             {                 await connection.OpenAsync();                 var rows = await connection.QueryAsync&lt;Test&gt;(\""select top 10 * from TestTable\"");                 return new OkObjectResult(rows);             }             catch (Exception e)             {                 throw e;             }          }     } </code></pre>  <p>The code retrieves a token correctly  the error occurs on line <code>await connection.OpenAsync()</code>. </p>  <p>If I open the database in Azure Data Studio with the same user than the one connected to Visual Studio (which is member of the AD group with the rights on the database)  I can connect and query the database without any issue.</p>  <p>Is it a known issue or am I missing something here ?</p>""",azure-functions
53412259,"Azure Function Docker not working with http trigger <p>Recently I have created a docker image with Azure Function (Node) having HttpTrigger. This is a basic HttpTrigger which generate by default. I'm developing this on Macbook Pro (MoJave) and I have following tools installed.</p>  <p>NodeJs - node/10.13.0 .NET Core 2.1 for macOS Azure Function core tools (via brew)</p>  <p>When I run the function locally with \func host start\""  it all works fine and I could see the function loading messages. Also I was able to execute the Azure function with trigger endpoint.However  when I try to build the Docker container and run the same  I can load the home page of the app but could not reach the function endpoint. In the log I could only see following;</p>  <pre><code>Hosting environment: Production Content root path: / Now listening on: http://[::]:80 Application started. Press Ctrl+C to shut down. </code></pre>  <p>My Docker file is as below (generated by Azure core tools);</p>  <pre><code>FROM mcr.microsoft.com/azure-functions/node:2.0 ENV AzureWebJobsScriptRoot=/home/site/wwwroot COPY . /home/site/wwwroot </code></pre>  <p>When I try to to use 'microsoft/azure-functions-runtime:v2.0.0-beta1' as base image  then I can see the function loading and could able to access the http trigger also. </p>  <p>Is there anything missing or do I need to use a different image?</p>""",azure-functions
56394509,"Azure container fails to configure and then 'terminated' <p>I have a Docker container with an ASP.NET (.NET 4.7) web application. The Docker image works perfectly using our local docker deployment  but will not start on Azure and I cannot find any information or diagnostics on why that might be.</p>  <p>From the log stream I get </p>  <pre><code>31/05/2019 11:05:34.487 INFO - Site: ip-app-develop-1 - Creating container for image: 3tcsoftwaredockerdevelop.azurecr.io/irs-plus-app:latest-develop. 31/05/2019 11:05:34.516 INFO - Site: ip-app-develop-1 - Create container for image: 3tcsoftwaredockerdevelop.azurecr.io/irs-plus-app:latest-develop succeeded. Container Id 1ea16ee9f5f128f14246fefcd936705bb8a655dc6cdbce184fb11970ef7b1cc9 31/05/2019 11:05:40.151 INFO - Site: ip-app-develop-1 - Start container succeeded. Container: 1ea16ee9f5f128f14246fefcd936705bb8a655dc6cdbce184fb11970ef7b1cc9 31/05/2019 11:05:43.745 INFO - Site: ip-app-develop-1 - Application Logging (Filesystem): On 31/05/2019 11:05:44.919 INFO - Site: ip-app-develop-1 - Container ready 31/05/2019 11:05:44.919 INFO - Site: ip-app-develop-1 - Configuring container 31/05/2019 11:05:57.448 ERROR - Site: ip-app-develop-1 - Error configuring container 31/05/2019 11:06:02.455 INFO - Site: ip-app-develop-1 - Container has exited 31/05/2019 11:06:02.456 ERROR - Site: ip-app-develop-1 - Container customization failed 31/05/2019 11:06:02.470 INFO - Site: ip-app-develop-1 - Purging pending logs after stopping container 31/05/2019 11:06:02.456 INFO - Site: ip-app-develop-1 - Attempting to stop container: 1ea16ee9f5f128f14246fefcd936705bb8a655dc6cdbce184fb11970ef7b1cc9 31/05/2019 11:06:02.470 INFO - Site: ip-app-develop-1 - Container stopped successfully. Container Id: 1ea16ee9f5f128f14246fefcd936705bb8a655dc6cdbce184fb11970ef7b1cc9 31/05/2019 11:06:02.484 INFO - Site: ip-app-develop-1 - Purging after container failed to start </code></pre>  <p>After several restart attempts (manual or as a result of re-configuration) I will simply get:</p>  <pre>2019-05-31T10:33:46  The application was terminated.</pre>  <p>The application then refuses to even attempt to start regardless of whether I use the az cli or the portal.</p>  <p>My current logging configuration is: </p>  <pre><code>{   \applicationLogs\"": {     \""azureBlobStorage\"": {       \""level\"": \""Off\""        \""retentionInDays\"": null        \""sasUrl\"": null     }      \""azureTableStorage\"": {       \""level\"": \""Off\""        \""sasUrl\"": null     }      \""fileSystem\"": {       \""level\"": \""Verbose\""     }   }    \""detailedErrorMessages\"": {     \""enabled\"": true   }    \""failedRequestsTracing\"": {     \""enabled\"": false   }    \""httpLogs\"": {     \""azureBlobStorage\"": {       \""enabled\"": false        \""retentionInDays\"": 2        \""sasUrl\"": null     }      \""fileSystem\"": {       \""enabled\"": true        \""retentionInDays\"": 2        \""retentionInMb\"": 35     }   }    \""id\"": \""/subscriptions/XXX/resourceGroups/XXX/providers/Microsoft.Web/sites/XXX/config/logs\""    \""kind\"": null    \""location\"": \""North Europe\""    \""name\"": \""logs\""    \""resourceGroup\"": \""XXX\""    \""type\"": \""Microsoft.Web/sites/config\"" } </code></pre>  <p>Further info on the app:  - deployed using a docker container  - docker base image mcr.microsoft.com/dotnet/framework/aspnet:4.7.2  - image entrypoint c:\\ServiceMonitor.exe w3svc  - app developed in ASP.NET 4.7  - using IIS as a web server</p>  <p><strong>Questions:</strong></p>  <p>How can I get some diagnostics on what is going on to enable me to determine why the app is not starting?</p>  <p>Why does the app refuse to even attempt to restart after a few failed attempts?</p>""",azure-web-app-service
55479062,"Why Azure app service restarts when swapping slots? <p>After having this issue in production for a long time  and having read anything i can find about (such as <a href=\https://stackoverflow.com/questions/45077899/preventing-staging-site-restart-during-a-swap\"">this</a> or <a href=\""https://stackoverflow.com/questions/29130396/why-would-azure-be-restarting-website-when-i-do-a-deployment-slot-swap?rq=1\"">this</a> or <a href=\""https://stackoverflow.com/questions/45021644/is-there-way-to-determine-why-azure-app-service-restarted/45242214#45242214\"">that</a>)  i made a simple test.</p>  <ol> <li>Create an empty asp.net website</li> <li>in Application_Start  send an email or message (i've used PushBullet) to you so you know when the app starts</li> <li>Create a new app service plan and resource group</li> <li>Create the website on Azure and publish it</li> <li>Create a staging deployment slot</li> <li>Swap staging/production</li> <li>Publish the website again so both slots have the same version of the website</li> </ol>  <p>So i have an empty website  no connectionstring  no slot setting : <a href=\""https://i.stack.imgur.com/1g1cj.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/1g1cj.png\"" alt=\""no change in both slots\""></a></p>  <p>When i click swap  I will get notifications that slots restart (at least once each).</p>  <p>Why is this happening ?</p>  <p>UPDATE:</p>  <p>After studying Mohit's answer  i need some more clarifications.</p>  <ul> <li><p>We send the notification in the Application_Start method  which is triggered by the AppInit event if i understand correctly.</p></li> <li><p>I do not understand the behavior you explain. The order seems very important to ensure no downtime  yet you say it's not necessarily in that order. Why is it required to restart the app domain for the production slot ? Why would users get annoyed that the site is down (it should not) ?</p></li> <li><p>What is the \""new swap\"" feature ? What's the difference with the \""old swap\"" ? For my tests  i just swapped using the portal.</p></li> <li><p>You mention the \""new swap\"" pauses before swap. I suppose it just means it waits for the applicationInitialization to complete (eg HTTP 200 on /) ?</p></li> <li><p>I've done some more testing since yesterday. In the Application_Start method  i've added some Thread.Sleep to make app startups longer. However  when i swap i see no downtime on either staging or production. Shouldn't i experience downtimes on staging  at least for the duration of my app startup ? Does this mean the slot that is warmed up then swapped with production is in fact another temporary slot that is neither staging nor prod ?</p></li> </ul>""",azure-web-app-service
44247261,"How do I apply grayscale to my image with SimpleFilters in C#? <p>I am creating a function in Azure that takes an image and resizes it + makes it grayscale. I'm currently using this function:</p>  <pre><code>#r \System.Drawing\""  using ImageResizer; using ImageResizer.Plugins.SimpleFilters; using System.Drawing; using System.Drawing.Imaging;  public static void Run(Stream inputImage  string imageName  Stream  resizedImage  TraceWriter log) {   log.Info($\""C# Blob trigger function Processed blob\\n Name:{imageName} \\n    Size: {inputImage.Length} Bytes\"");    var settings = new ImageResizer.ResizeSettings{     MaxWidth = 400      Format = \""png\""   };    // Add the grayscale filter to the image   inputImage.filters.Add(GrayscaleNTSC());    ImageResizer.ImageBuilder.Current.Build(inputImage  resizedImage  settings);  } </code></pre>  <p>I'm importing the Plugins.SimpleFilters but I don't know how to use it in C#. The project site provides examples in pure HTML.</p>  <p>Do you know how to grayscale the image?</p>  <p>I get the following error: The name 'GrayscaleNTSC' does not exist in the current context</p>  <p>The packages I'm using are:</p>  <pre><code>\""dependencies\"": {   \""ImageResizer\"": \""4.0.5\""    \""ImageResizer.Plugins.SimpleFilters\"": \""4.0.5\"" } </code></pre>""",azure-functions
49455319,Duplicate existing running Virtual Machine - Python SDK <p>Does anyone have experience with the Python SDK (v: v2.0.0rc6) and cloning/duplicating running VM's into another resource group?</p>  <p>getting the OS disk to start. Will need the data disk as well</p>  <pre><code>managed_disk = self.compute_client.disks.get(resource_group_name=source_rg_name  disk_name=vm.storage_profile.os_disk.name) </code></pre>  <p>make a snapshot of the os disk. </p>  <pre><code>self.compute_client.snapshots.create_or_update(     self.config.resource_group_name      'SNAPSHOT-' + virtual_machine      {         'location': managed_disk.location          'creation_data': {             'create_option': 'Copy'              'source_uri': managed_disk.id         }     } ) </code></pre>  <p>create the VM. Throws exception below.</p>  <pre><code>result = self.compute_client.virtual_machines.create_or_update(     self.config.cybric_resource_group_name      virtual_machine      azure.mgmt.compute.models.VirtualMachine(         location=vm.location          os_profile=vm.os_profile          hardware_profile=vm.hardware_profile          network_profile=azure.mgmt.compute.models.NetworkProfile(             network_interfaces=[                 azure.mgmt.compute.models.NetworkInterfaceReference(                     id=nic_obj['id']                      primary=True                 )              ]          )          storage_profile=azure.mgmt.compute.models.StorageProfile(         os_disk=azure.mgmt.compute.models.OSDisk(             caching=azure.mgmt.compute.models.CachingTypes.none              create_option=azure.mgmt.compute.models.DiskCreateOptionTypes.attach              name=dup_virtual_machine              managed_disk=azure.mgmt.compute.models.ManagedDiskParameters(                 id=managed_disk.id             )          )          image_reference = azure.mgmt.compute.models.ImageReference(             publisher=vm.storage_profile.image_reference.publisher              offer=vm.storage_profile.image_reference.offer              sku=vm.storage_profile.image_reference.sku              version=vm.storage_profile.image_reference.version          )      )      )  ) </code></pre>  <p><em>Exception:</em></p>  <blockquote>   <p>Failed to create virtual machines: Azure Error: InvalidParameter   Message: Cannot attach an existing OS disk if the VM is created from a   platform or user image. Target: osDisk</p> </blockquote>,azure-virtual-machine
44318005,CloudTableClient client side timeout <p>When using a CloudTableClient  is there a way to specify a <i>client</i> side timeout?</p>  <p>The TableRequestOptions RetryPolicy and ServerTimeout control the number of retry attempts  the delay between attempts  and the storage service side timeout  but don't seem to cover a client side per-attempt timeout (like the HttpClient.Timeout property).</p>  <p>My concern with relying on the ServerSideTimeout is with delays connecting to the actual server.</p>,azure-storage
49779302,"Azure Functions returning Error : Keyword not supported: 'metadata' <p>I have an azure application that consists of an API application  Website  and Functions (originally webjobs).<br> All three use the same backend dlls to do all the heavy lifting and database work.  The api  website and functions are just shells.</p>  <p>My azure functions were working correctly and I updated the backend dlls and republished.  Since then I have been getting the \Keyword not supported: 'metadata'.\"" error everytime I try to insert records into the database.  Since the functions are nothing but shells for functionality in the API application and the Website I ran the same functionality from them without issue.  I even ran it from our integration test project also working just fine.</p>  <p>I know that Azure Functions can occasionally get \""Stuck\"" so I deleted and recreated it but still had the issue.  I am using EntityFramework 6.2 My connection string includes the metadata information and I changed the string to properly include the \"" . </p>  <p>example of my connection string (all caps are masked values)</p>  <pre><code>metadata=res://*/Model.MYMODEL.csdl|res://*/Model.MYMODEL.ssdl|res://*/Model.MYMODEL.msl;provider=System.Data.SqlClient;provider connection string=\""Server=tcp:MYDBAZURE.database.windows.net 1433;Database=MYDB;User ID=MYUSERNAME;Password=MYPASSWORD;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;\"" </code></pre>  <p>I know that the azure functions rely on some underling dlls and components I can not change so I am thinking this might be the issue.  </p>""",azure-functions
48950264,"Azure Created Image Without Generalizing <p>So I made the mistake of trying to capture an image of my VM without first running sysprep /generalize on it. Now I have a VM I can't start and an image I can't create a VM from. </p>  <p>Is there any way I can restore my original VM so I can create a valid image from it?</p>  <p>I saw this blog post <a href=\https://blogs.technet.microsoft.com/shwetanayak/2017/03/19/captured-the-virtual-machine-didnt-intend-to-generalize-it-now-what/\"" rel=\""nofollow noreferrer\"">https://blogs.technet.microsoft.com/shwetanayak/2017/03/19/captured-the-virtual-machine-didnt-intend-to-generalize-it-now-what/</a> that seems to imply that I can  but it's solution says to create a copy of a VHD using a snapshot. When I try to create the snapshot  nothing shows up in the Source Disk managed disks drop down.</p>""",azure-virtual-machine
41243172,"CreateIfnotExists throws a connection error <p>CreateIfNotExists method throws an error: </p>  <blockquote>   <p>No connection could be made because the target machine actively refused it 52.140.168.120:443</p> </blockquote>  <p>when an Application pool identity is used.</p>  <pre><code>// Parse the connection string and return a reference to the storage account.             CloudStorageAccount storageAccount = CloudStorageAccount.Parse(connectionString);              // Create the blob client.             CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();              CloudBlobContainer container = blobClient.GetContainerReference(\mycontainer\"");              if (container.CreateIfNotExists())             {                 BlobContainerPermissions containerPermissions = new BlobContainerPermissions() { PublicAccess = BlobContainerPublicAccessType.Blob };                 container.SetPermissions(containerPermissions);                 container.CreateIfNotExists();             } </code></pre>  <p>But this works on using the custom user account and password.  Is there a way to get this working using the Application Pool Identity.</p>""",azure-storage
46164977,"Azure Job BlobTrigger path to have year month day format in the path <p>I am writing a web job that processes data dumped to the azure storage account in a format<br>            mystorage/data/{yyyy}/{MM}/{dd}/app.csv</p>  <p>What I want to do now in Blobtrigger is the following</p>  <pre><code>  void Foo( BlobTrigger(\ mystorage/data/{yyyy}/{MM}/{dd}/app.csv\"") Stream message  TextWriter log) { } </code></pre>  <p>Is this possible? I want todays date to be parsed to yyyy  MM  and dd. Basically the blob should be triggered based on today's date which is part of the path of the file in the blob </p>""",azure-functions
42127733,"What does the \Storage Account\"" setting of an Azure Function App do? <p>It has a default selection of \""functionb7be452dbab0\"" in my case  but I can change it to select other storage accounts. There is no documentation that I can see which explains the \""storage account\"" setting.</p>""",azure-functions
53296667,"KeyVault firewall configuration and Azure Functions consumption plan <p>I have a KeyVault with some secrets in it. I have configured the firewall with a few limited client IPs and also made sure the \Allow trusted Microsoft services to bypass this firewall\"" is set to \""Yes\"". </p>  <p>However  when I try connect and retrieve a secret from an Azure function (using Managed Service Identity) I get a 403  Forbidden. If I set the firewall off (i.e. to \""Allow access from all networks\"") then it works fine. </p>  <p>In the (i)nformation box it says that Azure App Services (Web Apps) are supported. I thought this would cover function apps too but obviously not. </p>  <p>I know that I can use a S1 plan and a VNET (and join KeyVault to the same VNET)  but then we lose the flexibility of the consumption plan. </p>  <p>I have considered adding the entire Azure IP range for the data centre in question but I don't want the admin overhead. </p>  <p>Any other thoughts on how to secure a KeyVault using a firewall but still be able to access it from a function running on a consumption plan?</p>  <p><a href=\""https://i.stack.imgur.com/pJ4RK.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/pJ4RK.png\"" alt=\""Supported internal services\""></a></p>""",azure-functions
49224951,"Converting ODataQuery to TableQuery to query Azure Table Storage using OData <p>I'm using Azure table storage and I'd like to be able to query using OData. I've come across the <code>Microsoft.Rest.Azure.OData.ODataQuery</code> class but I can't find any examples of how this is consumed.</p>  <p>The <code>CloudTable</code> object permits queries through a <a href=\https://docs.microsoft.com/en-us/dotnet/api/microsoft.windowsazure.storage.table.tablequery-1?view=azure-dotnet\"" rel=\""nofollow noreferrer\""><code>TableQuery&lt;T&gt;</code></a> object  so is there any way to convert an <code>ODataQuery</code> to a <code>TableQuery</code>?</p>  <p>I know that earlier versions of Azure's table storage used an underlying OData API but I don't know if this is still the case  and I haven't found any documentation detailing whether the table can be exposed through OData.</p>  <p>Can anyone explain how to query Azure table storage using OData - ideally through a library?</p>  <p><strong>EDIT:</strong><br> For clarity  I know that table storage exposes a REST API which accepts OData queries; what I'm looking for is a way to pass the OData query programmatically: If I have an <code>ODataQuery</code> object  how can I use this to query a <code>CloudTable</code> object?</p>""",azure-storage
41433211,"TFS 2017  HTTPS Binding loses console permissions? <p>I've been trying all day to set up my instance of TFS2017 to work with HTTPS.</p>  <p>I've read the official setup guide  but it didn't help much.</p>  <p>My instance is attached to a domain and configuration has been made with an Administrators group user. The domain account is referenced as an administration console user properly. The setup has been made with default 8080 port and domain account user can access the website as expected (hosted at <a href=\http://machine-name:8080/tfs\"" rel=\""nofollow noreferrer\"">http://machine-name:8080/tfs</a>)</p>  <p>Now  when I change the IIS website settings binding to use HTTPS on port 443 with a valid wildchar certificate + set the hostname to be tfs.mydomain.com + ask for SSL require  I cannot have my user to authenticate anymore. I make TFS Public Url point to <a href=\""https://tfs.mydomain.com/tfs\"" rel=\""nofollow noreferrer\"">https://tfs.mydomain.com/tfs</a>.</p>  <p>I get prompted for the authentication box  but after many attempts  the site would just fail with 401.</p>  <p>The tests are made into the server environment to avoid Firewall confusions.</p>  <p>My instance has two network cards with 2 separate networks. First resolves to public IP  second resolves to private IP. I noticed the configuration works with the machine names  while it fails with the DNS resolution on the public IP. Could this be a reason ? </p>  <p>Thanks for your help</p>""",azure-devops
15787768,Accessing Azure Cloud Service PaaS Instances via PowerShell remoting <p>I have an Azure Web Role with 2 Instances (NB the PaaS Roles  <strong>*not Azure Virtual Machines</strong>). I can connect to them via Remote Desktop  but I don't know how to do Remoting in Powershell (PowerShell Remoting)  because unlike with a Azure Virtual Machine Cloud Service  there is no way to define an Endpoint and Port for each instance as there are not separate addresses for each Worker Role.</p>  <p>How can I connect to an individual PaaS Worker Role Instance via Powershell Remoting ? IOW how can I use:</p>  <pre><code>Enter-PSSession –ComputerName PC1 –Credential User </code></pre>  <p>against a Cloud Service Worker Role (PaaS) Instance?</p>,azure-virtual-machine
55627936,"Kusto language. Get one value only if the previous value in time is not the same <p>Context to my very vague title: I have 4 virtual machines that send their logs to application insights. I retrieve the logs and transform this in a table with kusto language.</p>  <p>Table of outcome <a href=\https://i.stack.imgur.com/T9bXa.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/T9bXa.png\"" alt=\""enter image description here\""></a></p>  <pre><code>Query:  AzureActivity | where ResourceProvider == \""Microsoft.Compute\"" and ActivityStatus == \""Succeeded\"" and OperationName == \""Deallocate Virtual Machine\"" | project DeallocateResource=Resource  DeallocatedDate=format_datetime(EventSubmissionTimestamp  'yyyy-MM-dd')  DeallocatedTime=format_datetime(EventSubmissionTimestamp  'HH:mm:ss') | join kind=fullouter ( AzureActivity | where ResourceProvider == \""Microsoft.Compute\"" and ActivityStatus == \""Succeeded\"" and OperationName == \""Start Virtual Machine\"" | project StartupResource=Resource  StartDate=format_datetime(EventSubmissionTimestamp  'yyyy-MM-dd')  StartTime=format_datetime(EventSubmissionTimestamp  'HH:mm:ss') ) on $right.StartupResource == $left.DeallocateResource | where StartDate == DeallocatedDate | project Resource=coalesce(StartupResource  DeallocateResource)   Date=format_datetime(todatetime(coalesce(StartDate  DeallocatedDate))  'dd/MM/yyyy' )     StartTime= StartTime  StopTime=DeallocatedTime    Runtime_Hours = format_datetime(datetime_add('minute' datetime_diff('minute'  todatetime(strcat(StartDate   \"" \""   DeallocatedTime ))   todatetime(strcat(StartDate   \"" \""   StartTime )))  make_datetime(2017 1 1))  'hh:mm')  | sort by Date asc   Resource asc </code></pre>  <p>As you can see the runtime is not correct when a VM is started at 8:15 and stopped at 8:58 and have runtimes of 12:43 hours then there is something wrong. In the activity log of the VM  I see that some colleague did some strange thing with the VM. And started it a couple of times (a minute after he started it again  probably a glitch when you click twice on the start button at the same time).</p>  <p>Activity Logs <a href=\""https://i.stack.imgur.com/ScJh8.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ScJh8.png\"" alt=\""enter image description here\""></a></p>  <p>I did find a theoretical solution to my problem:     My query needs to change so that the runtime and even the start and stop times need to get logged in the time table only when the VM starts and followed by a stop. But atm I got all the \""Start Virtual Machines\"" and all the \""Stop Virtual Machines\"" and just order them in a table which causes the mix up in my result table.</p>  <p>But I can't seem to find the way to adjust this in my query. To say Get the start virtual machine only when it's the first of the day (when the previous is not start virtual machine) or the previous log is \""deallocate virtual machine\"" because this is not by order start-stop. the time of the day needs to be in the formula. Get deallocate virtual machine only when the previous is a start virtual machine. and calculate the runtime of each run not for each day.</p>  <p>As I am very new to SQL and kusto and I am not here for someone to hand me the solution or do the work for me. I was hoping if there is someone who can help me out or guide me in the right direction to find a solution to my problem.</p>  <p>Thanks in advance !!!</p>""",azure-virtual-machine
30921734,"Installing Azure powershell in an azure Virtual Machine <p>I need to write a powershell workflow that creates an Azure Virtual Machine and executes some azure cmdlets in that Azure Virtual Machine. But the newly created VM has no azure powershell module installed in it. My code would be like this </p>  <pre><code>    New-AzureQuickVM -Windows -ServiceName $serviceName -Name $vmname -ImageName $VMImage  -Password $password -AdminUserName $username -InstanceSize \ExtraSmall\"" -WaitForBoot      $WinRmUri = Get-AzureWinRMUri -ServiceName $serviceName -Name $vmname     $Cred = new-object -typename System.Management.Automation.PSCredential -argumentlist $username  $password      Invoke-Command -ConnectionUri $WinRmUri -Credential $Cred -ScriptBlock {          Add-AzureAccount ......  ## These cmdlets need Azure Powershell Module           Set-AzureSubscription........          New-AzureStorageAccount......     } </code></pre>  <p>I am not supposed to manually get rdp of that VM and open it to install Azure Powershell Module but to dynamically create a VM using powershell cmdlet and install azure module in that vm using powershell itself.  </p>""",azure-virtual-machine
44975744,"Publishing Powershell Modules to VSTS Package Management using Publish-Module <p>I am trying to publish my Powershell modules to a VSTS Package Management feed. So far I have:</p>  <pre><code>$securePass = ConvertTo-SecureString -String $RepositoryPassword -AsPlainText -Force $cred = New-Object System.Management.Automation.PSCredential ($RepositoryUsername  $securePass)   Write-Debug \Adding the Repository $RepositoryName\"" Register-PSRepository -Name $RepositoryName -SourceLocation $RepositorySourceUri `                             -PublishLocation $RepositoryPublishUri -Credential $cred `                           -PackageManagementProvider Nuget -InstallationPolicy Trusted  $PublishParams = @{     Path = $ModuleFolderPath     ProjectUri = $ProjectUri     Tags = $ModuleTags     Repository = $RepositoryName     NugetApiKey = $NugetApiKey }  Publish-Module @PublishParams -Force -Verbose </code></pre>  <p>However  I get the following error:</p>  <blockquote>   <p>Publish-PSArtifactUtility : Failed to publish module   'Framework.Logging': 'Publishing to a ********   package management   feed   '<a href=\""https://xxx.pkgs.visualstudio.com/_packaging/PowershellModules/nuget/v2\"" rel=\""nofollow noreferrer\"">https://xxx.pkgs.visualstudio.com/_packaging/PowershellModules/nuget/v2</a>'   requires it to be   registered as a NuGet package source. Retry after   adding this source<br>   '<a href=\""https://xxx.pkgs.visualstudio.com/_packaging/PowershellModules/nuget/v2\"" rel=\""nofollow noreferrer\"">https://xxx.pkgs.visualstudio.com/_packaging/PowershellModules/nuget/v2</a>'   as NuGet package source by following the   instructions specified at   '<a href=\""https://go.microsoft.com/fwlink/?LinkID=698608\"" rel=\""nofollow noreferrer\"">https://go.microsoft.com/fwlink/?LinkID=698608</a>''.  At C:\\Program   Files\\WindowsPowerShell\\Modules\\PowerShellGet\\1.1.2.0\\PSModule.psm1:1227   char:17  + Publish-PSArtifactUtility -PSModuleInfo $moduleInfo `  +   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  + CategoryInfo   : InvalidOperation: (:) [Write-Error]  WriteErrorException  +   FullyQualifiedErrorId :   FailedToPublishTheModule Publish-PSArtifactUtility</p> </blockquote>  <p>The PSRepository is passed <a href=\""https://xxx.pkgs.visualstudio.com/_packaging/PowershellModules/nuget/v2\"" rel=\""nofollow noreferrer\"">https://xxx.pkgs.visualstudio.com/_packaging/PowershellModules/nuget/v2</a> as both the source and publish Uris when it is created. Any pointers as to where I am going wrong?</p>""",azure-devops
51767654,"Azure Storage Account requests getting throttled despite not reaching limits <p>I'm running into the below exception intermittently when running the Set-AzureRmStorageAccount cmdlet:</p>  <pre><code>Set-AzureRmStorageAccount : The request is being throttled. At D:\\StorageAccount.psm1:36 char:4 +             Set-AzureRmStorageAccount -ResourceGroupName $Resource.Re ... +             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : CloseError: (:) [Set-AzureRmStorageAccount]  CloudExce     ption     + FullyQualifiedErrorId : Microsoft.Azure.Commands.Management.Storage.SetAzureSt     orageAccountCommand </code></pre>  <p>The cmdlet that I'm running is</p>  <pre><code>Set-AzureRmStorageAccount -ResourceGroupName \RG\"" -Name \""SA\"" -EnableHttpsTrafficOnly $true </code></pre>  <p>So in order to repro this issue  I put the above cmdlet in a while loop and executed it.</p>  <p>However  I immediately started seeing the throttling error again and when I checked the portal for total transactions  it is not even close to the limits specified in the <a href=\""https://docs.microsoft.com/en-us/azure/azure-subscription-service-limits#storage-limits\"" rel=\""nofollow noreferrer\"">documentation</a>:</p>  <pre><code>    The following limits apply when performing management operations using the Azure Resource Manager only.      Resource                                     Default Limit    Storage account management operations (read)    800 per 5 minutes     Storage account management operations (write)   200 per hour      Storage account management operations (list)    100 per 5 minutes </code></pre>  <p>The screenshot from the azure portal shows only around 75 requests as shown below </p>  <p><a href=\""https://i.stack.imgur.com/1JxEg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/1JxEg.png\"" alt=\""Screenshot of requests to storage account from azure portal\""></a></p>  <p>Can someone help me understand why I'm seeing this throttling error so soon and if there is a way to see the source of requests to the storage account?</p>  <p>Thanks!</p>""",azure-storage
32582624,Azure WebJob: monitor all containers in account <p>I am developing an azure webjob which is monitoring a blob storage account for new inserted blobs. My storage account consists of multiple containers all holding similar information. Currently I'm using separate BlobTriggers for every container to monitor the single containers.</p>  <p>Is there a way to monitor the whole account for new blobs instead of every single container? If not  can I automatically iterate over the containers in a storage account and call the webjob with the container names as parameter?</p>,azure-storage
50796593,"How do I convert readable image stream into base64 without saving locally <p>I want to convert an image in azure to base64. How can I achieve this using azure-storage package?</p>  <pre><code>this.blobService.getBlobProperties(                 'container'                  path                  (err  properties  status)=&gt; {                     if (err) {                          res.send(502  \Error fetching file: %s\""  err.message);                     } else if (!status.isSuccessful) {                         res.send(502  \""The file %s does not exist\""  fileName)                     } else {                          res.header('Content-Type'  properties['contentType']);                          this.blobService.createReadStream('container'  path (error response)=&gt;{                          }).pipe(res);                     }                 }); </code></pre>  <p>The response I get is like this  I want to convert this(octet/stream) to base64.</p>  <p><a href=\""https://i.stack.imgur.com/o269g.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/o269g.png\"" alt=\""enter image description here\""></a></p>""",azure-storage
54511247,Transfer data from azure blob storage to hdfs file system <p>I have data in azure storage blob which is in parquet format. What I need to do is to transfer all those storage files to a hdfs. Is there any way I can do that?</p>  <p>couldn't find any helpful method to do it </p>  <p>Thanks.</p>,azure-storage
49267438,"How to accept connections from local network on Azure Functions (v2)? <p>I am trying to develop an @AzureFunctions using Xamarin Forms.  But it is not accepting connections from the cell phone.</p>  <p>How to configure host  port of Azure Functions on Visual Studio 2017 to enable connections from * other than localhost connections?</p>  <p>How to accept connections from local network on Azure Functions (v2) ?</p>  <p><strong>How to configure Host : Port of Azure Functions on Visual Studio 2017 ?</strong></p>  <p>I want that it accepts like ASP.Net Core (.UseUrls(\<a href=\""http://+:7071\"" rel=\""nofollow noreferrer\"">http://+:7071</a>\"")): </p>  <pre><code>Now listening on: http://[::]:7071 </code></pre>  <p>but it is only listening on </p>  <pre><code>http://localhost:7071 </code></pre>  <p><a href=\""https://i.stack.imgur.com/vpgaP.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/vpgaP.png\"" alt=\""Azure Functions host\""></a></p>  <p>GitHub Issue:  How to configure Azure Functions (v2) listening Host / Domain ?  <a href=\""https://github.com/Azure/azure-functions-core-tools/issues/537\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-functions-core-tools/issues/537</a></p>""",azure-functions
43798349,IP Forwarding With Azure - After Decommissioning VM <p>I have a Linux VM on Azure.  This VM has an External IP  let's call it VMIP.</p>  <p>I need to decommission the VM and move the traffic to a new External IP.  </p>  <p>We have moved most of the traffic via a DNS CNAME chain but some clients have an A-Record direct to VMIP.</p>  <p>How can I: </p>  <p>(a) Save the VMIP as static </p>  <p>(b) Decommission the VM </p>  <p>(c) Set up forwarding of all Port 80 traffic on VMIP to an External IP</p>,azure-virtual-machine
50035322,"Building asp.net MVC application in VSTS <p>I have been using Visual Studio Online for my MVC application for a while now  but I have only been using it mainly as a way to manage my work  cloud storage and version control in case I need rollback something that I made a mistake on.</p>  <p>It has gotten to the point in time where I need to start managing my releases properly rather than just managing it in a folder structure. (I know  I am fairly unprofessional).</p>  <p>So  I am trying to use CI in VSTS but all of my builds are failing. It seems that I am missing all of my NuGet packages. Here is the log from my <strong>NuGet restore</strong> </p>  <p><a href=\https://hastebin.com/ufibohoqir.tex\"" rel=\""nofollow noreferrer\"">https://hastebin.com/ufibohoqir.tex</a></p>  <p>I have read up a bit on a <code>nuget.config</code> file  which I don't have. I have tried to research into this but I am fairly lost. Do I need this file? I don't use any other packages except for nuget.</p>  <p>Any help would be appreciated. I use VS2015  and I can build using it. I have no idea why it can not find the nuget references.</p>  <p>Thanks!</p>  <p><strong>EDIT</strong></p>  <p>Here is the Log of the build that failed. <a href=\""https://file.io/cRydzZ\"" rel=\""nofollow noreferrer\"">https://file.io/cRydzZ</a></p>  <p>It was too big to put the whole thing on Hastebin. Bu  here is a snippet of the log of when it started to break.</p>  <p><a href=\""https://hastebin.com/ubofozirop.vbs\"" rel=\""nofollow noreferrer\"">https://hastebin.com/ubofozirop.vbs</a></p>  <p><strong>EDIT 2</strong></p>  <p>After changing my <strong>Agent Queue</strong> to <em>Hosted</em>  as was suggested  the NuGet packages all seem to be restored successfully. The build is still failing though. Here is my .csproj file: <a href=\""https://hastebin.com/iravicayek.xml\"" rel=\""nofollow noreferrer\"">https://hastebin.com/iravicayek.xml</a></p>  <p>One of the things that I have noticed is that the packages that are not found when building are the ones that look like this in the .csproj file:</p>  <pre><code>&lt;Reference Include=\""Antlr3.Runtime  Version=3.5.0.2  Culture=neutral  PublicKeyToken=eb42632606e9261f  processorArchitecture=MSIL\""&gt;   &lt;HintPath&gt;..\\packages\\Antlr.3.5.0.2\\lib\\Antlr3.Runtime.dll&lt;/HintPath&gt;   &lt;Private&gt;True&lt;/Private&gt; &lt;/Reference&gt; </code></pre>  <p>All of the ones that don't have <code>HintPath</code> and <code>Private</code> elements as children seem to load. I tested to see if I removed the children from the <code>Reference</code> elements  but they still failed to build.</p>""",azure-devops
48158825,"Visual Studio 2017 converting identity error <p>I just upgraded my VS 2017 to version 15.5.2  but get the following error dialog every time when open a VSTS project:</p>  <blockquote>   <p>Error converting value \Microsoft.IdentityModel.Claims.ClaimsIdentity;xxxxxxxxxx\\xxx@microsoft.com\"" to type 'Microsoft.VisualStudio.Services.Identity.IdentityDescriptor' Path 'authenticatedUser.descriptor'  line 1  position 184.</p> </blockquote>  <p>What can I do to resolve this issue?</p>""",azure-devops
56306821,"Get the data of Build.Repository.LocalPath and used it in my DockerFile <p>I want to get the data from the variable <code>Build.Repository.LocalPath</code> and use it in my Dockerfile  but it shows me and error.</p>  <p>This is my dockerfile:</p>  <pre><code>FROM microsoft/aspnet:latest  COPY \/${Build.Repository.LocalPath}/NH.Services.WebApi/bin/Release/Publish/\"" /inetpub/wwwroot </code></pre>  <p>I get this error:</p>  <pre><code>Step 2/9 : COPY \""/${Build.Repository.LocalPath}/NH.Services.WebApi/bin/Release/Publish/\"" /inetpub/wwwroot failed to process \""\\\""/${Build.Repository.LocalPath}/NH.Services.WebApi/bin/Release/Publish/\\\""\"": missing ':' in substitution ##[error]C:\\Program Files\\Docker\\docker.exe failed with return code: 1 </code></pre>  <p>I have try a lot of ways  putting this line: </p>  <pre><code>COPY \""/${Build.Repository.LocalPath}/NH.Services.WebApi/bin/Release/Publish/\"" /inetpub/wwwroot </code></pre>""",azure-devops
51122890,"How to manage Azure AD with service user and token instead of certificate? <p>How can I access and manage AAD groups via powershell when I only have an App-User and a token? </p>  <p>I don't like to manage the certificates especially since I want to use Azure functions to modify the AD.</p>  <p>Descriptions from <a href=\https://docs.microsoft.com/en-us/powershell/azure/active-directory/signing-in-service-principal?view=azureadps-2.0\"" rel=\""nofollow noreferrer\"">here</a> are great but they always use the cert to connect to the AD.</p>  <p>Is there a alternative that i could use to connect to the AAD and manage it automatically from powershell?</p>""",azure-functions
53761251,"Maximum Text Size For createBlockBlobFromText method Azure Storage  NodeJS <p><code>createBlockBlobFromText(container: string  blob: string  text: string | Buffer  options: CreateBlobRequestOptions  callback: ErrorOrResult&lt;BlobResult&gt;)</code></p>  <p>it is a method for writing text as block blob.</p>  <p>I want to know what is the limit of the text size.</p>  <p>In <a href=\https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs#about-block-blobs\"" rel=\""nofollow noreferrer\"">Docs</a> it is said that \""You create or modify a block blob by writing a set of blocks and committing them by their block IDs. Each block can be a different size  up to a maximum of 100 MB  and a block blob can include up to 50 000 blocks. The maximum size of a block blob is therefore slightly more than 4.75 TB (100 MB X 50 000 blocks\""</p>  <p>Does this method saves as a single block meaning only 100MB? Or can I use more memory for the single blob.</p>""",azure-storage
47046670,OMS extension or Windows Diagnostics extension <p>Can the windows diagnostic do the same as the OMS extension in terms of getting performance counter information and event details? Is there a reason to use the OMS extension over WAD for event/performance information?</p>,azure-virtual-machine
39293067,"Newly created Azure Web App with Overview and Activity Log not found? <p>I created a brand new web app on Azure. However  on navigating to the web app's page  the blades (panels) showcasing the service's overview and activity log (titled \Overview\"" and \""Activity Log\"" respectively) is unavailable.</p>  <p>A simple error page indicating it is not found is displayed instead. I have attempted to tinker with the two suggestions on the page regarding publish profiles (get and reset options) but to no avail.</p>  <p>I doubt there is an issue with my deployment method as I chose all the default values during setup. What could be the issue? </p>  <p><a href=\""http://i.stack.imgur.com/jF40m.png\"" rel=\""nofollow\"">Here is an image of the same.</a> Please note  I am still unable to post images in the questions.  Appreciate the help!</p>""",azure-web-app-service
44013645,"Creating a table in Azure Table fails without exception <p>I'm trying to create a table in Windows Azure Table service  using the example <a href=\https://github.com/Azure-Samples/storage-table-dotnet-getting-started\"" rel=\""nofollow noreferrer\"">https://github.com/Azure-Samples/storage-table-dotnet-getting-started</a></p>  <p>While running this example  I have no problem : the table creates itself  insert and delete work fine.</p>  <p>But what I copied as code into my project can't seem to work properly. Table creation apparently fails but returns no exception whatsoever. It's like my code does not wait for the table creation to finish.</p>  <p>Can any understand why ?</p>  <p>Thanks for your help !</p>  <p>Here is how I call the code :</p>  <pre><code>public async void saveInAzureTable() {             AzureStorage azure = new AzureStorage();             CloudTable table = await     AzureStorage.CreateTableAsync(\""randomtable123\""); } </code></pre>  <p>And here's the AzureStorage class :</p>  <pre><code>    using System;     using System.Threading.Tasks;     using Microsoft.Azure;     using Microsoft.WindowsAzure.Storage;     using Microsoft.Wi`enter code here`ndowsAzure.Storage.Table;     using Scraper.Models;      namespace Scraper     {         public class AzureStorage         {             public async Task&lt;TableResult&gt; storeAdvertisementInAzure(CloudTable table  AdvertisementEntity entity)         {             TableOperation insertOrMergeOperation = TableOperation.InsertOrMerge(entity);             TableResult result = await table.ExecuteAsync(insertOrMergeOperation);             return result;         }          /// &lt;summary&gt;         /// Validate the connection string information in app.config and throws an exception if it looks like          /// the user hasn't updated this to valid values.          /// &lt;/summary&gt;         /// &lt;param name=\""storageConnectionString\""&gt;Connection string for the storage service or the emulator&lt;/param&gt;         /// &lt;returns&gt;CloudStorageAccount object&lt;/returns&gt;         public static CloudStorageAccount CreateStorageAccountFromConnectionString(string storageConnectionString)         {             CloudStorageAccount storageAccount;             try             {                 storageAccount = CloudStorageAccount.Parse(storageConnectionString);             }             catch (FormatException)             {                 Console.WriteLine(\""Invalid storage account information provided. Please confirm the AccountName and AccountKey are valid in the app.config file - then restart the application.\"");                 throw;             }             catch (ArgumentException)             {                 Console.WriteLine(\""Invalid storage account information provided. Please confirm the AccountName and AccountKey are valid in the app.config file - then restart the sample.\"");                 Console.ReadLine();                 throw;             }              return storageAccount;         }           /// &lt;summary&gt;         /// Create a table for the sample application to process messages in.          /// &lt;/summary&gt;         /// &lt;returns&gt;A CloudTable object&lt;/returns&gt;         public static async Task&lt;CloudTable&gt; CreateTableAsync(string tableName)         {             // Retrieve storage account information from connection string.             CloudStorageAccount storageAccount = CreateStorageAccountFromConnectionString(CloudConfigurationManager.GetSetting(\""StorageConnectionString\""));              // Create a table client for interacting with the table service             CloudTableClient tableClient = storageAccount.CreateCloudTableClient();              Console.WriteLine(\""Create a Table to store data from the scraper\"");              // Create a table client for interacting with the table service              CloudTable table = tableClient.GetTableReference(tableName);             try             {                 if (await table.CreateIfNotExistsAsync())                 {                     Console.WriteLine(\""Created Table named: {0}\""  tableName);                 }                 else                 {                     Console.WriteLine(\""Table {0} already exists\""  tableName);                 }             }             catch (StorageException)             {                 Console.WriteLine(\""If you are running with the default configuration please make sure you have started the storage emulator. Press the Windows key and type Azure Storage to select and run it from the list of applications - then restart the sample.\"");                 Console.ReadLine();                 throw;             }              Console.WriteLine();             return table;         }      } } </code></pre>""",azure-storage
49374770,error while trying to push nuget package from VSTS <p>I added dotnet task (.Net Core) to do a nuget push. In the Nuget server section it asked me to use create a new Nuget Connection. I went with the API Key option and game in connection name Feed URL  and API Key. </p>  <p>when I run this step I get the following error </p>  <blockquote>   <p>Error: DotNetCore currently does not support using an encrypted Api   Key.</p> </blockquote>  <p>is this a limitation or am i doing something wrong?</p>  <p>Please note from my desktop I am about to create package and push the package using apikey.</p>,azure-devops
12309767,How to determine whether my Azure connection string is valid <p>A bad Azure connection string will hang my application indefinitely the first time I contact azure; in my case during <code>blobContainer.CreateIfNotExist();</code>.</p>  <p>Other SO posts about connectivity checking mentioned setting timeouts  but it still hangs indefinitely with a 2s timeout: <code>blobContainer.CreateIfNotExist(new BlobRequestOptions() { Timeout = new TimeSpan(0  0  2) });</code></p>  <p>What's the correct way to check if an Azure connection string is valid?</p>,azure-storage
42198043,When Upload/download files in window azure vm <p>I am using dedicated VM for my web application also use load balance to handle traffic.my query is when I upload updated files  Will these files accessible to all instance of load balance at once? secondly if users  want to download files   from application will they download from actual VM or any instance of load balance will help user to download these files whatever the instance be user hits.</p>,azure-virtual-machine
51469930,CI_VSTS publish different web Artifact for each project in single solution <p>I have a CI pipeline(VSTS) in which I am able to build whole solution which has two website projects in it in a single artifact. What I want to do it build whole solution and then create publish artifact for each project.  e.g. One artifact for Project_website1 One artifact for Project_website2 thanks. I tried similar topic in StackOverflow but didnt work for me</p>,azure-devops
49328159,"Azure App Service ApiApp <p>I am trying to create an API App in <strong>Azure App Service</strong> with PowerShell.</p>  <p>The cmdlet I am calling always create a Web App by default. If it is possible  I would like to know how I can specify the type/kind to be <code>Api App</code> instead of <code>Web App</code>? </p>  <pre><code>New-AzureRmWebApp -Name $name -Location $location -AppServicePlan $plan -ResourceGroupName $resourceGroup </code></pre>  <p>From my reading there is not much different between both except the icon  is it worth it to set the type to \Api App\"" if it's what my app is all about?</p>  <p>I am using version 5.4.0 of AzureRM PowerShell module.</p>  <pre><code>&gt; Get-Module \""AzureRM\""  ModuleType Version    Name                                                  ---------- -------    ---- Script     5.4.0      AzureRM </code></pre>""",azure-web-app-service
41275438,"Deploying to Azure from git: 'No Deployable Projects' <p>According to the documentation  it is possible to deploy to Azure by updating a git repository.</p>  <p>I have attempted the walkthrough <a href=\https://github.com/AndrewShepherd/kudu-deployment-test\"" rel=\""nofollow noreferrer\"">here</a>.</p>  <p>I created <a href=\""https://github.com/AndrewShepherd/kudu-deployment-test\"" rel=\""nofollow noreferrer\"">this github repository</a>  then generated an ASP.NET MVC project from the Visual Studio template.</p>  <p>Looking at the logs  Azure detected the checkin  but provided this unhelpful message:</p>  <blockquote>   <p>Using the following command to generate deployment script: 'azure site deploymentscript -y --no-dot-deployment -r \""D:\\home\\site\\repository\"" -o \""D:\\home\\site\\deployments\\tools\"" --basic'.</p>      <p>Generating deployment script for Web Site</p>      <p>Generated deployment script files</p>      <p>Found solution 'D:\\home\\site\\repository\\kudu-deployment-test.sln' <strong>with no deployable projects</strong>. Deploying files instead.</p> </blockquote>  <p>Why is my straight-out-of-the-box ASP.NET project not a 'deployable project'?</p>  <p>What can I do to fix it so it is?</p>""",azure-web-app-service
46703350,adding azure ad b2c authentication to azure function spa <p>I am trying to build a <strong>Single Page App</strong> with <strong>Azure Functions</strong> so that when user wants to visit my website they can visit the url of my azure function which will be a custom domain  like www.contoso.com</p>  <p>But when they visit it first they must automatically go to login page for <strong>Azure AD B2C</strong> and after they login they get redirected to my <strong>SPA</strong> with their info.</p>  <p>I know how to create a SPA with azure functions without authentication  and I also know how to configure an <strong>azure b2c tenant</strong>  I've also added azure ad b2c authentication into Azure Function -> Authentication -> Azure AD -> Advanced.</p>  <p>My question is  how can I initiate the login process for the user  just like in a normal website. In a normal asp website  visual studio provides options to integrate this  but how can I do the same for azure functions?</p>,azure-functions
49785180,"Unable to load Entity Framework Core into C# azure function <p>I already opened an <a href=\https://github.com/Azure/azure-functions-host/issues/2658\"" rel=\""noreferrer\"">issue</a> in <a href=\""https://github.com/Azure/azure-functions-host/\"" rel=\""noreferrer\""><code>Azure/azure-functions-host</code></a> and I have a <a href=\""https://github.com/mamodom/AzureFunctionEFErrorRepro\"" rel=\""noreferrer\"">repo</a> with the repro steps  but I'm posting this here in case there is something inherently wrong with what I'm doing  or someone has already stumbled open this issue.</p>  <p><strong>My goal</strong>: I want to run in an azure function some code that lives in a class library in an existing visual studio solution.</p>  <p>This code happens to use entity framework core in order to read and write to a SQL Server database.</p>  <p>While trying to isolate the issues I was facing  I ended up with the following scenario:</p>  <p>Repro steps:</p>  <ol> <li><p>In Visual Studio: File > New > Project > Azure Functions</p></li> <li><p>Select <code>Azure Functions v2 Preview (.NET Core)</code></p></li> <li><p>Select <code>Http trigger</code></p></li> <li><p>Select <code>Storage Emulator</code></p></li> <li><p>Select Access rights <code>Function</code></p></li> <li><p>Install using nuget <code>Microsoft.EntityFrameworkCore</code> version <code>2.0.2</code></p></li> <li><p>Add an invocation to anything from the <code>EFCore</code> package</p>  <p>In my case I added the following line: </p>  <pre><code>log.Info(typeof(DbContext).AssemblyQualifiedName); </code></pre></li> <li><p>Ensure the azure storage emulator is running</p></li> <li><p>Run the function from visual studio (<code>F5</code>)</p></li> <li><p>Hit the url printed in the console</p></li> </ol>  <p><strong>Expected behavior</strong>: along with the default behavior of the example <code>Http trigger</code> function I expect to see the following line printed with each invocation:</p>  <pre><code>Microsoft.EntityFrameworkCore.DbContext  Microsoft.EntityFrameworkCore  Version=2.0.2.0  Culture=neutral  PublicKeyToken=adb9793829ddae60 </code></pre>  <p><strong>Actual behavior</strong>: the app throws an exception at runtime and outputs the following</p>  <blockquote>   <p>[11-Apr-18 6:33:59 AM] Executing 'Function1' (Reason='This function was programmatically called via the host APIs.'  Id=6faabfd8-eb96-4d71-906c-940028a7978a)<br>   [11-Apr-18 6:33:59 AM] Executed 'Function1' (Failed  Id=6faabfd8-eb96-4d71-906c-940028a7978a)<br>   [11-Apr-18 6:33:59 AM] System.Private.CoreLib: Exception while executing function: Function1. FunctionApp1: Could not load file or assembly 'Microsoft.EntityFrameworkCore  Version=2.0.2.0  Culture=neutral  PublicKeyToken=adb9793829ddae60'. Could not find or load a specific file. (Exception from HRESULT: 0x80131621). System.Private.CoreLib: Could not load file or assembly 'Microsoft.EntityFrameworkCore  Version=2.0.2.0  Culture=neutral  PublicKeyToken=adb9793829ddae60'.</p> </blockquote>  <p>Current conjecture: while researching this issue I found something that might be related: </p>  <p>The Azure functions runtime already has a set of packages available  one of those being <code>Newtonsoft.Json</code> in a specific version. In the case a newer version of <code>Newtonsoft.Json</code> is referenced from the project a similar behavior is observed.</p>  <p><a href=\""https://stackoverflow.com/questions/47351068/could-not-load-file-or-assembly-newtonsoft-json-version-10-0-0-0-culture-neut\"">Here</a>'s a StackOverflow question.  <a href=\""https://github.com/Azure/azure-functions-host/issues/2529#issuecomment-373182486\"" rel=\""noreferrer\"">Here</a>'s a github issue </p>""",azure-functions
39523396,"Can an Azure Function be triggered by the creation of a DocumentDB document? <p>If I have another <a href=\https://azure.microsoft.com/en-us/documentation/articles/functions-bindings-documentdb/\"" rel=\""nofollow\"">Azure Function</a> creating documents  based on some other event (e.g. API call).</p>  <p>Is there support (or will there be) to have an Azure Function run based on a new document being created?</p>  <pre><code>using System; public static void Run(object doc  TraceWriter log) {     log.Info($\""doc based trigger? ... {doc}\""); } </code></pre>  <p>Binding I tried to use  i tried it with and wihout the \""id\"" property  and type <code>documentDB</code> and <code>documentDBTrigger</code> :</p>  <pre><code>\""bindings\"": [ {   \""type\"": \""documentDB\""    \""name\"": \""doc\""    \""databaseName\"": \""MyDb\""    \""collectionName\"": \""MyCollection\""    \""connection\"": \""mydb_DOCUMENTDB\""    \""direction\"": \""in\"" } </code></pre>""",azure-functions
31869830,Google Docs - with some different storage <p>Is it possible to use Google Docs  with some different storage other than Google Drive. </p>  <p>We have a .net application that is using some document (docx) files stored on Azure. These files will be edited simultaneously by multiple people.  We want to use <strong>Google Docs - collaboration feature</strong>. Using Google APIs we can load the files and can control the document sharing to some restricted people. But we cannot upload the docx files on Google Drive. Is it possible to do so and how?</p>  <p>OR</p>  <p>Is there any other online Document Collaboration tool  that allows </p>  <ol> <li>to upload the azure documents </li> <li>provides APIs to integrate the tool with existing .net application.</li> </ol>  <p>Thanks.</p>,azure-storage
55012289,"Azure endpoint reached  but calls to API returning 404 error <p>We have set up an app service project in the Azure Portal and then went through deployment of the project using Visual Studio DevOps. When I go to <a href=\http://MyAzureSite.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://MyAzureSite.azurewebsites.net</a> (Made up URL here)  I can confirm that the service is up and running. </p>  <p>But when I add \""api/ControllerName/getStatus\""  I get a 404 error.</p>  <p>Call from my local machine is working perfectly fine.</p>  <pre><code>http://localhost:52686/api/status/getStatus </code></pre>  <p>But not:</p>  <pre><code>http://MyAzureSite.azurewebsites.net/api/status/getstatus </code></pre>  <p>Signature for the GetStatus looks good:</p>  <pre><code>[HttpGet] public List&lt;Status&gt; GetStatus() </code></pre>""",azure-web-app-service
51136636,"Configuring Azure Application Gateway to Azure web app to route requests by path <p>I have two web apps (webapp1 and webapp2). I would like to use Application Gateway features where can route using path based redirect. <a href=\http://mywebsite/login1\"" rel=\""nofollow noreferrer\"">http://mywebsite/login1</a> redirect to webapp1 <a href=\""http://mywebsite/login2\"" rel=\""nofollow noreferrer\"">http://mywebsite/login2</a> redirect to webapp2</p>  <p>Is this possible it possible to do this with Application gateway if so can you please give link or direction on how to do this for web apps prespective</p>""",azure-web-app-service
56352264,"binding to input blob imperatively <p><strong>How do we imperatively bind to an input blob?</strong></p>  <p>I'd like to be able to read blobs inside of my azure function. One way to do this is to add a parameter like this one:</p>  <pre><code>[Blob(\%MyInputBlob%/{FileName}\""  FileAccess.Read)]  Stream input </code></pre>  <p>However  this won't work for me because I will need to read multiple blobs  and they have different <code>{filenames}</code>.</p>  <p>I understand there's an imperative binding solution to write to an output like so:</p>  <pre><code>        var attributes = new Attribute[]         {                 new BlobAttribute(path)                  new StorageAccountAttribute(connection)         };         using (var writer = await binder.BindAsync&lt;TextWriter&gt;(attributes))         {             writer.Write(payload);         } </code></pre>  <p><strong>Is there a similar binding capability for INPUT blobs?</strong></p>""",azure-functions
44910406,"How to read from Azure Table Storage with a HTTP Trigger PowerShell Azure Function? <p>The <code>Row Key</code> will be passed in the query string. What is needed in the function to create the \connection string\"" to the Table Storage?</p>""",azure-functions
43788697,"Azure App Service Linux hosting Wordpress error \Installing WordPress ... This could be done in minutes. Please refresh your browser later.\"" <p>I am hosting my blog on Azure App Service platform on the new linux host.It was working fine but now the website cannot be accessed and it is giving error \""Installing WordPress ... This could be done in minutes. Please refresh your browser later.\"" This stays like that for for ever.</p>  <p>I checked the health  and everything is fine.I tried to enable php loggiong by editing the  wp-config.php by adding these two lines </p>  <pre><code>define('WP_DEBUG'  true); define('WP_DEBUG_LOG'  true); </code></pre>  <p>But I do not see the the log file generated.Accessing the  phpmyadmin gives error </p>  <pre><code>\""No route registered for '/phpmyadmin/'\"" </code></pre>  <p>This msdn  <a href=\""https://blogs.msdn.microsoft.com/appserviceteam/2017/03/21/create-wordpress-using-web-apps-on-linux/\"" rel=\""nofollow noreferrer\"">blog</a> says that I might have to upgrade my docker image.I have some blog already created I would like to create a export the DB before doing anything.</p>  <p>I have also added the .user.ini file with log_errors=on but do not see any errors logged. </p>  <p><strong>edit:</strong>     </p>  <p>Here's the error from docket_XX_err.log file:    </p>  <pre><code>2017-04-21T03:06:06.663993010Z AH00558: httpd: Could not reliably determine the server's fully qualified domain name  using 172.17.0.3. Set the 'ServerName' directive globally to suppress this message 2017-04-21T03:06:14.616897475Z ERROR 1102 (42000) at line 1: Incorrect database name '' 2017-04-21T04:06:56.519319746Z AH00558: httpd: Could not reliably determine the server's fully qualified domain name  using 172.17.0.3. Set the 'ServerName' directive globally to suppress this message 2017-04-21T04:07:00.414460896Z ERROR 1102 (42000) at line 1: Incorrect database name '' </code></pre>  <p>** edit 2**</p>  <p>updating the docker image to appsvc/apps:wordpress:0.1 shown below did not fix the problem.</p>  <p><a href=\""https://i.stack.imgur.com/EJwyC.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/EJwyC.png\"" alt=\""dockerimage update\""></a></p>  <p>The error in the docker_XX log says</p>  <pre><code>Digest: sha256:ca50223ff969665a64ed3b690124f56d1cc51754331e94baa80327dcc474c020 Status: Image is up to date for appsvc/apps:wordpress wordpress: Pulling from appsvc/apps Digest: sha256:ca50223ff969665a64ed3b690124f56d1cc51754331e94baa80327dcc474c020 Status: Image is up to date for appsvc/apps:wordpress wordpress: Pulling from appsvc/apps </code></pre>  <p>After updating the image  am still not able to access phpmyadmin to export my data.</p>""",azure-web-app-service
47248572,"Any reason to use Azure Web Apps instead of Azure Web Apps for Containers? <p>I'm pretty new to Azure  so for the sake of learning  I have deployed Node.js applications in Azure both as Docker containers and Azure web apps on Linux. Since Azure web apps are containers anyway  is there any good reason why I should use them instead of my own containers  which I have better control over?</p>  <p>One problem I stumbled upon was that you have to take quite a few things into account with the preconfigured containers in Azure web apps  some of that described <a href=\https://docs.microsoft.com/en-us/azure/nodejs-use-node-modules-azure-apps\"" rel=\""nofollow noreferrer\"">here</a>. If I instead use my own Docker containers  I don't have to take the extra steps that are sometimes required to get your Node.js application with its dependencies up and running as an Azure web app.</p>  <p>Am I missing something  or is it as it now seems to me  less work to deploy my apps in Azure as Docker containers?</p>  <p>Sebastian</p>""",azure-web-app-service
53739799,"How do I find the network interface ID associated with an Azure VM <p>I can find the VM by using</p>  <pre><code>$vm = Get-AzureRmVM -ResourceGroupName \MyResource\"" -Name \""MyVM\"" </code></pre>  <p>But how can I find the network interface associated with this VM?</p>""",azure-virtual-machine
32867493,Blocking Outbound Internet connection on Azure VM but keeping Antimalware Extension working <p>I have a VM on which I blocked outbound connectivity to the Internet using a NetworkSecurityGroup.</p>  <p>I installed the Antimalware Extension and realized that the installation would not work without connecting to the Internet. So I removed the NetworkSecurityGroup to reactivate outbound connectivity and everything installed correctly.</p>  <p>Now I want put the NetworkSecurityGroup restrictions back (No internet access).</p>  <p>What exclusions should I add to the NetworkSecurityGroup so that the Antimalware Extension continue working and update normally?</p>,azure-virtual-machine
46368663,"VSTS Nuget Restore Fails with non compatible assembly error <p>I am trying to setup a VSTS build definition for a Service Fabric project and I can't get the build to get further than the 'Build' step. </p>  <p>Currently the project structure looks like this:</p>  <pre><code>- Application   - Service Fabric Project 1 (Web API)   - Service Fabric Project 2 (Stateful Service)   - Application Project Folder   - Angular Project </code></pre>  <p>I am just trying to build the Web API Service Fabric Project. I have followed <a href=\https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-set-up-continuous-integration\"" rel=\""nofollow noreferrer\"">this guide</a> and used the 'Azure Service Fabric Application' template and my build definition looks like this: <a href=\""https://i.stack.imgur.com/lSVPF.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/lSVPF.png\"" alt=\""BuildDefinition\""></a></p>  <p>And the error I get is:</p>  <blockquote>   <p>C:\\Program Files\\dotnet\\sdk\\2.0.0\\Sdks\\Microsoft.NET.Sdk\\build\\Microsoft.PackageDependencyResolution.targets(323 5): Error : Assets file 'd:\\a\\3\\s\\ApplicationName.Security.Gateway\\obj\\project.assets.json' not found. Run a NuGet package restore to generate this file.   C:\\Program Files\\dotnet\\sdk\\2.0.0\\Sdks\\Microsoft.NET.Sdk\\build\\Microsoft.PackageDependencyResolution.targets(323 5): error : Assets file 'd:\\a\\3\\s\\ApplicationName.Security.Gateway\\obj\\project.assets.json' not found. Run a NuGet package restore to generate this file. [d:\\a\\3\\s\\ApplicationName.Security.Gateway\\ApplicationName.Security.Gateway.csproj]     Build continuing because \""ContinueOnError\"" on the task \""ReportAssetsLogMessages\"" is set to \""ErrorAndContinue\"".   C:\\Program Files\\dotnet\\sdk\\2.0.0\\Sdks\\Microsoft.NET.Sdk\\build\\Microsoft.PackageDependencyResolution.targets(165 5): Error : Assets file 'd:\\a\\3\\s\\ApplicationName.Security.Gateway\\obj\\project.assets.json' not found. Run a NuGet package restore to generate this file.</p> </blockquote>  <p>I downloaded the logs and also found this error during the Nuget Restore process:</p>  <blockquote>   <p>2017-09-22T15:35:53.8340398Z d:\\a\\3\\s\\Application.Application\\Application.Application.sfproj(57 5): error : Unable to find the '..\\packages\\Microsoft.VisualStudio.Azure.Fabric.MSBuild.1.6.1\\build\\Microsoft.VisualStudio.Azure.Fabric.Application.props' file. Please restore the 'Microsoft.VisualStudio.Azure.Fabric.MSBuild' Nuget package   2017-09-22T15:35:53.8340398Z d:\\a\\3\\s\\Application.Application\\Application.Application.sfproj : warning NU1503: Skipping restore for project 'd:\\a\\3\\s\\Application.Application\\Application.Application.sfproj'. The project file may be invalid or missing targets required for restore. [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018: The \""WriteRestoreGraphTask\"" task failed unexpectedly. [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018: NuGet.Commands.RestoreCommandException: PackageTargetFallback and AssetTargetFallback cannot be used together. Remove PackageTargetFallback(deprecated) references from the project environment. [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at NuGet.Commands.AssetTargetFallbackUtility.EnsureValidFallback(IEnumerable<code>1 packageTargetFallback  IEnumerable</code>1 assetTargetFallback  String filePath) [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at NuGet.Commands.MSBuildRestoreUtility.AddPackageTargetFallbacks(PackageSpec spec  IEnumerable<code>1 items) [d:\\a\\_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a\\_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at NuGet.Commands.MSBuildRestoreUtility.GetPackageSpec(IEnumerable</code>1 items) [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at System.Linq.Enumerable.WhereSelectEnumerableIterator<code>2.MoveNext() [d:\\a\\_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a\\_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at System.Linq.Enumerable.WhereEnumerableIterator</code>1.MoveNext() [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at NuGet.Commands.MSBuildRestoreUtility.GetDependencySpec(IEnumerable`1 items) [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at NuGet.Build.Tasks.WriteRestoreGraphTask.Execute() [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at Microsoft.Build.BackEnd.TaskExecutionHost.Microsoft.Build.BackEnd.ITaskExecutionHost.Execute() [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z d:\\a_temp\\NuGetScratch\\tspr1daf.vdl.nugetrestore.targets(131 5): error MSB4018:    at Microsoft.Build.BackEnd.TaskBuilder.d__26.MoveNext() [d:\\a_temp\\NuGetScratch\\temmko3j.dto.nugetinputs.targets]   2017-09-22T15:35:53.8340398Z    2017-09-22T15:35:53.8750823Z NuGet.CommandLine.ExitCodeException: Exception of type 'NuGet.CommandLine.ExitCodeException' was thrown.   2017-09-22T15:35:53.8750823Z    at NuGet.CommandLine.MsBuildUtility.d__6.MoveNext()   2017-09-22T15:35:53.8750823Z --- End of stack trace from previous location where exception was thrown ---   2017-09-22T15:35:53.8750823Z    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()   2017-09-22T15:35:53.8750823Z    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)   2017-09-22T15:35:53.8750823Z    at NuGet.CommandLine.RestoreCommand.d__48.MoveNext()   2017-09-22T15:35:53.8750823Z --- End of stack trace from previous location where exception was thrown ---   2017-09-22T15:35:53.8750823Z    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()   2017-09-22T15:35:53.8762943Z    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)   2017-09-22T15:35:53.8762943Z    at NuGet.CommandLine.RestoreCommand.d__43.MoveNext()   2017-09-22T15:35:53.8770357Z WARNING: Error reading msbuild project information  ensure that your input solution or project file is valid. NETCore and UAP projects will be skipped  only packages.config files will be restored.   2017-09-22T15:35:54.0700174Z Restoring NuGet package Microsoft.ServiceFabric.5.7.198.</p> </blockquote>  <p>All the builds work without issue on our local machines under both Release and Debug build.</p>  <p>Any help would be greatly appreciated.</p>  <p>Build logs can be downloaded <a href=\""https://fundstreamza-my.sharepoint.com/personal/marka_fundstream_co_za/_layouts/15/guestaccess.aspx?docid=13162bb3b90c04e9c80b7e1ed76dfa9b0&amp;authkey=Ac51RzU5hdoMQ1Re-j99Ork&amp;expiration=2017-09-29T22%3a00%3a00.000Z\"" rel=\""nofollow noreferrer\"">here.</a></p>""",azure-devops
49280325,"How does traffic flow from Azure virtual machine to data dog <p>I have installed data dog agent on one of my virtual machines When I have altered my NSG so that all \Outbound-connections\"" are denied  I am still able to see \""CPU metric\"" getting updated on Data dog dashboard. I would like to know where this information is going from Azure to Datadog.</p>""",azure-virtual-machine
42104647,"Creating a folder using Azure Storage Rest API without creating a default blob file <p>I want to create following folder structure on Azure:</p>  <pre><code>mycontainer    -images        --2007            ---img001.jpg            ---img002.jpg </code></pre>  <p>Now  one way is to use PUT Blob request and upload img001.jpg specifying the whole path as </p>  <blockquote>   <p>PUT \mycontainer/images/2007/img001.jpg\""</p> </blockquote>  <p>But  I want to first create the folders <code>images</code> and <code>2007</code> and then in a different request upload the blob <code>img001.jpg</code>.</p>  <p>Right now when I tried to doing this using <code>PUT BLOB</code> request:</p>  <blockquote>   <p>StringToSign:</p> </blockquote>  <pre><code>PUT            x-ms-blob-type:BlockBlob x-ms-date:Tue  07 Feb 2017 23:35:12 GMT x-ms-version:2016-05-31 /account/mycontainer/images/ </code></pre>  <blockquote>   <p>HTTP URL</p> </blockquote>  <pre><code>sun.net.www.protocol.http.HttpURLConnection:http://account.blob.core.windows.net/mycontainer/images/ </code></pre>  <blockquote>   <p>It is creating a folder but its not empty. By  default its creating an   empty blob file without name.</p> </blockquote>  <p>Now  a lot of people say we can't create a empty folder. But  then how come  we can make it using the azure portal as the browser must be sending some type of rest request to create the folder.</p>  <p>I think it has to do something with <code>Content-Type</code> i.e. <code>x-ms-blob-content-type</code>  which should be specified in order to tell azure that its a folder not a blob. But  I am confused.</p>""",azure-storage
52404343,Rename Virtual Machine Managed Disks on Microsoft Azure through PowerShell <p>How to Rename Virtual Machine Managed Disks on Microsoft Azure through PowerShell?</p>  <p>I tried with </p>  <pre><code>Update-AzureRmDisk  </code></pre>  <p>But I'm not able to change the name </p>  <p>How can I do that?</p>,azure-virtual-machine
30925194,"Azure blobs - cannot display image store in blob container in MVC 4 <p><strong>Question background:</strong></p>  <p>I have a basic MVC 4 site and am trying to display a picture  that is stored in a blob storage container in my Azure cloud account. I store a list of image <code>Uri's</code> in a string <code>List</code> and pass these to a <code>View</code> where they should display</p>  <p><strong>The Issue:</strong></p>  <p><strong>I can't seem to get the file name of the image stored in the container.</strong> </p>  <p>The following image shows the container in Azure. <strong>Note</strong> that there is an image stored in it with a size of 101.28KB:</p>  <p><img src=\https://i.stack.imgur.com/52uQa.jpg\"" alt=\""enter image description here\""></p>  <p>This is the code I am trying to use to retrieve the blobs and then read the image <code>Uri's</code>:</p>  <p><code>AzureStorageController</code> with a <code>Pics</code> Action Method:</p>  <pre><code> public ActionResult Pics()     {         var imageList = new List&lt;string&gt;();          var imagesAzure = new myBlobStorageService();          var container = imagesAzure.GetCloudBlobContainer();          foreach (var blobItem in container.ListBlobs())         {             imageList.Add(blobItem.Uri.ToString());         }         return View(imageList);     } </code></pre>  <p>The <code>GetCloudBlobContainer</code> Method of the <code>myBlobStorageService</code> class:</p>  <pre><code> public CloudBlobContainer GetCloudBlobContainer()     {         string accountName = \""fmfcpics\"";          string accountKey = \""xxxxxx/yyyyyyyyy/3333333333==\"";          StorageCredentials credentials = new StorageCredentials(accountName  accountKey);          CloudStorageAccount storageAccount = new CloudStorageAccount(credentials  true);          CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();          CloudBlobContainer container = blobClient.GetContainerReference(\""images\"");          if (container.CreateIfNotExists())         {             container.SetPermissions(new BlobContainerPermissions() { PublicAccess = BlobContainerPublicAccessType.Blob });         }          return container;     } </code></pre>  <p>The <code>Pics</code> View:</p>  <pre><code>@{ ViewBag.Title = \""Pics\""; }  &lt;h2&gt;Pics&lt;/h2&gt;  @foreach (var item in Model) {     &lt;img src=\""@item\"" alt=\""picture\"" width=\""200\"" height=\""200\"" /&gt; } </code></pre>  <p>The Uri that is in the list that is being passed to the Pics View is: <strong><a href=\""https://fmfcpics.blob.core.windows.net/images/myblob\"" rel=\""nofollow noreferrer\"">https://fmfcpics.blob.core.windows.net/images/myblob</a></strong> but it does not feature the image file name.</p>  <p>Any help with this would be appreciated.</p>""",azure-storage
57408424,"How to trigger your automation script from VSTS and get the test execution result back in VSTS <p>I have a automation script which built in Java/selenium. I want to run my test cases from VSTS by triggering my script and also want to get the result back in VSTS. Can anybody give me the path how can I make that happen. Also where should I keep by project?</p>  <p>I was doing research on it. But doesn't make sense to me <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/test/continuous-test-selenium?view=azure-devops\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/test/continuous-test-selenium?view=azure-devops</a></p>""",azure-devops
55915618,"PublishTestResults with suite-level message output <p>I am well aware that what I am looking to do is not currently possible  so I am looking for a workaround.</p>  <hr>  <p>First of all  assume a microservice-based  highly modular application system. Each microservice has its own unit tests that are run in its build pipeline  the results are published to Azure DevOps - no problems at this point.</p>  <p>However  there is a need to run some integration (<em>almost</em> end-to-end) tests (let's call it the integration test suite) on a properly deployed application system. That is done on a designated environment (let's call it the integration test environment). The test suite would be executed in several different scenarios  so the output needs to reflect that (this simply means that if there are 4 scenarios  the test result output file will have 4 test suites).</p>  <p>Aside from that  there must be a directly visible link between application system releases and their test results.</p>  <p>In order to achieve this  there is a release pipeline  where the first three stages are: Deploy to DEV  Deploy to INT and Run Integration Tests.</p>  <p>Naturally  the <code>PublishTestResults</code> task is used to present a nice overview of the integration test results. The integration test orchestrator application is generating one JUnit XML/scenario and at the end of testing they are made available to the pipeline.</p>  <hr>  <p><strong>With that said  here comes the problem: there is a need to present certain statistics about the tests run in each scenario/suite</strong> (more interesting stuff than X/Y tests succeeded in Z seconds).</p>  <p>I know that Jenkins CI seem to follow the <a href=\https://llg.cubic.org/docs/junit/\"" rel=\""nofollow noreferrer\"">JUnit XML format</a> described by Dirk Jagdmann  namely that a <code>&lt;testsuite&gt;</code> element can have a <code>&lt;system-out&gt;</code> element and this would appear on the test suite visualization.</p>  <p>Unfortunately (!)  Azure DevOps <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/test/publish-test-results?view=azure-devops&amp;tabs=yaml#result-formats-mapping\"" rel=\""nofollow noreferrer\"">PublishTestResults task</a> only reads <code>&lt;system-out&gt;</code> under individual <code>&lt;testcase&gt;</code> elements (the link above shows the result format mapping). The irony is that the test suite and test case blades are rendered mostly the same - they both have the <code>Debug</code> section where you have an accordion with <code>Error message</code>  <code>Stack Trace</code> etc. (which will not be read/populated for <code>&lt;testsuite&gt;</code> though).</p>  <p>The same applies to JUnit format extensions that would allow referencing extra attachment files in the XML.</p>  <p>Now  if this were a build pipeline  I would <em>not care</em> and just use the <code>PublishBuildArtifacts</code> task to add some .TXT attachments (one per scenario/suite) and call it done. However  this task cannot be used in a release pipeline.</p>  <hr>  <p><strong>I do need the extended summary/statistics per suite</strong> and I cannot have them <em>somewhere in the XML</em>  which <em>can be downloaded after taking several possibly obscure steps</em>. This automatically rules out uploading them <em>somewhere else</em> - if the CI/CD is in Azure DevOps  then everything about it should stay there.</p>  <p>I have full control over the test result XML generation.</p>""",azure-devops
44162372,"Azure Queue Storage triggered without removing message <p>How can I keep a message in the \function App\"" until I decide to remove it?</p>  <p>When I build a console app in c#  I can decide when I remove the message that I read with:</p>  <pre><code>queue.DeleteMessage(msg); </code></pre>  <p>I'm able to read the queue automatically with this procedure: <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-storage-queue-triggered-function\"" rel=\""nofollow noreferrer\"">functions-create-storage-queue-triggered-function</a>.</p>  <p>The problem is  like Azure said:</p>  <blockquote>   <ol start=\""5\"">   <li>Back in Storage Explorer  click Refresh and verify that the message has been processed and is no longer in the queue.</li>   </ol> </blockquote>  <p>In this context  I can't remove the message by myself when the function is done.</p>  <p>I tried to <code>Throw new Exception(\""failed\"");</code> to simulate a failed function but the message is removed anyway. </p>  <p>I'm looking to keep this message in queue until I decide to remove it (At the end of the function).</p>""",azure-functions
42445686,"Access Azure Function runtime settings <p>Is it possible to access/update the <a href=\https://github.com/Azure/azure-webjobs-sdk-script/blob/dev/src/WebJobs.Script.WebHost/Web.config\"" rel=\""nofollow noreferrer\"">Web.config used by WebJobs.Script.WebHost</a> or the <code>func.exe.Config</code> (in <code>C:\\Users\\{user}\\AppData\\Local\\Azure.Functions.Cli\\1.0.0-beta.91\\</code>)?</p>  <p>When I create an Azure Function using the Consumption plan and browse the file share  I do not see either of these files in any of the directories  but I'm assuming that the runtime is getting the settings from one of these files  or something similar.</p>  <p>Essentially  I would like to <a href=\""https://azure.microsoft.com/en-us/blog/removing-standard-server-headers-on-windows-azure-web-sites/\"" rel=\""nofollow noreferrer\"">remove the standard .NET headers</a> being returned by setting some values in one of these .config files.</p>""",azure-functions
14969972,"Using Azure Storage Tables as Queues with multiple Worker Roles processing it? <p>My application will be receiving 1000+ requests/transactions every second  via multiple instances of the Web Role. These roles will write a record for every transaction across  multiple Storage Tables (randomly  to spread Azure's 500 transactions/sec limit). Now  I need a reliable way to process/aggregate this data using multiple Worker Roles and write the results to my SQL database. AKA  this needs to scale horizontally.</p>  <p>I need to retain/archive all of the transactions in the Storage tables post-processing  so I could go with having one set of tables for queues  and when they are processed move them onto the archive tables  or perhaps there is a way to do this on a single table  not sure.</p>  <p>What would you recommend as far as a mechanism to distribute the current workload in these queues across my Work Roles? Obviously  each role has to be aware of what every other role is working on  so they only work on unclaimed transactions. I think each role will be retrieving 1000 records from the queue as a single work load and multiple worker roles could be working on the same queue.</p>  <p>Should I keep the Worker Roles \state\"" in a Cache  perhaps in SQL server. </p>  <p>Your suggestions are much appreciated.</p>""",azure-storage
38950821,"I am unable to open Azure's VM port <p>What i have tried so far...</p>  <ol> <li>Created azure VMs both on Classic and ARM.</li> <li>Created end points of classic and ARM machine(NSG) port:9000</li> <li>Open allow port 9000 in firewall on Windows Server R2 Datacenter</li> <li>Check port status on <code>check-host.net</code></li> <li>Default Port status (Remote Desktop) is open  other ports are closed.   </li> </ol>  <p>This is how i have created my end point in azure classic VM &amp; Make New Firewall Inbound Outbound Rules. </p>  <p><a href=\https://i.stack.imgur.com/GBLWF.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/GBLWF.jpg\"" alt=\""enter image description here\""></a></p>  <p>Test Result of My Custom Port (Closed) &amp; Remote Desktop Port (Open):</p>  <p>(I'm going to add my second image as a link in the comments)</p>  <p>Sorry for improper way of screenshots..actually i am new here so i can post only upto two links. </p>""",azure-virtual-machine
48712764,"Max Pool Size ignored working with Azure SQL and Azure AppServices <p>I'm working in a ASP.NET Web API project (Full .NET Framework 4.6.1) and using Azure SQL Database  the API is deployed on an Azure AppService. Regarding the service tiers  we are using S2 in the case of the Azure SQL Database (50 DTU) and B1 in the case of the AppService where is deployed the API endpoint (1 Core and 1.75 GB of RAM). At this moment we are using 2 instances (2 VM with load balancer)</p>  <p>Our QA team is trying to find out the capacity of the platform in terms of performance. They have configured a performance test with JMeter which consist on launching 4000 requests during an interval of 60 seconds.</p>  <p>After the first executions of the performance tests the ratio of HTTP 500 errors was very high  after taking a look to the logs  we found a lot of exceptions like this:</p>  <pre><code>System.InvalidOperationException: Timeout expired.  The timeout period elapsed prior to obtaining a connection from the pool.  This may have occurred because all pooled connections were in use and max pool size was reached.    at System.Data.Common.ADP.ExceptionWithStackTrace(Exception e) --- End of stack trace from previous location where exception was thrown ---    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)    at System.Data.Entity.SqlServer.DefaultSqlExecutionStrategy.&lt;&gt;c__DisplayClass4.&lt;&lt;ExecuteAsync&gt;b__3&gt;d__6.MoveNext() --- End of stack trace from previous location where exception was thrown ---    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)    at System.Data.Entity.SqlServer.DefaultSqlExecutionStrategy.&lt;ExecuteAsyncImplementation&gt;d__9`1.MoveNext() --- End of stack trace from previous location where exception was thrown ---    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)    at System.Data.Entity.Core.EntityClient.EntityConnection.&lt;OpenAsync&gt;d__8.MoveNext() </code></pre>  <p>The first thing I thought was on a connection leak issue  we were reviewing the code  and monitoring the connections on SQL Server using the sp_who2 command  but the connections was being disposed as expected. </p>  <p>We are using an injection container that is creating a Entity Framework context (queries are async) each time a new request must be processed  the Entity Framework context is disposed automatically when the request ends (scoped dependencies).</p>  <p>The conclusion we reached was that we needed to increase the size of the connection pool to mitigate the timeouts in scenarios with huge traffic load.</p>  <p>Doing a quick search in the internet I found out that the default value of the Max Pool Size value is 100:</p>  <p><a href=\https://www.connectionstrings.com/all-sql-server-connection-string-keywords/\"" rel=\""nofollow noreferrer\"">https://www.connectionstrings.com/all-sql-server-connection-string-keywords/</a></p>  <p>I decided to increase the value to 400:</p>  <pre><code>Server=tcp:XXXX.database.windows.net 1433;Initial Catalog=XXXX;Persist Security Info=False;User ID=XXXX;Password=XXXXXXXXXXXX;MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Max Pool Size=400; </code></pre>  <p>After repeating the performance test our surprise was that we didn't notice any improvement since we were receiving the same ratio of HTTP 500 errors. We reached the conclusion that the Max Pool Size was being ignored.</p>  <p>The next thing we did  was to monitor the SQL Server during the performance test in order to find out how many sessions was opened from each host process  at this moment we are using the following SQL sentence for this purpose:</p>  <pre><code>SELECT         COUNT(*) AS sessions   host_name   host_process_id   program_name   DB_NAME(database_id) AS database_name FROM             sys.dm_exec_sessions AS s WHERE         (is_user_process = 1) AND  (program_name = '.Net SqlClient Data Provider') GROUP BY host_name  host_process_id  program_name  database_id ORDER BY sessions DESC </code></pre>  <p>After monitoring the opened sessions by each host process (the virtual machines where is deployed the API endpoint) we found out that only 128 database sessions was being created from each virtual machine. </p>  <p>At this point several options comes up to my mind that it could explain such weird behaviour:</p>  <ul> <li>Bearing in mind that the connection pooling is a concept that belongs to the client side  the first thing that I thought was that some kind of parameter in the IIS Application Pool was being responsible of such behaviour.</li> <li>Another option it would be that only 128 sessions can be opened by each host process and database login. I didn't find anything in the internet that points to this .. but in other databases like Oracle this constraint can be configured in order to limit the amount of sessions opened by each login.</li> <li>The last option .. in some blogs and stackoverflow threads I have read that the exception that we are receiving (The timeout period elapsed prior to obtaining a connection from the pool.  This may have occurred because all pooled connections were in use and max pool size was reached) can be misleading and exists the possibility that other problem is causing the exception ..</li> </ul>  <p>The quick solution it would be to disable the pooling in the connection string  but this is the last thing that I would do ..</p>  <p>Another solution it would be to scale out the AppService in order to add more VM instances  but this is expensive in terms of money ..</p>  <p>Anyone knows if exists some kind of limitation in the Azure AppServices which explains why only 128 sessions are opened when the connection pooling is enabled?</p>""",azure-web-app-service
38396653,"Multiple VM Creation by ARM Powershell approach <p>I have a ps workflow(.psm file) where I am trying to create 5 vms in parallel. I am using ARM cmdlets.I am getting an error-</p>  <blockquote>   <p>Error- Cannot validate argument on parameter 'SubnetId'. The argument is null or empty. Provide an argument that is not null or empty  and then try the command    again.</p> </blockquote>  <p>Here is my challange-</p>  <ol> <li><p>Even if I remove <code>-parallel</code> parameter from <code>foreach</code> even then its not making any difference.</p></li> <li><p>If I run the same code NOT inside a workflow(ps1 file) removing <code>-parralel</code> parameter I am able to create 5 vms</p></li> </ol>  <p>Code-</p>  <pre><code>workflow Create-VMs {     $UserName = \abc@cde.onmicrosoft.com\""     $pwd = ConvertTo-SecureString \""xxxxxxxx\"" -AsPlainText -Force     $AzureCredential = New-Object System.Management.Automation.PSCredential($UserName  $pwd)      login-azurermaccount -credential $AzureCredential     Add-AzureRmAccount -Credential $AzureCredential     Select-AzureRmSubscription -SubscriptionName \""xxxxx\""      $virtualNetworkName = \""myvpn\""     $locationName = \""East US\""     $ResourceGroupName = \""myrg\""     $user = \""adminuser\""     $password = \""AdminPass123\""     $VMSize = \""Standard_D2\""     $sourcevhd = \""https://abc.blob.core.windows.net/vhds/windowsserver2008.vhd\""     $virtualNetwork = Get-AzureRmVirtualNetwork -ResourceGroupName $ResourceGroupName -Name $virtualNetworkName      foreach -parallel($i in 1..5)     {         $VMName = \""myname\"" + $i         $destinationVhd = \""https://abc.blob.core.windows.net/vhds/windowsserver2008\"" + $i + \"".vhd\""         $staticip = \""dynamicip\"" + $i         $virtualNetwork = Get-AzureRmVirtualNetwork -ResourceGroupName $ResourceGroupName -Name $virtualNetworkName         $publicIp = New-AzureRmPublicIpAddress -Name $staticip -ResourceGroupName $ResourceGroupName -Location $locationName -AllocationMethod Dynamic         $networkInterface = New-AzureRmNetworkInterface -ResourceGroupName $ResourceGroupName -Name $VMName -Location $locationName -SubnetId $virtualNetwork.Subnets[0].Id -PublicIpAddressId $publicIp.Id         $vmConfig = New-AzureRmVMConfig -VMName $VMName -VMSize $VMSize         $vmConfig = Set-AzureRmVMOSDisk -VM $vmConfig -Name $VMName -VhdUri $destinationVhd -CreateOption FromImage -Windows -SourceImageUri $sourcevhd         $vmConfig = Add-AzureRmVMNetworkInterface -VM $vmConfig -Id $networkInterface.Id         $securePassword = ConvertTo-SecureString $password -AsPlainText -Force         $cred = New-Object System.Management.Automation.PSCredential ($user  $securePassword)          Set-AzureRmVMOperatingSystem -VM $vmConfig -Windows -Credential $cred -ProvisionVMAgent -ComputerName $VMName         New-AzureRmVM -VM $vmConfig -Location $locationName -ResourceGroupName $ResourceGroupName     } } </code></pre>  <hr>  <p>Not able to find out what is the actual problem. Any other approach for creating multiple vms in parallel using ARM ?</p>""",azure-virtual-machine
57555223,Azure build pipeline publish to specific folder <p>I have an Azure build pipeline  and a Publish task:</p>  <pre><code>- task: DotNetCoreCLI@2   displayName: 'dotnet publish'   inputs:     command: 'publish'     projects: '**/MyProj.csproj'     arguments: '--configuration $(buildConfiguration) --output $(build.artifactstagingdirectory)\webjob\App_Data\jobs\triggered\MyProjWebJob /p:AssemblyVersion=$(GitVersion.AssemblySemVer)'     zipAfterPublish: false     publishWebProjects: false </code></pre>  <p>As you can see I am specifying an output directory - it is for a webjob and I have to have this format. The problem is  that the publish adds another directory with the name of the project:</p>  <pre><code>$(build.artifactstagingdirectory)\webjob\App_Data\jobs\triggered\MyProjWebJob\my.proj.webjob </code></pre>  <p>and it puts all the artifacts in there  but I do not want this additional directory - when I deploy it can't be there or the webjob isn't accessible. How do I publish without creating this directory?</p>,azure-devops
55144062,"Azure Web App with Acitve Directory Express with Graph API to get user photo <p>My Azure Web App has Active Directory enabled using the Express option. I can get the user claims/user's name from auth.me. How do I then get the user's photo/avatar?  The token I get is not working in a Graph API call.  I get this error from Graph API.  Here is my code.</p>  <p>Please help!  Spent hours searching and reading docs but nothing seems to address the Express AD scenario. Thanks Donnie </p>  <pre><code>{ \error\"": { \""code\"": \""InvalidAuthenticationToken\""  \""message\"": \""CompactToken parsing failed with error code: 80049217\""  \""innerError\"": {   \""request-id\"": \""e25f1fe5-4ede-4966-93c2-6d92d34da6ae\""    \""date\"": \""2019-03-13T14:13:26\"" } } }  axios.get('/.auth/me').then(resp =&gt; {        if(resp.data){            loggedInUser = {             accessToken:resp.data[0].access_token              userId: resp.data[0].user_id              username: resp.data[0].user_claims[9].val              lastname: resp.data[0].user_claims[8].val              fullname: resp.data[0].user_claims[11].val              avatar:'https://cdn.vuetifyjs.com/images/lists/1.jpg'           }            let config = {             'headers':{               'Authorization': 'Bearer ' + loggedInUser.accessToken             }           }             axios.get('https://graph.microsoft.com/v1.0/me/photos/48x48/$value' config).then(resp =&gt; {             let photo = resp.data;             const url = window.URL || window.webkitURL;             const blobUrl = url.createObjectURL(photo);             document.getElementById('avatar').setAttribute(\""src\""  blobUrl);             loggedInUser.avatar = blobUrl;             console.log(blobUrl)           });        }       }) </code></pre>""",azure-web-app-service
54672439,Azure DevOps - Display name Updates not being updated in Work Items <p>I'm having some problems updating the Display name from users.</p>  <p>The point is  we have some other systems which uses the name as from AD to locate users on Azure DevOps Online (I know  name should bot be used as a valid key unfortunately we have no control over those old systems...)</p>  <p>The point is  we have a thousand users with different display names from AD in our Azure DevOps  because users can put anything they want to... </p>  <p>I started my tests by changing my own display name from my profile  for my surprise it doesn't change anywhere else  there is  if I come back to my profile it is changed  but on every WI it remains the old one  should it not have changed on Work Items?</p>  <p>The second question would be if there's an easy way  to bulk change the Display Name for all users  I have found a couple of examples  but they are from 2010 and I'm not sure it would work on Azure DevOps Online Version</p>,azure-devops
45106071,"How to disable RC4 cipher in Azure VM Scaleset <p>I have a VM scale set with this image:</p>  <pre><code>Publisher: MicrosoftWindowsServer Offer: WindowsServer SKU: 2016-Datacenter-with-Containers Version: latest </code></pre>  <p>These machines are running SSL web endpoint hosted in service fabric. The website is build in dotnetcore with a WebListener which propably uses the http.sys</p>  <p>I was wondering why new VM images still supports RC4 ciphers and how to disable them. I don't want to do it manually because that will break to autoscaling.</p>  <p>Similar issue  but then for Worker roles: <a href=\https://stackoverflow.com/questions/29777559/how-to-disable-rc4-cipher-on-azure-web-roles\"">How to disable RC4 cipher on Azure Web Roles</a></p>""",azure-virtual-machine
57286438,"How to authenticate to Azure database with the users credentials not the web apps <p>I have an ASP.Net MVC web application that connects to an azure sql database. I have an account set up on that database using my AAD login. When I run locally (localhost) the web application loads fine and my credentials are authenticated successfully and I am able to query the database. When i publish the application to an app service on the cloud i am unable to authenticate on the database.</p>  <p>I followed this tutorial <a href=\https://docs.microsoft.com/en-us/azure/app-service/app-service-web-tutorial-connect-msi\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/app-service/app-service-web-tutorial-connect-msi</a> initially  which I understand authenticates as the app itself once published (I've proved this by registering the app to AAD and adding the Application API login to the Database)</p>  <p>What i really want is a way to authenticate as the user of the app not the app itself - i.e. An Azure version of Kerberos which we currently use for our on-prem applications</p>""",azure-web-app-service
32376349,"How are the \Cloud Services\"" created for Virtual Machines and Azure Cloud Services related? <p>When you create an Azure VM  it has to be placed into a Cloud Service (either new or existing).</p>  <p>Is that the exact same logical structure as an Azure Cloud Service that's created when deploying Web and Worker roles via Visual Studio?</p>  <p>Can I deploy Roles from VS into a Cloud Service created via VM creation?  I can deploy a VM into a Cloud Service created via VS deployment?  If either of those are true  how does that \""free-standing\"" VM relate to the Role VMs?  Is it just floating inside the Cloud Service independently from the Role VMs?</p>  <p>Thanks in advance!</p>""",azure-virtual-machine
16127953,Windows Azure   How to make custom registration process in Android App <p>I am using windows azure services for my android app  In this windows azure provide authentication from Facebook  Google Twitter etc.  </p>  <p>But i want custom registration for user and when user successfully register in app then they can also log in with there user id and pass that they created at registration time.</p>  <p>How is it possible using windows azure in android app.</p>,azure-storage
51564708,"How to Import NetworManangementClient in Azure using Python? <p>I want to obtain the public IP of a NIC interface in Azure using Python SDK. So  I need to import NetworkManagemenClient. </p>  <p>But when I do the following:</p>  <p>\from azure.mgmt.compute import NetworkManagementClient\"" or \""from azure.mgmt.resource import NetworkManagementClient\""</p>  <p>I am not able to import.</p>  <p>Any fixes?</p>""",azure-virtual-machine
35876272,Azure vm quick-start isn't linking the created IP address to the vm <p>When I use the vm quick-start to spin up a new Linux vm  it shows the public ip address being provisioned however it is not linked to the vm itself. If I go into the portal  I can see that the VM and IP exist  but must manually allow the IP to link to the VM. Why is this happening?</p>,azure-virtual-machine
21624860,"Windows Azure Storage emulator error occured <p>I was trying to install the Windows Azure SDK when this shows up:</p>  <pre><code> \System.NullReferenceException: Object reference is not set to an instance      of an object at MicrosoftHosting.DevelopmentStorage.Tools.DSInit.Controller.PerformActions() at     Microsoft.ServiceHosting.DevelopmentStorage.Tools.DSInit.DSInitProgram.Run(string args here)     at Microsoft.WindowsAzure.DSinit.Program.Main(string args here)\"" </code></pre>  <p>I downloaded the Windows Azure SDK for vs2013 through web platform and this error shows up. but then i downloaded the separate program again but then  same error shows up.can someone please help me identify the root cause of this? Thanks</p>""",azure-storage
52663175,How to manually start $(Rev:r) counter from specific number? <p>Say  I have a library which is already version 1.0.15</p>  <p>I migrate my build process to Azure DevOps  and want auto increment of build number. So in the build pipeline options  I set Build number format to <code>1.0.$(Rev:r)</code>.</p>  <p>But now it starts making builds at 1.0.1</p>  <p>So how do I artificially increment this to 15?</p>,azure-devops
32470159,"How to get php include_path to work on a custom directory '/var/custom_directory'? <p>I thought php include path was a pretty simple concept. I've done it many times  but now am having trouble getting it to work. </p>  <p>I am running an </p>  <blockquote>   <p>centos 7.1 server on azure with Apache/2.4.6 PHP/5.4.16</p> </blockquote>  <p>When I modify the <code>include_path</code> within <code>php.ini</code>. The error after restarting apache shows </p>  <blockquote>   <p>Failed opening required 'xfile' (include_path='.:/var/custom_directory')...</p> </blockquote>  <p>The include path is in the proper file format.</p>  <p>I might have an ownership problem. </p>  <p>I can place my files inside the default <code>usr/share/php</code> directory and the pages <code>\include\""</code>. However when I try to put my own directory inside of <code>/var</code> they do not.</p>  <p>I have done this before so I do not know why it isn't working now. I have chowned and chmod these directories and their contents to death. Even mimicing the server that works's directories. Switching ownership to <code>apache</code> and giving full grant access just trying to get it to see the file from my <code>/var/www/html/index.php</code></p>  <p>Am I missing something? Is there something I need to enable or grant access or modify in the <code>php</code> or <code>http.conf</code> files?</p>  <p>Further information: This is the only php.ini file included in the system /etc/php.ini</p>  <p>The purpose of the include path is to provide coding / user files behind the firewall.</p>  <p>I don't think this maters  but my vm is in Azure.</p>  <p>Putting something like this</p>  <pre><code>include('/var/custom_directory/file.php');  </code></pre>  <p>Doesn't work as well. Why?</p>""",azure-virtual-machine
46474941,Azure functions storage recommandation <p>I'm using Azure functions as micro services. I have 7 functions apps running in an App Service. What is the recommandation about the storage (AzureWebJobsStorage &amp; AzureWebJobsDashboard) ? </p>  <p>Should I create 2 storage accounts (1 for AzureWebJobsStorage &amp; 1 for AzureWebJobsDashboard) for each function app or can I share ?</p>,azure-functions
55273472,How to create a self Time triggered Function? <p>Looking for some self triggering function which starts on a time given. </p>  <p>eg. A user has a conference to start at 25/04/2019 05:30  Here the user should get a notification at 25/04/2019 05:25 | 05:29 That the conference is about to start. </p>  <p>Have created a azure function (Time triggred) which triggers every minute and checks if current time is the Conference Time  - 4 minutes  Then send a notification regarding conference to be started. </p>  <p>In future will have multiple users and so I do not want the function to run every minute  Is there a way in which at 05:25 or at the conference time  the function will execute itself.  So there can be 100 users and they will have different. Just looking for options about how to implement in a better way.</p>  <p>.net core site   hosted on azure  Have azure functions running every minute to check the remainder </p>,azure-functions
50037032,"Azure function failed to deploy with the error ERROR_CONNECTION_TERMINATED <h2>Issue Description</h2>  <p>I am trying to deploy the azure function using visual studio and getting the error: Web deployment task failed (Complete error logs are given below). I have followed all the steps mentioned in the article <a href=\http://techgenix.com/video-publish-azure-functions-azure-using-visual-studio-tools-azure-functions/\"" rel=\""nofollow noreferrer\"">http://techgenix.com/video-publish-azure-functions-azure-using-visual-studio-tools-azure-functions/</a> but still facing the issue. Please help me as I have spent a lot of time on this issue and didn't get any solution.</p>  <p>Fiddler was not running when I deployed the azure function using visual studio.</p>  <h3>Error logs</h3>  <pre><code>1&gt;------ Build started: Project: TestFunction  Configuration: Release Any CPU ------ 1&gt;TestFunction -&gt; C:\\Repo\\TestFunction\\TestFunction\\bin\\Release\\net461\\bin\\TestFunction.dll ========== Build: 1 succeeded  0 failed  0 up-to-date  0 skipped ==========   Publish Started   TestFunction -&gt; C:\\Repo\\TestFunction\\TestFunction\\bin\\Release\\net461\\bin\\TestFunction.dll   TestFunction -&gt; C:\\Repo\\TestFunction\\TestFunction\\obj\\Release\\net461\\PubTmp\\Out\\ C:\\Program Files\\dotnet\\sdk\\2.1.300-preview1-008174\\Sdks\\Microsoft.NET.Sdk.Publish\\build\\netstandard1.0\\PublishTargets\\Microsoft.NET.Sdk.Publish.MSDeploy.targets(139 5): error : Web deployment task failed. (Web Deploy experienced a connection problem with the server and had to terminate the connection.  Contact your server administrator if the problem persists.  Learn more at: http://go.microsoft.com/fwlink/?LinkId=221672#ERROR_CONNECTION_TERMINATED.) [C:\\Repo\\TestFunction\\TestFunction\\TestFunction.csproj] C:\\Program Files\\dotnet\\sdk\\2.1.300-preview1-008174\\Sdks\\Microsoft.NET.Sdk.Publish\\build\\netstandard1.0\\PublishTargets\\Microsoft.NET.Sdk.Publish.MSDeploy.targets(139 5): error :  [C:\\Repo\\TestFunction\\TestFunction\\TestFunction.csproj] C:\\Program Files\\dotnet\\sdk\\2.1.300-preview1-008174\\Sdks\\Microsoft.NET.Sdk.Publish\\build\\netstandard1.0\\PublishTargets\\Microsoft.NET.Sdk.Publish.MSDeploy.targets(139 5): error : Web Deploy experienced a connection problem with the server and had to terminate the connection.  Contact your server administrator if the problem persists.  Learn more at: http://go.microsoft.com/fwlink/?LinkId=221672#ERROR_CONNECTION_TERMINATED. [C:\\Repo\\TestFunction\\TestFunction\\TestFunction.csproj] C:\\Program Files\\dotnet\\sdk\\2.1.300-preview1-008174\\Sdks\\Microsoft.NET.Sdk.Publish\\build\\netstandard1.0\\PublishTargets\\Microsoft.NET.Sdk.Publish.MSDeploy.targets(139 5): error : Root element is missing. [C:\\Repo\\TestFunction\\TestFunction\\TestFunction.csproj]   Publish failed to deploy. </code></pre>""",azure-functions
55561689,"How ti fix the \You do not have permission to view this directory or page.\"" issue in Azure web app services? <p>I have a simple web app which if I deploy to Azure through Intelij (Using Azure App plugin ) the app works perfectly. But when I tried deploying using Jenkins the log says deployment successful   but when I try to navigate to the site it says \""You do not have permission to view this directory or page.\"" Am I missing anything ?</p>  <p>As per my understanding as My project is working fine when deployed using Intelij  but not working through Jenkins  so the problem will be in my Jenkins Job. Here is the configuration I am  using :  Publish Files  Files  :target\\spring-mvc-example.war  Source Directory(optional):target  Target Directory(optional): webapps</p>""",azure-web-app-service
49451858,"Azure PowerShell return the Name of CustomScriptExtension if it exists <p>I have created a variable called <code>$VMStatus</code></p>  <pre><code>$VMStatus = Get-AzureRmVM -ResourceGroupName $RGName -VMName $VMName -status </code></pre>  <p>Now when I run <code>$VMStatus.Extensions.Type</code>  it returns the list of virtual machine extensions for the provided entries.</p>  <p>So now when I run <code>$VMStatus.Extensions.Type -Match \Custom\""</code>  it returns the entry I am interested in: <code>Microsoft.Compute.CustomScriptExtension</code></p>  <p>The problem I am having is getting the <code>Name</code> of that <code>CustomScriptExtension</code>.  I have tried the following with no success:</p>  <pre><code>IF ($VMstatus.Extensions.Type -Match \""Custom\"") {$VMstatus.Extensions.Name} </code></pre>  <p>This will actually return ALL entries for <code>Name</code> since the first part of the <code>IF</code> statement is <code>TRUE</code>.</p>  <p>How do I return just the <code>Name</code> of the <code>CustomrScriptExtension</code> if one exists?</p>""",azure-virtual-machine
53396177,"how to create VM with Json arm template using define VHD (or disk snapshot)? <p>The question in the title: \how to create VM with Json arm template using define VHD (or disk snapshot) in azure?\"" Thanks for your help! </p>""",azure-virtual-machine
52987660,vsts-agent in OpenShift <p>I run the agent in my machine and it works just perfect. Then I pushed my image to openshift  then I got some permission denied issue: <code>./start.sh: line 19: /vsts/.token: Permission denied</code></p>  <p>I tried to find how to give these permissions within OpenShift  but I was not able to find yet  someone has any idea?</p>,azure-devops
43606096,"Unable to find free machine on self-provisioned load test rig <p>We have recently been performing load testing as part of a build(using the Cloud Load Test build task) using a self-provisioned load testing rig deployed using the following quick start template -</p>  <p><a href=\https://github.com/Azure/azure-quickstart-templates/tree/master/101-vsts-cloudloadtest-rig\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-quickstart-templates/tree/master/101-vsts-cloudloadtest-rig</a></p>  <p>This has been working well for us  but something seems to have changed and this process no longer works. When the load test task starts we now get the following error:</p>  <pre><code>2017-04-24T14:32:07.4831251Z [Message]This load test was run using self-provisioned rig 'default'. No virtual-user minutes (VUMs) will be charged for this run. 2017-04-24T14:32:07.4881254Z ##[error]Microsoft.PowerShell.Commands.WriteErrorException: Test run could not be started using the self-provisioned rig 0ebc4aad-33b2-495e-a75a-213d4607976b. Number of free machines available in the rig are less than the required number. (Requested – 1  Available - 0  In-Use – 0  Offline – 3). </code></pre>  <p>Using the ManageVSTSCloudLoadAgent.ps1 script</p>  <p><a href=\""https://blogs.msdn.microsoft.com/visualstudioalm/2016/08/23/testing-privateintranet-applications-using-cloud-based-load-testing/\"" rel=\""nofollow noreferrer\"">https://blogs.msdn.microsoft.com/visualstudioalm/2016/08/23/testing-privateintranet-applications-using-cloud-based-load-testing/</a></p>  <p>I can see that there is an agent group called \""LoadTesting\"" with my two provisioned VM's in it  which shows them both as Free. However the GUID for this LoadTesting group does not match the one in the error message that the build task is attempting to use. According to the script there is only one rig available so I dont know where the cloud task is getting this other one from.</p>  <p>How can I change the task to use the correct group? Or change the 'LoadTesting\"" group to be the default? </p>  <p>I can't find anywhere within the load test definitions or through the team services site where I can make changes to to which rig it uses.</p>""",azure-devops
45588260,How to automatically restart an app service after certain time? <p>How to automatically restart an app service after 24 hours? How to schedule the app service to restart automatically at a specific time through the use of web jobs?</p>,azure-web-app-service
30883365,'Your credentials did not work' in MS Azure <p>I just created an Azure VM using the Windows 8.1 image in the Marketplace. During the creation process I provided a username and password.</p>  <p>After the VM has been created I press connect and try and login via MSTSC - using the credentials that I just entered (with a slash to remove the domain).</p>  <p>But I keep getting 'Your credentials did not work'. What have I done wrong? This procedure has worked for me in the past.</p>  <p>Furthermore  when I review the users of the VM through the portal  I only see 'Subscription admins' containing my Microsoft ID. I can't login using my Microsoft ID either.</p>,azure-virtual-machine
53062671,"Azure Functions: Can I have different configuration for BlobTriggered function? <p>I have a .Net project which contains  multiple trigger in a same azure function project (a blob triggered function &amp; a Queue triggered function).</p>  <p>I need a different concurrency for my blob triggered function from queue triggered function.</p>  <p>I know that the blob trigger uses a queue internally. </p>  <p><a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob#trigger---poison-blobs\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob#trigger---poison-blobs</a></p>  <p>Is there any way I can achieve it?</p>""",azure-functions
39199201,"Git stuck at deltafying objects <p>My source code ( with pictures ) size is ~500MB.<br> <strong>But I can't push it to any git repository</strong>: My git push attempt is stucked at \deltafying objects\"" in VS.<br> I watched my network in: ~3kb/s. out: 100kb/s. But still not pushing.</p>  <p>Here is a screenshot from visual studio:</p>  <p><a href=\""https://i.stack.imgur.com/iwuHJ.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/iwuHJ.png\"" alt=\""enter image description here\""></a></p>  <p>I tried in visual studio  to push it Visual Studio Team Services (with git) didn't work. I tried sourcetree(v1.9.6.1) for checking it to bitbucket. Didn't work. I tried git console  didn't work.</p>  <p>My Visual Studio Enterprise 2015 has \""Git-2.9.3.2-64bit\"" also this git version installed on my machine.</p>  <p><strong>Update:</strong> More information: I tried on source-tree again  here is console output;  </p>  <pre><code>git -c diff.mnemonicprefix=false -c core.quotepath=false push -v --tags --set-upstream LeanStartup master:master   POST git-receive-pack (163209032 bytes)   fatal: The remote end hung up unexpectedly   fatal: The remote end hung up unexpectedly   error: RPC failed; curl 56 SSL read: error:00000000:lib(0):func(0):reason(0)  errno 10054   Pushing to https://*****@bitbucket.org/*****/leanstartup.git   Everything up-to-date   Completed with errors  see above.   </code></pre>  <p><strong>Update 2</strong>: I tried on another solution ( just changed 1-2 things to commit and push). My git in Visual Studio &amp; Source Tree is working well.<br> So maybe I need to suspect for one solution \""leanstartup\""?.<br> I tried to delete files: \""<code>.gitattributes</code>\"" \""<code>.gitignore</code>\"" and folder: \""<code>.git</code>\"" on solution folder to re-assign the git source control.<br> But again  It hangs on \""deltafying objects\"".<br> Do you I need to delete more git data from somewhere else to clear all git-assigment on this project?</p>  <p>What can I do to fix this problem ?</p>""",azure-devops
9398159,"How to control azure storage account costs in Azure when using WAD tables <p>We do not use our Azure storage account for anything except standard Azure infrastructure concerns (i.e. no application data). For example  the only tables we have are the WAD (Windows Azure Diagnostics) ones  and our only blob containers are for vsdeploy  iislogfiles  etc. We do not use queues in the app either. </p>  <p>14 cents per gigabyte isn't breaking the bank yet  but after several months of logging WAD info to these tables  the storage account is quickly nearing 100 GB. </p>  <p>We've found that deleting rows from these tables is painful  with continuation tokens  etc  because some contain millions of rows (have been logging diagnostics info since June 2011). </p>  <p>One idea I have is to \cycle\"" storage accounts. Since they contain diagnostic data used by MS to help us debug unexpected exceptions and errors  we could log the WAD info to storage account A for a month  then switch to account B for the following month  then C. </p>  <p>By the time we get to the 3rd month  it's a pretty safe bet that we no longer need the diagnostics data from storage account A  and can safely delete it  or delete the tables themselves rather than individual rows. </p>  <p>Has anyone tried an approach like this? How do you keep WAD storage costs under control?</p>""",azure-storage
18621787,"How to add a empty disk to a virtual machine under new storage location? <p>I'd like to add an empty data disk to a virtual drive under a new storage location.  When I have the virtual machine select and click Add -> Empty Data Disk I'm not able to change the storage location.  Does anyone know how to change the default storage location when adding an empty disk?  Thanks</p>  <p><strong>UPDATE</strong></p>  <p>I believe this is the command that needs to be run.  But running it on the vm doesn't do anything.</p>  <pre><code>Get-AzureVM \service\"" -Name \""vmname\"" `| Add-AzureDataDisk -CreateNew -DiskSizeInGB 1000 -DiskLabel \""sqlsa1\"" -MediaLocation \""http://mystoragelocation.blob.core.windows.net/\"" -LUN 4 '| Update-AzureVM </code></pre>""",azure-virtual-machine
46641696,"Send Artifacts to external server <p>I'm a little lost between Custom Agent   powersheel script etc.</p>  <p>I want to send artifacts (dll) to an external website (MVC) at the end of the build.</p>  <p>What the simpliest way to do it?</p>  <ul> <li>Make a new custom agent</li> <li>Make a powershell script</li> <li>Send a zip file to website with an existing task (\Publish Artifact\""  \""Upload with cURL\""  \""FTP Upload\"")</li> </ul>  <p>Regarding my skill I'm thinking about sending all artifacts to the website and then just make a call on my website like www.website.com/newArtifactUploaded.</p>  <p>But I'have no idea what is the best way to do it and how to do it. Do you have any suggestion idea or documentation / tutorial ?</p>""",azure-devops
48373669,"azure functions throw System.OperationCanceledException <p>My project is using Azure function send data to AWS SNS. However there is a Exception throw out roughly 1 per day. We process 400 000 data per day. Does this means the function running more than 5 mins and azure function canceled this thread or there is another reason? We monitor Azure function using application insight.</p>  <pre><code>\System.Threading.CancellationToken.ThrowOperationCanceledException\"".  </code></pre>  <p>Error log:</p>  <pre><code>System.OperationCanceledException:    at System.Threading.CancellationToken.ThrowOperationCanceledException (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at Microsoft.Azure.WebJobs.ServiceBus.Listeners.NamespaceManagerExtensions+&lt;CreateSubscriptionIfNotExistsAsync&gt;d__4.MoveNext (Microsoft.Azure.WebJobs.ServiceBus  Version=2.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at Microsoft.Azure.WebJobs.ServiceBus.Listeners.ServiceBusSubscriptionListenerFactory+&lt;CreateAsync&gt;d__8.MoveNext (Microsoft.Azure.WebJobs.ServiceBus  Version=2.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at Microsoft.Azure.WebJobs.Host.Indexers.FunctionIndexer+ListenerFactory+&lt;CreateAsync&gt;d__5.MoveNext (Microsoft.Azure.WebJobs.Host  Version=2.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at Microsoft.Azure.WebJobs.Host.Listeners.HostListenerFactory+&lt;CreateAsync&gt;d__10.MoveNext (Microsoft.Azure.WebJobs.Host  Version=2.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at Microsoft.Azure.WebJobs.Host.Listeners.ListenerFactoryListener+&lt;StartAsyncCore&gt;d__8.MoveNext (Microsoft.Azure.WebJobs.Host  Version=2.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at Microsoft.Azure.WebJobs.Host.Listeners.ShutdownListener+&lt;StartAsync&gt;d__5.MoveNext (Microsoft.Azure.WebJobs.Host  Version=2.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at Microsoft.Azure.WebJobs.JobHost+&lt;StartAsyncCore&gt;d__25.MoveNext (Microsoft.Azure.WebJobs.Host  Version=2.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (mscorlib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=b77a5c561934e089)    at Microsoft.Azure.WebJobs.Script.ScriptHostManager.RunAndBlock (Microsoft.Azure.WebJobs.Script  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\projects\\azure-webjobs-sdk-script\\src\\WebJobs.Script\\Host\\ScriptHostManager.cs: 184) </code></pre>""",azure-functions
43539498,Azure storage underlying technology <p>What is Azure storage made of  the underlying storage technology which supports the Azure storage we access in azure portal? </p>  <p>Is it object based storage or block storage (persistent/ephemeral) similar to categorization in Ceph?</p>  <p>If there is a mix of block and object based  which storage is used for each of exposed Azure storage service - block blob  append blob  page blob  storage tables  storage queues  Azure files</p>,azure-storage
56794684,Azure Dev Ops Build Agent's builds and releases used <p>In Azure DevOps is it possible to see all of the builds and releases that are configured to use a particular agent pool? I can see the last 30 builds that have been associated with the agent but would like to see all the builds associated with the pool rather than have to check all of the agent configurations for the build stages. The agent is a self hosted agent as well  if that makes a difference. I don't mind if it is through the UI or the REST api I get this data.</p>,azure-devops
40914738,"Migrate EC2 from AWS to Azure <p>We have a requirement to Migrate EC2 instance of AWS to Azure as VM  have been trying to implement the same from <a href=\https://azure.microsoft.com/en-in/blog/seamlessly-migrate-your-application-from-aws-to-azure-in-4-simple-steps/\"" rel=\""nofollow noreferrer\"">this source</a>   unable to complete the process. Tried and stuck on Protection Group.</p>  <p>I'm looking in these other links </p>  <p><a href=\""https://dzone.com/articles/migrating-vm-ec2-azure-300\"" rel=\""nofollow noreferrer\"">Migrating a VM from EC2 to Azure at 300 Mbps</a> For this I'm able to create VM in Classis portal but unable connect to it only port 80 is active all other ports are not working <a href=\""https://i.stack.imgur.com/dk5X2.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/dk5X2.png\"" alt=\""See the Inline image where all ports are enabled\""></a></p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/site-recovery/site-recovery-migrate-aws-to-azure\"" rel=\""nofollow noreferrer\"">Migrate virtual machines in Amazon Web Services (AWS) to Azure with Azure Site Recovery</a></p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/site-recovery/site-recovery-vmware-to-azure\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/site-recovery/site-recovery-vmware-to-azure</a></p>  <p><a href=\""https://aws.amazon.com/ec2/vm-import/\"" rel=\""nofollow noreferrer\"">https://aws.amazon.com/ec2/vm-import/</a> on trying this I'm getting this unresolved <a href=\""https://forums.aws.amazon.com/message.jspa?messageID=606602\"" rel=\""nofollow noreferrer\"">EC2 API export to S3 ACL issue</a></p>  <p>Can anyone suggest me a workflow on how to implement this?</p>""",azure-virtual-machine
54685039,How to fetch a file using nifi from a fileshare location? <p>I am trying to fetch some files from a fileshare location in a azure storage account using NiFi. I tried the fetchFTP processor but it is not being able to connect to the url of the fileshare location . I tried putting the correct parameters  but I am getting an error. </p>  <blockquote>   <p>Failed to fetch file on remote host due to java.net.UknownHostException:</p> </blockquote>,azure-storage
46102880,Azure powershell - how to get FQDN from a VM? <p>I am automating the deployment of several Azure VMs and I want to WinRM into each of them to finish the deployment. How do I find the FQDN of the VM from the script that creates it?</p>  <p>I'm looking for:</p>  <pre><code>$psVirtualMachine = Add-AzureRmVMNetworkInterface -VM $psVirtualMachine -Id $Nic.Id  $CreateNewVM = New-AzureRMVM -ResourceGroupName $ResourceGroupName -Location $GeoLocation -VM $psVirtualMachine  Enter-PSSession -ConnectionUri https://&lt;-- $CreateNewVM.FQDN --&gt;:5986 -Credential $Cred -SessionOption (New-PSSessionOption -SkipCACheck -SkipCNCheck -SkipRevocationCheck) -Authentication Negotiate </code></pre>,azure-virtual-machine
51821295,"Using Kudu with multi-instance app service in Azure <p>In Azure I have a Linux Web App (for containers) running under an app service plan of 2 instances (set under the \Scale out\"" menu item). If I understood correctly  this corresponds to my application being hosted on two separate VM instances in Azure. </p>  <p>If I then use the debug console in the Kudu interface (Developement Tools-> Advanced Tools) what am I actually logging on to ? Is it one of the VMs which hosts my Docker container ? If so why am I not prompted to choose the VM (seeing as I configured 2 in the plan) ? </p>""",azure-web-app-service
50319740,"Azure Functions - File not found <p>I'm following this guide to get Azure Functions installed and creating an app: <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-run-local\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-run-local</a></p>  <p>When I run the command <code>func init MyFunctionProj</code> I should get an output like this:</p>  <pre><code>Writing .gitignore Writing host.json Writing local.settings.json Created launch.json Initialized empty Git repository in D:/Code/Playground/MyFunctionProj/.git/ </code></pre>  <p>But instead I get this:</p>  <pre><code>Writing .gitignore Writing host.json Writing local.settings.json Writing C:\\Users\\nahue\\dev\\MyFunctionProj\\.vscode\\extensions.json El sistema no puede encontrar el archivo especificado </code></pre>  <p>Translation: \""File not found\"".</p>  <p>I've already installed all the things mentioned in the link and it doesn't work. It creates that folder called \"".vscode\"" with that \""extensions.json\"" file inside and it doesn't create \""launch.json\""  I don't know why. I don't have Visual Studio nor VS Code installed in my computer.</p>""",azure-functions
57137042,"Flask Azure web app deployed successfully but showing default page <p>I deployed a python flask app with azure web service using local git. The status in the deployment center shows \success\"" but when i go to the web page  it is still the default page that tells me I'm running python 3.6.6.</p>  <p>When i navigate to the kudu git clone uri it says \"" no route registered for '/testapp1.git'</p>  <p>The /wwwroot folder in kudu also has the following files.</p>  <pre><code>env static (css folder) __pycache__ app.py hostingstart-python.html hostingstart-python.py index.html requirements.txt web.config </code></pre>  <p>A potential problem could be because the web.config file is still refering to the hostingstart-python.application.</p>  <pre><code>&lt;configuration&gt;    &lt;appSettings&gt;       &lt;add key =\""pythonpath\"" value=\""%systemDrive%home\\site\\wwwroot\"" /&gt;       &lt;add key =\""WSGI_HANDLER\"" value=\""hostingstart-python.application\"" /&gt;    &lt;/appSettings&gt; &lt;/configuration&gt; </code></pre>  <p>I tried to follow the instructions on <a href=\""https://docs.microsoft.com/en-us/azure/app-service/containers/how-to-configure-python\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/app-service/containers/how-to-configure-python</a> but this is for linux so i'm not sure what to do as i'm running Windows 10.</p>""",azure-web-app-service
20968594,Reset message visibility Azure Storage Queue <p>I have an azure storage Queue with many messages  that were checked out (getQueueMessages) with a very long visibility timeout (>72hrs  setVisibilityTimeoutInSeconds). The dequeue process crashed  leaving of millions of messages stuck in the queue  we have to wait now a long time until they expire and become visible in the queue again.</p>  <p>Is there a way to reset the visibility timeout for all messages in the queue  that is  to make all invisible messages visible again  without having the pop receipt/id for each message?</p>,azure-storage
41174693,"Xamarin app crash when attempting to sync SyncTable <p>I making an app using xamarin and azure mobile service. I am attempting to add offline sync capabilities but I am stuck. I have a service which looks like this </p>  <pre><code>class AzureService     {          public MobileServiceClient Client;          AuthHandler authHandler;         IMobileServiceTable&lt;Subscription&gt; subscriptionTable;         IMobileServiceSyncTable&lt;ShopItem&gt; shopItemTable;         IMobileServiceSyncTable&lt;ContraceptionCenter&gt; contraceptionCenterTable;         IMobileServiceTable&lt;Member&gt; memberTable;         const string offlineDbPath = @\localstore.db\"";           static AzureService defaultInstance = new AzureService();         private AzureService()         {             this.authHandler = new AuthHandler();             this.Client = new MobileServiceClient(Constants.ApplicationURL  authHandler);              if (!string.IsNullOrWhiteSpace(Settings.AuthToken) &amp;&amp; !string.IsNullOrWhiteSpace(Settings.UserId))             {                 Client.CurrentUser = new MobileServiceUser(Settings.UserId);                 Client.CurrentUser.MobileServiceAuthenticationToken = Settings.AuthToken;             }              authHandler.Client = Client;              //local sync table definitions             //var path = \""syncstore.db\"";             //path = Path.Combine(MobileServiceClient.DefaultDatabasePath  path);              //setup our local sqlite store and intialize our table             var store = new MobileServiceSQLiteStore(offlineDbPath);              //Define sync table             store.DefineTable&lt;ShopItem&gt;();             store.DefineTable&lt;ContraceptionCenter&gt;();              //Initialize file sync context             //Client.InitializeFileSyncContext(new ShopItemFileSyncHandler(this)  store);              //Initialize SyncContext             this.Client.SyncContext.InitializeAsync(store);              //Tables             contraceptionCenterTable = Client.GetSyncTable&lt;ContraceptionCenter&gt;();             subscriptionTable = Client.GetTable&lt;Subscription&gt;();             shopItemTable = Client.GetSyncTable&lt;ShopItem&gt;();             memberTable = Client.GetTable&lt;Member&gt;();          }          public static AzureService defaultManager         {             get { return defaultInstance; }             set { defaultInstance = value; }         }          public MobileServiceClient CurrentClient         {             get { return Client; }         }  public async Task&lt;IEnumerable&lt;ContraceptionCenter&gt;&gt; GetContraceptionCenters()         {             try             {                 await this.SyncContraceptionCenters();                 return await contraceptionCenterTable.ToEnumerableAsync();             }             catch (MobileServiceInvalidOperationException msioe)             {                 Debug.WriteLine(@\""Invalid sync operation: {0}\""  msioe.Message);             }             catch (Exception e)             {                 Debug.WriteLine(@\""Sync error: {0}\""  e.Message);             }             return null;            } public async Task SyncContraceptionCenters()         {              ReadOnlyCollection&lt;MobileServiceTableOperationError&gt; syncErrors = null;              try             {                 //await this.Client.SyncContext.PushAsync();                  await this.contraceptionCenterTable.PullAsync(                     //The first parameter is a query name that is used internally by the client SDK to implement incremental sync.                     //Use a different query name for each unique query in your program                     \""allContraceptionCenters\""                      this.contraceptionCenterTable.CreateQuery());             }             catch (MobileServicePushFailedException exc)             {                 if (exc.PushResult != null)                 {                     syncErrors = exc.PushResult.Errors;                 }             }              // Simple error/conflict handling. A real application would handle the various errors like network conditions              // server conflicts and others via the IMobileServiceSyncHandler.             if (syncErrors != null)             {                 foreach (var error in syncErrors)                 {                     if (error.OperationKind == MobileServiceTableOperationKind.Update &amp;&amp; error.Result != null)                     {                         //Update failed  reverting to server's copy.                         await error.CancelAndUpdateItemAsync(error.Result);                     }                     else                     {                         // Discard local change.                         await error.CancelAndDiscardItemAsync();                     }                      Debug.WriteLine(@\""Error executing sync operation. Item: {0} ({1}). Operation discarded.\""  error.TableName  error.Item[\""id\""]);                 }             }         } </code></pre>  <p>I am getting this error: <code>System.NullReferenceException: Object reference not set to an instance of an object.</code> When the <code>SyncContraceptionCenters()</code> is run. As far as I can tell I reproduced the coffeeItems example in my service But I am stuck.</p>""",azure-storage
56776185,"Merging coverage results from multiple Azure Pipeline jobs in Python (with pytest) <p>I've setup my open source project to run CI with Azure Pipelines  and am collecting code coverage following the example from the Azure pipelines docs on <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/languages/python?view=azure-devops#test-with-pytest-and-collect-coverage-metrics-with-pytest-cov\"" rel=\""nofollow noreferrer\"">how to test Python apps</a>.</p>  <p>This seems to work pretty well  but the code coverage statistics seem to only pick up a test results from a single job (at random). To get complete coverage for my project (e.g.  for platform dependent code)  I really need to aggregate coverage across all of the test jobs.</p>  <p>Here are the relevant tasks from my pipeline:</p>  <pre><code>- bash: |     source activate test_env     pytest xarray --junitxml=junit/test-results.xml \\     --cov=xarray --cov-config=ci/.coveragerc --cov-report=xml   displayName: Run tests - task: PublishCodeCoverageResults@1   inputs:     codeCoverageTool: Cobertura     summaryFileLocation: '$(System.DefaultWorkingDirectory)/**/coverage.xml'     reportDirectory: '$(System.DefaultWorkingDirectory)/**/htmlcov' </code></pre>  <p>What's the right way to configure Azure to show this information?</p>  <p>I've tried adding <code>--cov-append</code> into my <code>pytest</code> invocation but that doesn't seem to make a difference.</p>""",azure-devops
57291779,"Publish build artifact through build.cake instead of Azure Devops <ol> <li>Is it possible to publish an build artifact to Azure Devops/TFS through build.cake script?</li> <li>Where should the responsibility for publishing the build artifact be configured when converting to cake scripts  in the build.cake script or in the Azure DevOps pipeline?</li> </ol>  <p>To achieve versioning in our build and release pipelines we decided to move our (gitversion  clean  build  tests  ...) tasks to be handled by a cake script stored in each repository instead. </p>  <p>Is there a way to replace the <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/publish-build-artifacts?view=azure-devops\"" rel=\""nofollow noreferrer\"">publish build artifact(Azure DevOps)</a> task with a task in the cake.build? I have searched the official documentation of both Azure and cake but can not seem to find a solution.  The first task  copying the build artifacts to a staging directory is possible  however  publishing the artifact - is where it gets complicated.</p>  <p>Currently  a snippet of our <strong>build.cake</strong>.</p>  <pre><code>Task(\""Copy-Bin\"")     .WithCriteria(!isLocalBuild)     .Does(() =&gt;     {         Information($\""Creating directory {artifactStagingDir}/drop\"");         CreateDirectory($\""{artifactStagingDir}/drop\"");         Information($\""Copying all files from {solutionDir}/{moduleName}.ServiceHost/bin to {artifactStagingDir}/drop/bin\"");         CopyDirectory($\""{solutionDir}/{moduleName}.ServiceHost/bin\""  $\""{artifactStagingDir}/drop/bin\"");         // Now we should publish the artifact to TFS/Azure Devops     }); </code></pre>  <p>Solution</p>  <p>A snippet of an <strong>updated build.cake</strong>.</p>  <pre><code>Task(\""Copy-And-Publish-Artifacts\"")     .WithCriteria(BuildSystem.IsRunningOnAzurePipelinesHosted)     .Does(() =&gt;     {         Information($\""Creating directory {artifactStagingDir}/drop\"");         CreateDirectory($\""{artifactStagingDir}/drop\"");         Information($\""Copying all files from {solutionDir}/{moduleName}.ServiceHost/bin to {artifactStagingDir}/drop/bin\"");         CopyDirectory($\""{solutionDir}/{moduleName}.ServiceHost/bin\""  $\""{artifactStagingDir}/drop/bin\"");         Information($\""Uploading files from artifact directory: {artifactStagingDir}/drop to TFS\"");         TFBuild.Commands.UploadArtifactDirectory($\""{artifactStagingDir}/drop\"");     }); </code></pre>""",azure-devops
56762589,"Unable to load the dll libwkhtmltox using dinktopdf for a .net core2.2 azure functionapp <p>I have an Azure functionapp using .net Core 2.2 that is written for the converting the html text to pdf. I am using the DinkToPdf. When I run the function  I get \Unable to load the libwkhtmltox.dll. I have tried the alternate solutions as mentioned in some of the posts  but it still throws the same error. </p>  <p>I tried using Directory.GetCurrentDirectory and using path.combine</p>  <p>The code is below:</p>  <pre><code>        [FunctionName(\""Function1\"")]         public static async Task&lt;IActionResult&gt; Run(             [HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = null)] HttpRequest req              ILogger log)         {             log.LogInformation(\""C# HTTP trigger function processed a request.\"");              CustomAssemblyLoadContext context = new CustomAssemblyLoadContext();             var architectureFolder = (IntPtr.Size == 8) ? \""64 bit\"" : \""32 bit\"";             context.LoadUnmanagedLibrary($@\""{Directory.GetCurrentDirectory()}\\Dependencies\\libwkhtmltox.dll\"");              var IocContainer = new SynchronizedConverter(new PdfTools());             string html = await new StreamReader(req.Body).ReadToEndAsync();             var globalSettings = new GlobalSettings             {                 ColorMode = ColorMode.Color                  Orientation = Orientation.Portrait                  PaperSize = PaperKind.A4                  Margins = new MarginSettings { Top = 10 }              };             var objectSettings = new ObjectSettings             {                 PagesCount = true                  WebSettings = { DefaultEncoding = \""utf-8\"" }                  HtmlContent = html             };              var pdf = new HtmlToPdfDocument()             {                 GlobalSettings = globalSettings                  Objects = { objectSettings }             };              byte[] pdfBytes = null;// IocContainer.Convert(pdf);             return new FileContentResult(pdfBytes  \""application/pdf\"");         } } </code></pre>""",azure-functions
54604833,"Azure VM Scale Set: is it possible to pass bootstrap script/settings without downloading them from URL? <p>I can see that with Custom Script Extension it is possible to bootstrap new VMs (in Scale Set). To access a script it needs azure storage URI and credentials. This approach doesn't work for me because (internal policies) it's not allowed to pass storage credentials.</p>  <p>My VMSS has assigned service identity  the latter is registered with KeyVault. So  it is quite straightforward to get credentials directly on a box. But for this I need at least small bootstrap script =)</p>  <p>I found one hacky way how to achieve this through Custom Script Extension:</p>  <pre><code>$bootstrapScriptPath = Join-Path -Path $PSScriptRoot -ChildPath \bootstrap.ps1\"" $bootstrapScriptBlock = get-command $bootstrapScriptPath | Select -ExpandProperty ScriptBlock $installScriptBase64 = [System.Convert]::ToBase64String([System.Text.Encoding]::Unicode.GetBytes($bootstrapScriptBlock.ToString()))  \""commandToExecute\"": \""[concat('powershell -ExecutionPolicy Unrestricted -EncodedCommand '  parameters('installScriptBase64'))]\"" </code></pre>  <p>But I wonder whether there are better solutions.</p>  <p>Essentially I need something which Cloud Service provides - ability to upload payload and config settings. </p>  <p><strong>SOLUTION</strong> </p>  <p>(note  this is for Windows VM. For Linux VM there is an easier way - thanks to @sendmarsh)</p>  <p>Please see below for actual implementation (note  I marked as answer a post from @4c74356b41 who suggested this idea).</p>""",azure-virtual-machine
56490215,Is there any Rest Api which can Create Deployment Center at Azure portal in Web App? <p>I am trying to create Resources group  WebApp plan service  Webapp through the Rest Api of microsoft azure  I have created above services from RestApi of microsoft Azure   but i am unable to find  How to create Deployment center.</p>  <p>not getting any thing.</p>,azure-web-app-service
54761959,"Deploy WAR to ROOT folder using MSDeploy ARM Template <p>I am using ARM Template to create a Azure App Service with Tomcat container and Deploy application as .war file. Here is my template.json with MSDeploy extension</p>  <pre><code>{      \apiVersion\"": \""2014-06-01\""       \""name\"": \""MSDeploy\""       \""type\"": \""Extensions\""       \""dependsOn\"": [       \""[concat('Microsoft.Web/Sites/'  parameters('appservice_name'))]\""         \""[concat('Microsoft.Web/Sites/'  parameters('appservice_name')  '/config/web')]\""      ]       \""properties\"": {        \""packageUri\"": \""&lt;StorageUrl&gt;/Application.war\""      }   } </code></pre>  <p>It was working fine and deploying my war file to wwwroot folder but I need to deploy into wwwroot/ROOT folder. </p>  <p>Is there any way to specify deployment path in MSDeploy ARM Template?</p>""",azure-web-app-service
50335655,Azure Web App getting time out of 4 minuets idle <p>I have hosted ASP.NET MVC application in Azure Web APP its getting time-out of 4 Minutes. The session is clearing for that instance.</p>  <p>Now I'm using Free Shared Infrastructure pricing tire  if I changing the plan to extend this idle timeout? or did I missed any configuration to setup session time-out.</p>,azure-web-app-service
50480462,Can Azure Backup server be installed on same server as workload? <p>Is it possible to install azure backup server on same server as workload or does it require separate server?</p>  <p>And does it support backup of SQL 2014 Express edition? </p>,azure-virtual-machine
47883799,"Azure Auto scaling Dependency on virtual scale set and its limitation <p>In Azure why there is not auto scaling for invidual virtual machine. Auto scaling is done through virtual scale set which supports hand full of operating system images. Is there is any limitation of VSS vs virtual machines. Is there is any way to do auto scaling for virtual machine other than using this  <a href=\https://blogs.msdn.microsoft.com/kaevans/2015/02/20/autoscaling-azurevirtual-machines/\"" rel=\""nofollow noreferrer\"">https://blogs.msdn.microsoft.com/kaevans/2015/02/20/autoscaling-azurevirtual-machines/</a></p>  <p>I think azure monitor can be configured for to autoscale a VM but I could not figure out how to do so? </p>""",azure-virtual-machine
55735005,"Azure HTTPtrigger function not writing to Azure Storage Queue <p>I am expecting the below code to take a JSON body from <code>func.HttpRequest</code>  write that message to an Azure Storage Queue and then return a success message to the caller. This works except that my Storage Queue is blank. </p>  <pre><code>import logging  import azure.functions as func   def main(req: func.HttpRequest           orders: func.Out[func.QueueMessage]) -&gt; func.HttpResponse:       logging.info('Python HTTP trigger function processed a request.')     message = req.get_json()     logging.info(message)     orders.set(message)     return func.HttpResponse(         body=”success”          status_code=200     ) </code></pre>  <p>Function.json</p>  <pre><code>{   \scriptFile\"": \""__init__.py\""    \""bindings\"": [     {       \""authLevel\"": \""anonymous\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""name\"": \""req\""        \""methods\"": [         \""get\""          \""post\""       ]     }      {       \""type\"": \""http\""        \""direction\"": \""out\""        \""name\"": \""$return\""     }    {     \""type\"": \""queue\""      \""direction\"": \""out\""      \""name\"": \""orders\""      \""queueName\"": \""preprocess\""      \""connection\"": \""orders_STORAGE\""   }   ] } </code></pre>  <p>Local.settings.json</p>  <pre><code>{   \""IsEncrypted\"": false    \""Values\"": {     \""FUNCTIONS_ER_RUNTIME\"": \""python\""      \""AzureWebJobsStorage\"": \""AzureWebJobsStorage\""      \""orders_STORAGE\"": \""DefaultEndpointsProtocol=https;AccountName=orders;AccountKey=*****;EndpointSuffix=core.windows.net\""   } } </code></pre>  <p>Terminal output: </p>  <p>…  [4/17/2019 5:54:39 PM] Executing 'Functions.QueueTrigger' (Reason='New queue message detected on 'preprocess'.'  Id=f27fd7d1-1ace-****-****-00fb021c9ca4)</p>  <p>[4/17/2019 5:54:39 PM] Trigger Details: MessageId: d28f96c5-****-****-9191-93f96a4423de  DequeueCount: 1  InsertionTime: 4/17/2019 5:54:35 PM +00:00</p>  <p>[4/17/2019 5:54:39 PM]  INFO: Received FunctionInvocationRequest  request ID: 5bf59a45-****-****-9705-173d9635ca94  function ID: fa626dc9-****-****-a59b-6a48f08d87e1  invocation ID: f27fd7d1-1ace-****-****-00fb021c9ca4</p>  <p>[4/17/2019 5:54:39 PM] Python queue trigger function processed a queue item: name2</p>  <p>[4/17/2019 5:54:39 PM]  INFO: Successfully processed FunctionInvocationRequest  request ID: 5bf59a45-****-****-9705-173d9635ca94  function ID: fa626dc9-3313-****-****6a48f08d87e1  invocation ID: f27fd7d1-1ace-****-****-00fb021c9ca4</p>  <p>[4/17/2019 5:54:39 PM] Executed 'Functions.QueueTrigger' (Succeeded  Id=f27fd7d1-1ace-****-****-00fb021c9ca4)</p>  <blockquote>   <p>INFO: Successfully processed</p> </blockquote>  <p>– makes me think this worked and I should see a message in my queue  but it is blank. </p>  <p>Why am I not seeing the message in the queue?</p>  <p>Thanks</p>""",azure-functions
21550850,"Azure CreateVM Deployment No target URI is specified for the image <p>I am trying to creating vm using the azure service management restapi. It is working fine if I choose my own images which i have created against my account. When I choose other images which are publicly available i am getting the following error.</p>  <pre><code>No target URI is specified for the image fb83b3509582419d99629ce476bcb5c8__SQL-Server-2014CTP2-CU1-12.0.1736.0-Evaluation-ENU-WS2012R2-CY13SU12. </code></pre>  <p>With the following the xml I have to create vm:</p>  <pre><code>&lt;Deployment xmlns=\http://schemas.microsoft.com/windowsazure\"" xmlns:i=\""http://www.w3.org/2001/XMLSchema-instance\""&gt;     &lt;Name&gt;azure4569033333&lt;/Name&gt;     &lt;DeploymentSlot&gt;Production&lt;/DeploymentSlot&gt;     &lt;Label&gt;YXp1cmU0NTY5MDMzMzMz&lt;/Label&gt;     &lt;RoleList&gt;         &lt;Role&gt;             &lt;RoleName&gt;azure4569033333&lt;/RoleName&gt;             &lt;RoleType&gt;PersistentVMRole&lt;/RoleType&gt;             &lt;ConfigurationSets&gt;                 &lt;ConfigurationSet i:type=\""WindowsProvisioningConfigurationSet\""&gt;                     &lt;ConfigurationSetType&gt;WindowsProvisioningConfiguration&lt;/ConfigurationSetType&gt;                     &lt;ComputerName&gt;azure4569033333&lt;/ComputerName&gt;                     &lt;AdminPassword&gt;Pass!admin123&lt;/AdminPassword&gt;                     &lt;AdminUsername&gt;admin12&lt;/AdminUsername&gt;                 &lt;/ConfigurationSet&gt;                 &lt;ConfigurationSet i:type=\""NetworkConfigurationSet\""&gt;                     &lt;ConfigurationSetType&gt;NetworkConfiguration&lt;/ConfigurationSetType&gt;                     &lt;InputEndpoints&gt;                         &lt;InputEndpoint&gt;                             &lt;LocalPort&gt;3389&lt;/LocalPort&gt;                             &lt;Name&gt;Remote Desktop&lt;/Name&gt;                             &lt;Port&gt;3389&lt;/Port&gt;                             &lt;Protocol&gt;tcp&lt;/Protocol&gt;                         &lt;/InputEndpoint&gt;                     &lt;/InputEndpoints&gt;                 &lt;/ConfigurationSet&gt;             &lt;/ConfigurationSets&gt;             &lt;OSVirtualHardDisk&gt;                 &lt;SourceImageName&gt;fb83b3509582419d99629ce476bcb5c8__SQL-Server-2014CTP2-CU1-12.0.1736.0-Evaluation-ENU-WS2012R2-CY13SU12&lt;/SourceImageName&gt;                 &lt;MediaLink&gt;https://portalvhdsd4lc8tzn260zd.blob.core.windows.net/vhds/fb83b3509582419d99629ce476bcb5c8__SQL-Server-2014CTP2-CU1-12.0.1736.0-Evaluation-ENU-WS2012R2-CY13SU12.vhd&lt;/MediaLink&gt;             &lt;/OSVirtualHardDisk&gt;             &lt;RoleSize&gt;ExtraSmall&lt;/RoleSize&gt;         &lt;/Role&gt;     &lt;/RoleList&gt; &lt;/Deployment&gt; </code></pre>""",azure-virtual-machine
55261361,"Actionresult not returning correct error code <p>I am implementing a custom business exception and returns the exception using <code>BadRequestObjectResult</code>.</p>  <h1>exception throw</h1>  <pre><code>throw new BusinessException(Int32.Parse(AppConstants.ErrorCodes.DeviceNotFound)  \Device not found.\""); </code></pre>  <h1>catch block</h1>  <pre><code>    catch (BusinessException ex)     {          return (ActionResult)new BadRequestObjectResult(ex);     } </code></pre>  <p>But it always returns an internal server error (code 500)</p>  <p>The value in the object at the catch block shows the correct error code which is passed from the throw part.</p>  <p><a href=\""https://i.stack.imgur.com/9dOnN.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/9dOnN.png\"" alt=\""Values of variable ex at catch block\""></a></p>""",azure-functions
57624103,"When user logs into website using ASP.NET Core Identity  he is logged-in in all browsers accessing the website <p>I have an ASP.NET Core 2.2 application running in a B1 instance in Azure App Services. If I log into the website  and open it on another machine  I am logged in on that machine too  including access to all pages protected by Authorization. When I log out on the second machine I'm not automatically logged back in until I clear the browser cache and restart the browser.</p>  <p>A similar issue was described here  but was never really answered: <a href=\https://stackoverflow.com/questions/37209605/asp-net-core-identity-shared-across-browser\"">ASP.NET Core identity shared across browser</a></p>  <p>This behavior seems to be somehow related to be running in an Azure App Service (Linux). I had the site running in a Docker image on a normal Linux VM (Ubuntu 18.04  official MS Docker image) before  and did not encounter this problem. </p>  <p>Here is all code from Startup.cs that could be relevant:</p>  <pre class=\""lang-cs prettyprint-override\""><code>public void ConfigureServices(IServiceCollection services)         { [...]  services.Configure&lt;CookiePolicyOptions&gt;(                 options =&gt;                 {                     // This lambda determines whether user consent for non-essential cookies is needed for a given request.                     options.CheckConsentNeeded = _ =&gt; false;                     options.MinimumSameSitePolicy = SameSiteMode.None;                 }); [...] services.AddIdentity&lt;User  IdentityRole&gt;()                 .AddErrorDescriber&lt;TopikonIdentityErrorDescriber&gt;()                 .AddEntityFrameworkStores&lt;TopikonContext&gt;()                 .AddDefaultTokenProviders();             services.AddAuthentication();             services.AddAuthorization(                 options =&gt;                 {                     options.AddPolicy(                         TopikonPolicies.ControlPanel                          policy =&gt; policy                             .RequireRole(TopikonRoles.ControlCenterAccess));                                     });  services        .AddMvc()                                 .AddRazorPagesOptions(                     options =&gt;                     {                         options.AllowAreas = true;                         options.Conventions.AuthorizeFolder(\""/\"");                                            }).SetCompatibilityVersion(CompatibilityVersion.Version_2_2);  [...] }  public static void Configure(IApplicationBuilder app  IHostingEnvironment env){ [...] app.UseCookiePolicy(); app.UseAuthentication(); app.UseSession(); app.UseMvc(); } </code></pre>  <p>App Service Authentication is switched on and set to \""Allow Anonymous\"". I tried switching it off  but the result was the same. I'd like users to be logged in only on the machine they are using  and not to provide their login to everyone visiting the site. Unfortunately I'm not quite sure where to look for answers.</p>""",azure-web-app-service
54770199,azure webapp node default start script <p>I want an npm script to run after deployment in my azure webapp.</p>  <p>I assumed that <code>npm run start</code> would automatically be executed. However this does not seem to be the case. I already tried to leave the start script emtpy and the server still works. I also tried to run some random node file in the start script and this does not get executed. So I assume that azure does not run  <code>npm run start</code> by default  but rather executes <code>node index.js</code></p>  <p>How can I run npm scripts instead?</p>,azure-web-app-service
36112904,"Edit Work Item Templates in Visual Studio Teamservices? <p>Is it possible to edit the Work Item Templates (former TFS Online) in Visual Studio Team Services?</p>  <p>I haven't found anything yet during my research. I tried the Powertools  unfortunately it says \access denied\"".</p>""",azure-devops
45428821,"setup azure machine with docker for play-framework application <p>I am new to Azure and trying to setup my dockerized play-framework 2.5.x application there following this post:</p>  <p><a href=\https://docs.microsoft.com/en-us/azure/virtual-machines/linux/docker-machine\"" rel=\""nofollow noreferrer\"">Azure Linux Docker Machine setup</a></p>  <p>However  it always failed on the first command:</p>  <pre><code>docker-machine create -d azure \\ --azure-subscription-id $sub \\ --azure-ssh-user azureuser \\ --azure-open-port 80 \\ myvm </code></pre>  <p>error:</p>  <pre><code>Provisioning with ubuntu(systemd)... Installing Docker... Copying certs to the local machine directory... Copying certs to the remote machine... Setting Docker configuration on the remote daemon... Error creating machine: Error running provisioning: ssh command error: command : sudo systemctl -f start docker err     : exit status 1 output  : Job for docker.service failed because the control process exited  with error code. See \""systemctl status docker.service\"" and \""journalctl -xe\""  for details. </code></pre>  <p>There are a lot of posts in Microsoft's website for azure setup  but everything is in pieces. I have followed through numerous of those and they just end up with new entries in my dashboard which just adds to my bill but I still can not have access to any of those to deploy my app. This is really frustating as I have spent days and almost runs out of my free $200 credits.</p>  <p>Any help  or any link to a WORKING setup is very highly appreciated</p>""",azure-virtual-machine
35447513,How can I run 5 azure micro-service instance in same time <p>I have azure micro-service call <strong>Service A</strong>. This micro service always looking queue call <strong>Queue A</strong>. Then I want to run 5 instance of Service A in same time. Is it possible?</p>  <p>if it is possible then what happens when I'm inserting 5 items to queue at same time ?</p>,azure-web-app-service
48514044,"Azure Function Authorization <p>I'm converting a WebApi to an Azure Function app. It authenticates using a SecurityToken in the header. With the api  I put in an attribute to call the authentication logic  but this doesn't work in Azure functions.</p>  <pre><code>[ApiAuthentication()]     [FunctionName(\GetConfig\"")]     public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Function  \""get\"")]HttpRequestMessage req  TraceWriter log)     { </code></pre>  <p>}</p>  <p>Is there a way to make this work  or is there a better way?</p>""",azure-functions
57450594,VS2019 - Durable function (v1.8.3) and non-durable Function in a single function app - is supported? <p>I have a VS 2019 solution  with two functions.  One Durable Function with an Orchestration Client triggered by a BLOB trigger and its related activities.  And another non-durable function triggered by a service bus event trigger.</p>  <p>The non-durable function triggered by a service bus event  creates a blob that triggers the durable function.</p>  <p>I setup a taskhub for the Durable Function.  Deployed both the functions onto Azure on cloud.  </p>  <p>For some reason  the functions work fine and get triggered the first time.  The orchestrator does its job.  The second time on  the orchestration client  gets triggered.  But the orchestrator function is not getting triggered.</p>  <p>Looking for the durable function related tables in the storage explorer  I do not see them - they don't seem to be getting created.  </p>  <p>Using 1.8.3 version of Durable Task extensions.</p>  <p>Was wondering if I can have both durable and non-durable functions within the same function app?  Was about to try moving them into separate function apps and VS 2017 solutions.</p>  <p>Anyone aware of any such limitations of Durable functions co-existing with non-durable functions within the same function app?</p>  <p>Regards -Athadu</p>,azure-functions
44305888,"Ajax call 500 server error for Django - Azure <p>I have an azure deployed django web app in which it shows instagram embedded pages one by one when I click next.</p>  <p><strong>Issue:-</strong></p>  <p>When I switch on the Azure Active Directory authentication ON  it loads the first instagram embedded link but on click on next button which should load the next embedded page  it shows a http 500 error message on console and doesn't load the page.</p>  <p>And if I switch off AD authentication and set to anonymous access  the pages load without any issue on the next click.</p>  <p>What is the issue and how can be able to load them with my authentication settings on?</p>  <p><strong>EDIT</strong></p>  <p>I had come to a conclusion before that instagram pages were the problem behind the pages not able to load but it seems that's not the issue. </p>  <p>The problem is with the URL I am calling while clicking the next button. With authentication  the app doesn't direct to next page but without any authentication  it successfully goes to next page.</p>  <p>Refer the code below where I am making the call:-</p>  <pre><code>$(\#button-next\"").click(function(e){     var fin = '';     $.ajax({         url: 'mywebsitename.azurewebsites.net/next_details/'          method: 'GET'          data: {'link': window.location.href}          success: function(response) {             if (response.data != 'no links') {               $.each(response['data']  function(index  value){                 fin += \""//pass\""              });              $('append-iframes').html(fin);              window.location.href = '*' + response.name + '/?type=' + response.check_type;             }         }         })         }) </code></pre>  <p><strong>EDIT - 2</strong></p>  <p>//Next_details function</p>  <pre><code>@csrf_exempt https://myappname.azurewebsites.net def next_details(request):     import pdb; pdb.set_trace()     check_type = ''.join(findall('type=(.*)'  request.POST.get('link'  '')))     data_list = []     if check_type:         present_link = request.POST.get('link'  '').split('/')[-2]         if check_type == 'all':             data = urlopen('https://myappname.azurewebsites.net/get_detailed/').read()         else:             data = urlopen('https://myappname.azurewebsites.net/get_detailed_%s/' % check_type).read()     else:         check_type= 'all'         present_link = request.POST.get('link'  '').split('/')[-1]         data = urlopen('https://myappname.azurewebsites.net/get_detailed/').read()     data_json = json.loads(data)     qual_data = [dt['id'] for dt in data_json['qual_data'] if dt['name'] == present_link]     if qual_data:         present_id = qual_data[0]         next_acc = [dt['name'] for dt in data_json['qual_data'] if dt['id'] == present_id + 1]         acc_name = next_acc[0]         links = Radarly.objects.filter(screen_name=acc_name  status='Active')         if links:             for link in links:                 data_list.append({'perma_link': link.permalink  'name': acc_name})             data = json.dumps({'data': data_list  'check_type': check_type})             return HttpResponse(data  content_type =\""application/json\"")         else:             new_data = json.dumps({'data': 'no links'})             return HttpResponse(new_data  content_type =\""application/json\"") </code></pre>  <p>Also below is a screenshot of the error which shows on the DOM. <a href=\""https://i.stack.imgur.com/1LQcq.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/1LQcq.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
34797792,"InvalidApiVersionParameter-When I am trying to create VM on Azure <p>When I am trying to create VM on Azure by Azure Java SDK  I got the error message shown below.</p>  <p><a href=\http://i.stack.imgur.com/5z6Gk.png\"" rel=\""nofollow\""> InvalidApiVersionParameter: The api-version '2015-06-15' is invalid. The supported versions are '2015-11-01 2015-01-01 2014-04-01-preview 2014-04-01 2014-01-01 2013-03-01 2014-02-26 2014-04'.</a></p>  <p>It seems my api-version is incorrect. However  I didn't set this api-version in the code. How to fix this error? Thanks.</p>""",azure-virtual-machine
54442936,Why do we get HttpAntiForgeryException after publishing update to Azure Web app service? <p>We published an application update to the same Azure web app service and started getting errors:</p>  <blockquote>   <p>Exception: System.Web.Mvc.HttpAntiForgeryException (0x80004005): The anti-forgery token could not be decrypted. If this application is hosted by a Web Farm or cluster  ensure that all machines are running the same version of ASP.NET Web Pages and that the  configuration specifies explicit encryption and validation keys. AutoGenerate cannot be used in a cluster.</p> </blockquote>  <p>This happens to clients using a login page within the app. These are the response headers:</p>  <pre><code>HTTP/1.1 200 OK Cache-Control: private Content-Length: 5585 Content-Type: text/html; charset=utf-8 Vary: Accept-Encoding Server: Microsoft-IIS/10.0 X-AspNetMvc-Version: 5.2 X-Frame-Options: SAMEORIGIN X-AspNet-Version: 4.0.30319 X-Powered-By: ASP.NET Date: Wed  30 Jan 2019 14:23:33 GMT </code></pre>  <p>The client has to either close the browser and reopen or clear the browser's cookies to fix the problem.</p>  <p>The web app was running 3 app service instances before and after the upgrade. ARR Affinity is on.</p>  <p>Why is this happening and how do I fix it?</p>,azure-web-app-service
41665397,"Cannot access my scm url <p>I'm working through the App Service <a href=\https://docs.microsoft.com/en-gb/azure/app-service-web/app-service-web-get-started\"" rel=\""nofollow noreferrer\"">getting started tutorial</a> with Azure CLI 2.0 Preview but at the stage we do a ``git push``` the host is unresolved. Indeed when I ping it I get no response  even if I add port 443 - which I'm not sure windows ping accepts.</p>  <p>When I log into the portal I see everything appears to be set up. At least the git clone URL is identical to what I have added as a git remote. Namely</p>  <p><a href=\""https://my@email.com.com@my-cli-app.scm.azurewebsites.net:443/my-cli-app.git\"" rel=\""nofollow noreferrer\"">https://my@email.com.com@my-cli-app.scm.azurewebsites.net:443/my-cli-app.git</a></p>  <p>I use the UK West centre which is the closest to me. Anyway  I can't imagine there are DNS propagation delays to worry about</p>  <p>Have I missed something obvious?</p>  <p>thanks</p>  <p>PS one thing that I don't believe can be related is I have a number of subscriptions but as they are not specified in the given commands it picked a random one it Happens to be a MSDN subscription which has expired but works with Azure.</p>""",azure-web-app-service
47033544,"Azure KeyVault with Key Rotation <p>Our application doesn't use keyvault until now. We are thinking of using <code>Azure KeyVault</code> to enforce security for keys  secrets and certificates. I read microsoft documentation on this <a href=\https://docs.microsoft.com/en-us/azure/key-vault/key-vault-ovw-storage-keys\"" rel=\""nofollow noreferrer\"">Link</a>. It's not clear that  <code>Azure KeyVault</code> works with identity providers other than <code>Azure AD</code>. Because we are not using Azure AD but we are using Azure app service and storage account. we also want to implement <code>key rotation</code> with 1 hour expiry.  </p>  <p>My questions are</p>  <ol> <li><p>Should the web app be registered with Azure AD to use KeyVault ?</p></li> <li><p>While creating an <code>azure keyvault</code> i didn't see any option about key rotation. Am i looking in the wrong place?</p></li> <li><p>Any sample code would be helpful.</p></li> </ol>""",azure-storage
23771981,TFS Renaming and deleting files is slow within Visual Studio 2013 <p>When  within Visual Studio 2013  I rename a file that is bound to TFS  Visual Studio pauses for around six seconds.  When I'm refactoring for example  this wait is really annoying because it interrupts my flow.  </p>  <p>I suspect that when I rename a file it is contacting TFS and doing the rename on the server which is the reason for the pause and my wait (edit - I don't think this is the case because it takes exactly 6 seconds when I don't have internet connectivity).  If this is the reason  is there anyway to tell VS not to contact TFS until I check in?  If it is not the reason for the slowing down of VS while I rename does anyone have any solutions to quicken up this process?</p>  <p><strong>Edit - further information</strong> Visual Studio 2013 with update 2 and the free online version of TFS.  The pause occurs with or without internet access.  My machine is fairly fast (i5-2520M processor) with a SSD but it is 32 bit with 3gb of ram. I don't have many problems with memory though due to the SSD. In terms of add-ins I haven't installed any other than the default (I only recently upgraded to VS 2013)</p>,azure-devops
35776501,"VSTS - Backlog Priority altered by sorting in columns <p>I am attached to a project using VSTS  with the Scrum process selected. As the Product Owner sorts the backlog  things work fine with respect to the Backlog Priority value under the hood.</p>  <p>As tasks move along the Board  from column to column  I have noticed that the ordering of cards within a column will impact the Backlog Priority. This seems contrary to good sense.</p>  <p>Is there a justification why a developer's move of a card within a column such as \In QA\"" would result in that item being ranked above the other cards in the backlog?</p>  <p>I think it would be better if the sorting/ranking only worked on the Backlog itself. Once an item is underway in the columns  moving it up and down  as developers tend to do  should not disrupt its position in the backlog.</p>""",azure-devops
38055705,"How to include Gulp generated dist folder in ProjectName.zip package created by the Visual Studio Build step <p>I have a build definition with the following build steps in the following order:</p>  <ol> <li>NuGet Installer</li> <li>Npm</li> <li>Gulp</li> <li>Visual Studio Build</li> <li>Azure Web App Deployment</li> </ol>  <p>In step 3  Gulp generates a <code>dist</code> folder in my application root. The <code>dist</code> folder contains some subfolders and files. The subfolders themselves can contain other subfolders and files.</p>  <p>In step 4  the <em>Visual Studio Build</em> step creates a <code>&lt;ProjectName&gt;.zip</code> zip file when completed. </p>  <p>The <em>Azure Web App Deployment</em> step then deploys that zip file to my Azure Web App.</p>  <p>How do I include the <code>dist</code> folder in <code>&lt;ProjectName&gt;.zip</code>?</p>  <p>I tried doing two <em>Azure Web App Deployments</em> deploying one zip file at a time in the same build definition but the second <em>Azure Web App Deployment</em> build step wipes whatever was deployed by the first one. Is there a way to tell the second <em>Azure Web App Deployment</em> step to \append\"" to whatever was deployed by the first <em>Azure Web App Deployment</em> step?</p>""",azure-devops
57675488,Deploying an Azure Function from VS Code - Succesfull but not visible in the Portal <p>I created a function and I am trying to deploy it from VS Code by clicking the <code>Deploy to Function App...</code>. The Deployment runs successfully based on the output log - <code>Deployment successful</code> but then when I go to the portal  the function is not listed under Functions. </p>  <p>What shall I do and what is the problem here?</p>  <p>When I debug in VS Code  I get this: <code>No job functions found. Try making your job classes and methods public. If you're using binding extensions (e.g. Azure Storage  ServiceBus  Timers  etc.) make sure you've called the registration method for the extension(s) in your startup code (e.g. builder.AddAzureStorage()  builder.AddServiceBus()  builder.AddTimers()  etc.).</code></p>,azure-functions
38571852,Synology NAS Backup to Azure Blob Storage - used space and billing <p>I am using Azure Blob Storage to backup Synology NAS. </p>  <p>My used space on NAS is 810 GB but my used space in Azure Blob Storage is 2642GB. I am using STANDARD IO - BLOCK BLOB (GB) - LOCALLY REDUNDANT.</p>  <p>Does someone know why there is such a big difference in stored data?</p>  <p>Thanks  A</p>,azure-storage
53480232,"How to configure AllowedQueryOptions on an Azure Mobile App? <p>I am attempting to get the total item count from an Azure Mobile App. The mobile app is a .Net implementation that is using Table Storage. It is based on the Mobile App QuickStart code and it's only got the minimum of changes needed to make it work with Table Storage. All NuGet packages have been updated to the latest versions.</p>  <p>Here's the client code (Xamarin-Android):</p>  <pre><code>    client = new MobileServiceClient(applicationURL  new LoggingHandler(true));     todoTable = client.GetTable&lt;ToDoItem&gt;();     List&lt;ToDoItem&gt; list = await todoTable.Take(0).IncludeTotalCount().ToListAsync(); </code></pre>  <p>This gives me the response</p>  <blockquote>   <p>The query specified in the URI is not valid: 'Query option 'InlineCount' is not allowed. To allow it  set the 'AllowedQueryOptions' property on EnableQueryAttribute or QueryValidationSettings.'.</p> </blockquote>  <p><strong>What I've tried</strong></p>  <pre><code>    [EnableQuery(AllowedQueryOptions= AllowedQueryOptions.All]     public Task&lt;IEnumerable&lt;TodoItem&gt;&gt; GetAllTodoItems(ODataQueryOptions options)     {             return DomainManager.QueryAsync(options);     } </code></pre>  <p>This still gives me the same error back. I have tried different combinations of AllowedQueryOptions as well such as [EnableQuery(AllowedQueryOptions= AllowedQueryOptions.Filter | AllowedQueryOptions.Top | AllowedQueryOptions.Select | AllowedQueryOptions.InlineCount)] but the result is always the same.</p>  <p>Then I tried to add the option in ConfigureMobileApp()</p>  <pre><code>    config.Filters.Add(new EnableQueryAttribute()     {         AllowedQueryOptions = AllowedQueryOptions.All     }); </code></pre>  <p>The code compiles and publish appears to succeed but the web site that is shown after publishing the code displayed</p>  <pre><code>    &lt;?xml version=\1.0\"" encoding=\""ISO-8859-1\""?&gt;     &lt;Error&gt;             &lt;Message&gt;An error has occurred.&lt;/Message&gt;     &lt;/Error&gt;         </code></pre>  <p>The client is still returning the same error message. I've also tried to combine this with [EnableQuery] but still no luck.</p>  <p>The DomainManager is initialized using the code</p>  <pre><code>    DomainManager = new StorageDomainManager&lt;TodoItem&gt;(connectionStringName  tableName  Request); </code></pre>  <p>I tried to modify this to use the constructor that takes ValidationSettings and ODataQuerySettings objects.</p>  <pre><code>    DomainManager = new StorageDomainManager&lt;TodoItem&gt;(connectionStringName  tableName  Request  GetValidationSettings()  GetQuerySettings()); </code></pre>  <p>My implementation of GetValidationSettings is identical to GetDefaultValidationSettings on <a href=\""https://github.com/Azure/azure-mobile-apps-net-server/blob/master/src/Microsoft.Azure.Mobile.Server.Storage/StorageDomainManager.cs\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-mobile-apps-net-server/blob/master/src/Microsoft.Azure.Mobile.Server.Storage/StorageDomainManager.cs</a></p>  <p>except I added inlinecount to the AllowedQueryOptions</p>  <pre><code>    AllowedQueryOptions = AllowedQueryOptions.Filter                 | AllowedQueryOptions.Top                 | AllowedQueryOptions.Select                 | AllowedQueryOptions.InlineCount  </code></pre>  <p>I didn't get the same error back anymore  as this made QueryAsync fail with internal server error instead.</p>  <p>Anyone know how to configure AllowedQueryOptions so that I can use IncludeTotalCount() from the client?</p>""",azure-storage
8889823,What is the best way to monitor a container in Azure blob storage for changes? <p>I am looking for the best way to monitor a container/folder in Azure blob storage for changes. So far I have only found one way to do this  which is to run a worker process somewhere that pings the container's contents on a regular basis to look for changes.</p>  <p>Is there a better way?</p>,azure-storage
12250634,installing oracle in windows azure under VM <p>I am thinking of using windows azure for my next project. I am forced to use oracle as the db back end. I would like to know whether there is any possibility of installing oracle on a windows azure virtual machine? </p>,azure-virtual-machine
54446426,"Azure website deployment to machine that already has a \Default web site\"" <p>Am am trying to deploy a website via Azure Devops to an IIS server that has the reconfigured \""Default Web Site\"" started with a binding on port 80.</p>  <p>I want my website to run on port 80.</p>  <p>I am using the \""IIS Web App Manage\"" task. When I run my deployment on this machine  I get an error:</p>  <blockquote>   <h2>[error]Binding (http / * : 80 : ) already exists for a different website (\""site \""default web site\"" (id:1 bindings:http/*:80: state:stopped)\"")  change the port and retry the operation.</h2> </blockquote>  <p>I have stopped the default web site but I still get the same error because the binding already exists.</p>  <p>I have tried using the IIS Web App Manage task to remove the binding on the Default web site but there does not appear to be a way to do this.  I do not see another task that will perform this task.</p>  <p>I am trying to automate this for future deployment via Azure Devops so I do not have to change the bindings or remove the default website by hand.</p>""",azure-devops
56390151,"how to call from an azure web app a process running as a continuous azure webjob <p>I want to run the OPA (<a href=\https://www.openpolicyagent.org/\"" rel=\""nofollow noreferrer\"">https://www.openpolicyagent.org/</a>) agent as a background process besides my webapp with my webapp calling the OPA agent through <a href=\""http://localhost:8181\"" rel=\""nofollow noreferrer\"">http://localhost:8181</a>.</p>  <p>I can start the OPA agent (with opa.exe run -s) which exposes an API on localhost:8181 through a continuous webjob in the azure web app. However  my web app cannot connect to the OPA agent.</p>  <p>Is it possible for a web app process to do RPC (REST API) with a webjob process ?</p>""",azure-web-app-service
53100139,Point root domain to Azure Function <p>In our project requirements we need to deal with a number of redirects where requests come in the form of <code>example.com/some-uri</code> and based on this <code>some-uri</code> get redirected to various places.</p>  <p>As all of our existing apps are already hosted in Azure (hundreds of services  databases  applications  etc  etc.)  Azure Functions seem a very reasonable choice.  The workload is extremely simple: match the incoming uri against a table and issue a 301 redirect to the corresponding target.</p>  <p>Unfortunately  with Azure Function there is no public IP address and I cannot use CNAME on the root domain (that is  I cannot use DNS syntax <code>@   CNAME   somefunction.something.azure.net</code>)</p>  <p>I don't want to have to pay for an app service to just deal with these redirects.  The number of requests I expect is well within the free allocation of function invocations  therefore I would be getting this essentially for free.</p>  <p>How can I point the root of my example.com domain to the function?  </p>,azure-functions
55848047,"Authentication with Azure Active Directory on App Service for multi-container app (docker-compose) <p>I am trying to enable in-build authentication for app service with Azure Active Directory.</p>  <p>It is working fine when I use single container configuration  but when I try to configure docker-compose then the redirection to microsoft login page is not in place. </p>  <p>I am using nginx (reverse-proxy image) for serving the static websites (two images) and one api image (server image).</p>  <p>App service in-build authentication is enabled and Active Directory is configured and action to take when request is not authenticated is set to Log in with Azure Active Directory. <a href=\https://i.stack.imgur.com/7WmKG.png\"" rel=\""nofollow noreferrer\"">screenshot of auth setup</a></p>  <p>docker-compose.yml</p>  <pre><code>version: '3'  services:   api:     image: plugotestcontainerregistry.azurecr.io/server:latest     environment:       PORT: 4000     expose:       - \""4000\""     restart: always   reverse-proxy:     image: plugotestcontainerregistry.azurecr.io/reverse-proxy:latest     ports:        - \""8080:8080\""     restart: always </code></pre>  <p>nginx config</p>  <pre><code>server {   listen 80;   root   /usr/share/nginx/root;   location / {     index  index.html index.htm;     try_files $uri $uri/ /index.html;   }   location /api {     proxy_pass  \""http://api:4000\"";     proxy_set_header  Host $http_host;     proxy_set_header  X-Forwarded-For $remote_addr;   }   location /admin {     alias   /usr/share/nginx/admin/;     index  index.html index.htm;     try_files $uri $uri/ /admin/index.html;   }   error_page   500 502 503 504  /50x.html;   location = /50x.html {     root   /usr/share/nginx/html;   } } </code></pre>  <p>Working authentication using AAD and docker compose in Web App for containers.</p>""",azure-web-app-service
35853840,AzureWebApp: Monitor Application Logs <p>I'm building an Azure web-app and if there are certain unexpected errors  I want to be able to bubble it up in the Azure Dashboard / add alerts.</p>  <p>Any <code>System.Diagnostics.Trace.TraceError()</code> messages are logged to the <code>ApplicationLog</code>. Is there a  way to add alert/monitoring-graphs for these in Azure Portal?</p>,azure-web-app-service
38370304,"NetStandard Library not getting dependencies on VSTS Build Agent <p>I currently have a Xamarin.Android project that references a .NET Standard 1.1 library that references AutoMapper 5.0.2.</p>  <p>When I try to build this through VSTS I get this error</p>  <blockquote>   <p>C:\\Program Files   (x86)\\MSBuild\\Xamarin\\Android\\Xamarin.Android.Common.targets(1316 2):   Error : Exception while loading assemblies:   System.IO.FileNotFoundException: Could not load assembly   'System.Collections.Specialized  Version=4.0.1.0  Culture=neutral    PublicKeyToken=b03f5f7f11d50a3a'. Perhaps it doesn't exist in the Mono   for Android profile?</p> </blockquote>  <p>This solution builds perfectly fine on my local machine and runs in the Android Emulator.</p>  <p>Things I have tried (and none have worked)</p>  <ol> <li>Installing the AutoMapper Nuget package directly against the Android Project. </li> <li>Installing <a href=\https://www.nuget.org/packages/System.Collections.Specialized/\"" rel=\""nofollow\"">System.Collections.Specialized</a> in the Android project. </li> <li>Doing <code>&lt;CopyNuGetImplementations&gt;true&lt;/CopyNuGetImplementations&gt;</code> in the Android Project.</li> </ol>  <p>Also just as a side note  I have .NET Standard 1.1 Libraries all the way through my project  yet I can see from the build log that its using .NET Standard 1.3. Not sure if this will make a difference as I am not sure how the build process manages these standards.</p>  <blockquote>   <p>Copying file from   \""C:\\Users\\buildguest.nuget\\packages\\AutoMapper\\5.0.2\\lib\\netstandard1.3\\AutoMapper.dll\""   to \""C:\\a\\1\\b/Release\\AutoMapper.dll\"".</p> </blockquote>  <p><strong>Update 1</strong></p>  <p>Just to add that I have tried using Nuget 3.4.4 and Nuget 3.5.0-beta2 in the build agent and while this solved other issues I was having  it didn't resolve the current one I am experiencing.</p>  <p><strong>Update 2</strong></p>  <p>Here is my Android project.json</p>  <pre><code>{   \""dependencies\"": {     \""Newtonsoft.Json\"": \""9.0.1\""   }    \""frameworks\"": {     \""MonoAndroid Version=v6.0\"": {}   }    \""runtimes\"": {     \""win\"": {}   } } </code></pre>  <p>Here is my Portable project.json</p>  <pre><code>{   \""supports\"": {}    \""dependencies\"": {     \""AutoMapper\"": \""5.0.2\""      \""NETStandard.Library\"": \""1.6.0\""      \""Xamarin.Forms\"": \""2.3.0.107\""   }    \""frameworks\"": {     \""netstandard1.1\"": {       \""imports\"": \""portable-win+net45+wp8+win81+wpa8\""     }   } } </code></pre>  <p><strong>Update 3: 18th July</strong> Just adding more test cases</p>  <ol> <li>Did a brand new Xamarin Android project  with packages.config  existing nuget.exe. All works.</li> <li>Add AutoMapper reference  builds and runs locally. Fails in VSTS Build Agent</li> <li>Updated Nuget.exe - still fails on build</li> <li>Update to project.json - still fails on build.</li> </ol>  <p>I can not get even a blank project with an AutoMapper 5.0.2 reference working in the Visual Studio Build step of VSTS. Always the same error as above.</p>""",azure-devops
51071947,Azure VM with VPN <p>This is more one for curiosity and learning.</p>  <p>I currently have an Azure VM (Windows 2016 and SQL 2017) which I just used for R&amp;D. The RDP port is enabled - no big deal as there is nothing top secret there. </p>  <p>But just to learn more about Azure I wanted to create a VPN so I can connect via that.  Googling  has left me a tad confused as how to go about this gateways  gateway subnet etc etc. I'm not sure if the articles I am reading are the right ones as whatever I try doesn't appear to work.</p>  <p>Does anyone know of any links that might help me start from scratch with VPN settings to connect?</p>  <p>Thanks in advance  Ray</p>,azure-virtual-machine
5483301,Reduce File Size Upload for Azure <p>I Have a hosted service on Azure  every time I want to put the package (cspkg &amp; cscfg files) it always take so long. My cspkg file is 18 MB. Is there any better way to do the upload? my thought is to put the images  style  etc in Storage on Azure and pointing my web app image references (src) to the storage account  so I don't have to include those files in cspkg  or something like that. It is just too much if I only have to modify a single line of code and but have to wait almost 30 min for the upload to be completed.</p>  <p>thx</p>,azure-storage
42003440,The IP address of my Azure Windows VM changed without waning <p>A few days ago  the IP address of our VB Windows Server changed from 40.x.x.x to 13.x.x.x on the Azure platform. We have many loggers in the field that connect to this IP address and now  none of them can connect.</p>  <p>Can the IP change without any warning from Azure?</p>  <p>Also  there is no support to be found. No number  no online support... I mean  This is not a problem I should be paying support for... besides.. support is more expensive than the VM.</p>,azure-virtual-machine
47410951,"Cannot deploy REST API with Python on Azure <p>I'm trying to deploy simple Azure web application. I create it exactly as described here</p>  <p><a href=\https://docs.microsoft.com/en-us/azure/app-service/app-service-web-get-started-python\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/app-service/app-service-web-get-started-python</a></p>  <p>but replaced code in <strong>main.py</strong> with following (and update <strong>requirements.txt</strong> of course):</p>  <pre><code>from flask import Flask  request from flask_restful import Resource  Api   app = Flask(__name__) api = Api(app) todos = {}   class HelloWorld(Resource):     def get(self):         return {'hello': 'world'}   class TodoSimple(Resource):     def get(self  todo_id):         return {todo_id: todos[todo_id]}      def put(self  todo_id):         todos[todo_id] = request.form['data']         return {todo_id: todos[todo_id]}   api.add_resource(HelloWorld  '/') api.add_resource(TodoSimple  '/&lt;string:todo_id&gt;')   if __name__ == '__main__':     app.run(debug=True) </code></pre>  <p>Everything works fine locally  but there are issues with deployed version:</p>  <p>-- <a href=\""http://my-app-name-here.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://my-app-name-here.azurewebsites.net</a> is just fine and prints {'hello': 'world'} as expected</p>  <p>-- other commands provided by TodoSimple are not accessible.</p>  <p>For example following query</p>  <pre><code>curl http://my-app-name-here.azurewebsites.net/todo -d \""data=Remember the milk\"" -X PUT </code></pre>  <p>would result with \""The resource you are looking for has been removed  had its name changed  or is temporarily unavailable.\"" response.</p>  <p><strong>Update:</strong> it's all fine when ran locally</p>  <pre><code>$curl http://localhost:5000/todo -d \""data=Remember the milk\"" -X PUT {     \""todo\"": \""Remember the milk\"" } </code></pre>  <p>Does anyone know what I'm missing with this app deployment?</p>  <p><strong>Update2:</strong> approach without flask_restful won't work either:</p>  <pre><code>from flask import Flask app = Flask(__name__)   @app.route('/') def hello_world():     return 'Hello  World!'   @app.route('/data') def get_data():     return 'The data.'   if __name__ == '__main__':   app.run() </code></pre>  <p>Calling <a href=\""http://my-app-name-here.azurewebsites.net/data\"" rel=\""nofollow noreferrer\"">http://my-app-name-here.azurewebsites.net/data</a> results in \""The resource you are looking for has been removed  had its name changed  or is temporarily unavailable.\"" message again.</p>""",azure-web-app-service
11119614,Execute Methode in windows azure with multiple instances <p>I want to execute a job scheduler methods in my windows azure application. So in my application i am using 2 instance of the same application. So If i create a scheduler means both the instance can execute same code. Is it possible to avoid such execution? Or is it possible check other instace before executing the code? For the implementation i am using c#.Net.</p>,azure-storage
26739170,Azure: Cannot Configure a VM Size beyond A0-A4 <p>I am attempting to increase the size of a Virtual Machine on my Azure subscription from an A2 (2 cores  3.5GB) machine to a D3 (4 cores  14GB) machine.  The only options available for this particular VM on the configure tab > Virtual machine size are: - A0 - A1 - A2 - A3 - A4</p>  <p>I do not see an A5 or a D3 virtual machine size available - although these are available for other virtual machines within my subscription. We have had this and a couple of other VMs with the same issue running for about a year and a half - the newer VMs in our subscription (as well as machines in the create gallery) can all be scaled into the memory and CPU intensive versions (A5 or D3  D4).</p>  <p>Is there any pathway that will allow me to upgrade this older VM to a newer specification of Virtual Machine?  </p>,azure-virtual-machine
38469845,How do I authenticate Azure Powershell on Azure VM <p>I'm wanting to execute a Powershell script from an Azure VM to get its current public IP address (and to write this address to an evironment variable for an application to use).</p>  <p>My question is what the best way to authenticate the Azure Powershell environment is? On AWS credentials get 'baked' into an instance when it gets created. Does the equivalent happen with Azure Virtual Machines? </p>,azure-virtual-machine
50567301,"Custom Redirect page is not working <p>I have the Custom Error  <code>&lt;customErrors mode=\Off\"" defaultRedirect=\""Error.aspx\""/&gt;</code>.</p>  <p>Its totally not working  tried <code>&lt;deployment retail=\""false\""/&gt;</code> No result.</p>  <p><strong>Application in Azure App service  so No role of IIS here. Please help</strong> </p>""",azure-web-app-service
38138379,How to migrate Github Private server to another server in Azure Migration <p>We have <strong>Private</strong> Github server in Ubuntu running in Azure subscription and requirement is to migrate Github to another private github server. Decided to migrate Azure from one Subscription to another subscription taking the image.</p>  <p>So What are the steps/process has to be done pre and post activities for Private Github server migration from Azure to Azure subscription?</p>,azure-virtual-machine
57621967,"How do I move Work Items from one organization to another <p>We have a number of Work Items in a project. Now  there is another organization in our devops and we wish to move all our existing Work Items from the old organization (project) to the new one. How can this be done?</p>  <p>I've seen people <a href=\https://developercommunity.visualstudio.com/content/problem/355412/moving-work-items-from-one-organization-to-another.html\"" rel=\""nofollow noreferrer\"">discussing this before</a>  and some comments saying \""we use excel\"". But no information about how to actually do this.</p>""",azure-devops
50275661,"VSTS Dashboard Widget getWorkItem optional parameter expand <p>I am writing a VSTS dashboard widget used for <a href=\https://docs.microsoft.com/nl-nl/vsts/extend/reference/client/api/tfs/workitemtracking/restclient/workitemtrackinghttpclient2_2?view=vsts#getworkitem()\"" rel=\""nofollow noreferrer\"">Work Item Tracking</a></p>  <p>However I am running into a problem when using the getWorkItem() function. I want to get the <strong>ids</strong> of all the <strong>Features</strong> under a given <strong>Epic</strong> (I already know the epic ID). I am confident that if I set the <strong>expand</strong> paremeter of getWorkItem() to \""All\"" I will get a list of all the Features and their respective ids. Unfortunately I do not know how to define the \""type\"" of expand parameter and how to properly pass it as a value to the getWorkItem() function.</p>  <p>Here is my code:</p>  <pre><code>VSS.require([\""VSS/Service\""  \""TFS/Dashboards/WidgetHelpers\""  \""TFS/WorkItemTracking/RestClient\""]          function (VSS_Service  WidgetHelpers  TFS_Wit_WebApi) {             WidgetHelpers.IncludeWidgetStyles();             VSS.register(\""myapp\""  function () {                 var fetchData = function (widgetSettings) {                     const epicID = 123456;                     // Get a WIT client to make REST calls to VSTS                     return VSS_Service.getCollectionClient(TFS_Wit_WebApi.WorkItemTrackingHttpClient).getWorkItem(123456  null  null  All).                         then(                             //Successful retrieval of workItems                             function (workItems) {                                 $('#myText').text(JSON.stringify(workItems));                                 console.log(workItems);                                 // Use the widget helper and return success as Widget Status                                 return WidgetHelpers.WidgetStatusHelper.Success();                             }                              function (error) {                                 // Use the widget helper and return failure as Widget Status                                 return WidgetHelpers.WidgetStatusHelper.Failure(error.message);                             });                 } </code></pre>  <p>Here is the VSTS reference for <a href=\""https://docs.microsoft.com/nl-nl/vsts/extend/reference/client/api/tfs/workitemtracking/contracts/workitemexpand?view=vsts\"" rel=\""nofollow noreferrer\"">expand</a> It explains what the values can be  but doesn't say how to pass it into the getWorkItem() function.</p>  <blockquote>   <p>I would like to set the optional expand parameter of the function to \""All\"" but don't know its type and how to properly define and use it.</p> </blockquote>""",azure-devops
22937220,"How to start Windows Azure Storage Emulator V3.0 from code <p>Since I installed the new Windows Azure SDK 2.3 I got a warning from csrun:</p>  <p>\DevStore interaction through CSRun has been depricated. Use WAStorageEmulator.exe instead.\""</p>  <p>So there are two questions: 1) How to start the new storage emulator correctly from code? 2) How to determine from code if the storage emulator is already running?</p>""",azure-storage
49195041,"how to analyze memory leaks for \azure web apps\"" (PaaS) <p>I am looking to analyze memory leaks for the web app deployed in azure.</p>  <p>Referring to following urls</p>  <ul> <li><a href=\""https://blogs.msdn.microsoft.com/kaushal/2017/05/04/azure-app-service-manually-collect-memory-dumps/\"" rel=\""nofollow noreferrer\"">https://blogs.msdn.microsoft.com/kaushal/2017/05/04/azure-app-service-manually-collect-memory-dumps/</a></li> <li><a href=\""https://blogs.msdn.microsoft.com/kaushal/2017/05/04/azure-app-service-manually-collect-memory-dumps/\"" rel=\""nofollow noreferrer\"">https://blogs.msdn.microsoft.com/kaushal/2017/05/04/azure-app-service-manually-collect-memory-dumps/</a></li> </ul>  <p>we were able to extract memory dump and analyze them. but since we were not able to inject the LeakTrack dll / enable memory leaks tracking when collecting the dump  we are getting message that leak analysis was not performed due to not injecting the dll on performing memory analysis.</p>  <p>please suggest how to find out memory leakages from analyzing the dump in this scenario.</p>""",azure-web-app-service
53391754,"Publish build artifact from folder without including root folder <p>On Azure DevOps  I have some files I want to publish:</p>  <ul> <li><code>$(Build.ArtifactStagingDirectory)/dist/app/index.html</code></li> <li><code>$(Build.ArtifactStagingDirectory)/dist/app/bundle.js</code></li> </ul>  <p>I want to publish them into an artifact <code>app.zip</code> which contains  at the root level:  - <code>index.html</code>  - <code>bundle.js</code></p>  <p>However when I use the \Publish Build Artifacts\"" tasks with the path set to <code>$(Build.ArtifactStagingDirectory)/dist/app</code>  I get the following contents in <code>app.zip</code>:</p>  <ul> <li><code>app/</code>  <ul> <li><code>index.html</code></li> <li><code>bundle.js</code></li> </ul></li> </ul>  <p>I tried setting the publish path to:</p>  <ul> <li><code>$(Build.ArtifactStagingDirectory)/dist/app/**</code></li> <li><code>$(Build.ArtifactStagingDirectory)/dist/app/*</code></li> <li><code>$(Build.ArtifactStagingDirectory)/dist/app/*.*</code></li> </ul>  <p>but all of these fail the build with the error <code>Not found PathtoPublish</code></p>""",azure-devops
33800455,Is it safe to multithread host.RunAndBlock() in azure WebJobs <p>I need to handle a large amount of separated queues  the queues need to be separated but handled in the same way  I don’t want to setup multiple queue-functions so I thought of this solution but I’m not sure it’s a safe way to do: </p>  <pre><code>var connectors = GetTheConnectors();          var tasks = new List&lt;Task&gt;();         foreach (var item in connectors)         {             var task = Task.Factory.StartNew(() =&gt; {                 var host = new JobHost(new JobHostConfiguration                 {                     NameResolver = new QueueNameResolver(item.Name)                 });                 host.RunAndBlock();             });             tasks.Add(task);         }          Task.WaitAll(tasks.ToArray()); </code></pre>  <p>If not  Do anyone have a better solution?</p>,azure-storage
56747494,"How to programmatically using C# fetch or update or toggle or manipulate the auto-shutdown parameters for a selected azure VM in Azure portal? <p>I am trying to programmatically using C# fetch the details of Auto-shutdown parameters for a selected VM from azure portal. The things i want to achieve are given below:</p>  <blockquote>   <ol>   <li>First  get the auto shut down status it is enabled or disabled?</li>   <li>If it is enabled then get auto shutdown time and its time zone related information</li>   <li>Based on input update the timezone and time or disable the auto shutdown status on need basis</li>   </ol> </blockquote>  <p>I want this to be done via C# program.</p>  <p>I am not knowing how to achieve it through the googling i have done. Please provide a detailed step by step guide how to achieve it as i am new to coding  C#  and AZURE</p>  <p>Please note that the VM's in our project are not created in any DevTest labs these are created through LCS directly and with DEMO env an option while creation.</p>  <p>Can you please provide details taking the above points into consideration? Or this is not possible as the step is not correct?</p>  <p>Please let me know if any other information is needed from my end to enable you provide me a solution.</p>  <p>I have already looked into below PowerShell script:</p>  <p><a href=\https://stackoverflow.com/questions/56295205/how-to-collect-the-azure-vm-auto-shutdown-time-using-powershell\"">How to collect the Azure VM auto-shutdown time using PowerShell?</a></p>  <p>But this seems to be involving a VM created in DEV TEST lab which in my case will not work as our VM'S are not created in a separate lab has tried to explain above. Hence i think the script does not work</p>  <p>Tried to look into a few REST API but could not find anything there also.</p>""",azure-virtual-machine
11173260,What's the best workflow for an Azure virtual machine (Windows)? <p>I'm developing a Socket.IO application with a MongoDB database. For various reasons I am developing the application to run on a Windows virtual machine within Azure. Setting everything up was fairly painless and I now have a basic application within the cloud. However  I am unable to find a comfortable workflow. I want to be able to push changes to the virtual machine (as if I was on *nix system using git) and I'm not sure how best to do this.</p>,azure-virtual-machine
55113103,"Azure CLI returns error on Storage access <p>I'm on a Linux machine trying to use the Azure CLI <code>az</code> to list storages</p>  <pre><code>az storage blob list --container-name &lt;name&gt; --account-name &lt;name&gt; --account-key &lt;key&gt; </code></pre>  <p>when executing it returns the error </p>  <pre><code>azure.common.AzureHttpError: One of the request inputs is out of range. ErrorCode: OutOfRangeInput &lt;?xml version=\1.0\"" encoding=\""utf-8\""?&gt;&lt;Error&gt;&lt;Code&gt;OutOfRangeInput&lt;/Code&gt;&lt;Message&gt;One of the request inputs is out of range. RequestId:bf2b4b1d-401e-0055-1678-d80520000000 Time:2019-03-12T02:08:42.4135303Z&lt;/Message&gt;&lt;/Error&gt; </code></pre>  <p>I can't find any documentation that explains the error?</p>""",azure-storage
48351439,"Azure Functions fails to receive Azure Queue messages [.net Core 2.0] <p>When I updated my Azure Functions project to .net core 2.0  it started failing to trigger upon a message on my Queue.</p>  <p><strong>TranslatorAPI.cs</strong></p>  <pre><code>public static class TranslatorAPI {     [FunctionName(\TranslatorAPI\"")]     public static void Run([QueueTrigger(\""Translator\"")]string mySbMsg  TraceWriter log)     {         //breakpoint here  but never hit         CallTranslator callTranslator = new CallTranslator();          //something     } } </code></pre>  <p><strong>local.setting.json</strong></p>  <pre><code>{   \""IsEncrypted\"": false    \""Values\"": {     \""WEBSITE_SLOT_NAME\"": \""Production\""      \""FUNCTIONS_EXTENSION_VERSION\"": \""~1\""      \""ScmType\"": \""None\""      \""WEBSITE_AUTH_ENABLED\"": \""False\""      \""FUNCTION_APP_EDIT_MODE\"": \""readwrite\""      \""APPINSIGHTS_INSTRUMENTATIONKEY\"": \""&lt;Key&gt;\""      \""WEBSITE_NODE_DEFAULT_VERSION\"": \""6.5.0\""      \""WEBSITE_CONTENTAZUREFILECONNECTIONSTRING\"": \""DefaultEndpointsProtocol=https;AccountName=&lt;AccountName&gt;;AccountKey=&lt;Key&gt;\""      \""WEBSITE_CONTENTSHARE\"": \""&lt;ShareName&gt;\""      \""WEBSITE_SITE_NAME\"": \""&lt;Functions'Name&gt;\""      \""&lt;ServiceBusInstanceName&gt;_RootManageSharedAccessKey_SERVICEBUS\"": \""Endpoint=&lt;ConnectionString&gt;\""      \""AzureWebJobsStorage\"": \""DefaultEndpointsProtocol=https;AccountName=&lt;AccountName&gt;;AccountKey=&lt;Key&gt;\""      \""AzureWebJobsDashboard\"": \""DefaultEndpointsProtocol=https;AccountName=&lt;AccountName&gt;;AccountKey=&lt;Key&gt;;BlobEndpoint=&lt;BlobURL&gt;;TableEndpoint=&lt;TableURL&gt;;QueueEndpoint=&lt;QueueURL&gt;;FileEndpoint=&lt;FileURL&gt;\""   } } </code></pre>  <p><strong>Workaround:</strong></p>  <p>With the latest NuGet package \""Microsoft.Azure.WebJobs\"" 3.0.0-beta4  there is <a href=\""https://github.com/Azure/Azure-Functions/issues/624\"" rel=\""nofollow noreferrer\"">a  known issue</a> with handling an extension for ServiceBus connection and project build is to fail at establishing a path for the ServiceBus metadata. Updating these packages from the source <a href=\""http://www.myget.org/F/azure-appservice/api/v2\"" rel=\""nofollow noreferrer\"">Azure App Service</a>:</p>  <pre><code>Microsoft.Azure.WebJobs: 3.0.0-beta4-11131 Microsoft.Azure.WebJobs.Extensions: 3.0.0-beta4-10578 Microsoft.Azure.WebJobs.Script.ExtensionsMetadataGenerator: 1.0.0-beta3 Microsoft.Azure.WebJobs.ServisBus: 3.0.0-beta4-11131 </code></pre>  <p>enabled the build succeeded. However  it still cannot receive a message from my queue. Here's the log of function console.</p>  <pre><code>[2018/01/20 0:22:38] Reading host configuration file '&lt;ProjectPath&gt;\\bin\\Debug\\netstandard2.0\\host.json' [2018/01/20 0:22:38] Host configuration file read: [2018/01/20 0:22:38] {} [2018/01/20 0:22:40] Loading custom extension 'HttpExtensionConfiguration' [2018/01/20 0:22:40] Unable to load custom extension type for extension 'HttpExtensionConfiguration' (Type: `Microsoft.Azure.WebJobs.Extensions.Http.HttpExtensionConfiguration  Microsoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null`).The type does not exist or is not a valid extension. Please validate the type and assembly names. [2018/01/20 0:22:40] Loading custom extension 'ServiceBusExtensionConfig' [2018/01/20 0:22:40] Loaded custom extension: ServiceBusExtensionConfig from '&lt;ProjectPath&gt;\\bin\\Debug\\netstandard2.0\\bin\\Microsoft.Azure.WebJobs.ServiceBus.dll' [2018/01/20 0:22:41] Generating 1 job function(s) [2018/01/20 0:22:42] Starting Host (HostId=&lt;PCName&gt;-1149239943  Version=2.0.11415.0  ProcessId=12536  Debug=False  ConsecutiveErrors=0  StartupCount=1  FunctionsExtensionVersion=~1) [2018/01/20 0:22:44] Found the following functions: [2018/01/20 0:22:44] &lt;Functions'Name&gt;.TranslatorAPI.Run [2018/01/20 0:22:44] [2018/01/20 0:22:44] Job host started [2018/01/20 0:22:44] Host lock lease acquired by instance ID '&lt;ID&gt;'. Listening on http://localhost:7071/ Hit CTRL-C to exit... </code></pre>  <p>Although it fails to read an extenstion for http trigger type  it succeeds to generate TranslatorAPI.Run.</p>  <p>So what would be a problem here?</p>  <p><strong>EDIT</strong></p>  <p>I assumed the method failed to get the connection string  so I changed the method argument to</p>  <pre><code>public static void Run([QueueTrigger(\""Translator\""  Connection = \""&lt;ServiceBusInstanceName&gt;_RootManageSharedAccessKey_SERVICEBUS\"")]string mySbMsg  TraceWriter log) </code></pre>  <p>Then the error changed into </p>  <pre><code>[2018/01/20 1:32:57] Run: Microsoft.Azure.WebJobs.Host: Error indexing method 'TranslatorAPI.Run'. Microsoft.Azure.WebJobs.Host: Failed to validate Microsoft Azure WebJobs SDK &lt;ServiceBusInstanceName&gt;_RootManageSharedAccessKey_SERVICEBUS connection string. The Microsoft Azure Storage account connection string is not formatted correctly. Please visit https://go.microsoft.com/fwlink/?linkid=841340 for details about configuring Microsoft Azure Storage connection strings. </code></pre>  <p>Now it seems say my connection string for the ServiceBus is wrong <em>based on the validation of connection string for Azure Storage Account</em>. I'm not sure how to understand what's this meaning and to solve this issue. </p>""",azure-functions
51268507,How do I get a camera to work on an Azure Virtual Machine <p>I want to be able to use a camera on an Azure Virtual Machine using Windows 10.</p>  <p>Camera feed can either come through on local machine or a feed from another machine. Either way I get the below error: We can't find your camera  NoCamerasAreAttached.</p>  <p>Even though I have enabled both through the connection and enable USB Redirection in Windows 10. incl gpedit.msc</p>,azure-virtual-machine
47399191,"How to create a counter inside a for loop for Iterable in Java and get the value of the counter variable <p>Here's my current code snippet:</p>  <pre><code>    Iterable&lt;HashMap&lt;String  EntityProperty&gt;&gt; results =             cloudTable.execute(query  propertyResolver);      if (results == null) {         System.out.println(\No files processed\"");         exit_code = \""exit_code=1\"";     } else {         for (HashMap&lt;String  EntityProperty&gt; entity : results) {             // don't know how to start the loop here          }     } </code></pre>  <p>I have a query for retrieving a list of certain files in Microsoft Azure. Now I just need to show the number of files processed result. </p>  <p>I know the concept of what I should be doing  create a counter within the for loop  and then after the Iterations in that loop  whatever the value of that counter variable  it should also give me the count of files right? I just don't know how to start :( I've been reading so much about Iterable in Java but still can't get a grasp on how it would work. </p>  <p>Any inputs would be greatly appreciated </p>""",azure-storage
38710138,"How often can MS Azure App Services Outbound IP addresses change? <p>I'm using Azure App Services that calls an external API that uses white-listing of IP addresses for defense-in-depth protection. </p>  <p>I'm aware I can find my Outbound IP addresses of my App Services under the WebApp -> Settings -> Properties -> Outbound IP addresses (showing a list of 4 comma separated IP addresses) which can be supplied to the external API whitelist. I understand Microsoft publishes a regularly updated list of Azure datacenter's IP addresses for outbound traffic that I can whitelist: <a href=\https://www.microsoft.com/en-us/download/details.aspx?id=41653\"" rel=\""noreferrer\"">https://www.microsoft.com/en-us/download/details.aspx?id=41653</a></p>  <p>The issue is the external API can only handle a number of IP addresses and not the full list of Azure datacenter IP's. Would it be safe to just provide the 4 comma separated IP addresses? Is there clear Microsoft documentation on how often or when the IP address can dynamically change?  </p>  <p>I have tried to look for the answer and found two external sites that suggested it only changes when moving Azure regions [Ref 2] or if you scale up/down (but scale out/in is apparently fine) [Ref 1]. Is this correct information?</p>  <p>Is the Azure App Services Environment the only other viable alternative in my situation?</p>""",azure-web-app-service
53266028,"Azure DevOps hosted ubuntu agent issue updating Application Gateway <p>I deployed some infra using Terraform  including an application gateway. Unfortunately not all settings can be set/updated with terraform. SO I have a shell script that updates the application gateway. </p>  <pre><code>#!/bin/bash SP_ID=${1} SP_SECRET=${2} TENANT_ID=${3} SUBSCRIPTION=${4} RG=${5}  az login --service-principal -u ${SP_ID} -p ${SP_SECRET} -t ${TENANT_ID} az account set --subscription ${SUBSCRIPTION} az account list -o table  # Get the name of the AG echo \RG = ${RG}\"" AG=$(az network application-gateway list --resource-group ${RG} | tail -n 1 | awk '{ print $2 }') echo \""AG = ${AG}\""  # Get the AG backend pool name BP=$(az network application-gateway address-pool list --resource-group ${RG} --gateway-name ${AG} | tail -n 1 | awk '{ print $1 }') echo \""Backend pool = ${BP}\""  # Get the frontendip of the load balancer LB=$(az network lb list --resource-group ${RG} | tail -n 1 | awk '{ print $2         }') LBFEIP=$(az network lb frontend-ip list --lb-name ${LB} --resource-group    ${RG} | tail -n 1 | awk '{ print $2 }') echo \""Load balancer = ${LB}\"" echo \""Frontend ip LB =  ${LBFEIP}\""  # Update the backend pool of the AG with the frontend ip of the loadbalancer echo \""Updating Backend address pool of AG ${AG}\"" az network application-gateway address-pool update --gateway-name $AG --resource-group $RG --name $BP --servers ${LBFEIP}  # Update http settings echo \""Updating HTTP settings of AG ${AG}\"" AG_HTS=$(az network application-gateway http-settings list --resource-group     ${RG} --gateway-name ${AG} | tail -n 1 | awk '{ print $2 }') az network application-gateway http-settings update --resource-group ${RG} --gateway-name ${AG} --name ${AG_HTS} --host-name-from-backend-pool true  # Update health probe echo \""Updating Health probe of AG ${AG}\"" AG_HP=$(az network application-gateway probe list --resource-group ${RG} --gateway-name ${AG} | tail -n 1 | awk '{ print $4 }') az network application-gateway probe update --resource-group ${RG} --gateway-name ${AG} --name ${AG_HP} --host '' --host-name-from-http-settings true </code></pre>  <p>This script works fine running locally from my laptop but via the azure devops release pipeline I get the error:</p>  <pre><code>ERROR: az network application-gateway address-pool list: error: argument --gateway-name: expected one argument </code></pre>  <p>Somehow it cannot get the application gateway name when the script is running through the release pipeline. Again  when running this script locally it works fine. Anyoone an idea of what I maybe missing here or can try?</p>  <p>I created the script on WSL Ubuntu and used a ubuntu hosted agent to publish the artifacts and also use a hosted ubuntu agent to deploy the script.</p>""",azure-devops
50122242,"what's the easiest way to upload a solution to a vsts repo? <p>What's the easiest way to upload a solution to a new VSTS repo? I've created a new repo in VSTS and I need to upload a solution to it. When I go to the repo in VSTS there's an \Upload file(s)\"" button which opens a \""Commit\"" dialog.  The top panel of the Commit dialog has a \""Browse...\"" widget which says: \""Drag and drop files here or click browse to select a file\""</p>  <p>If I provide the path where my app exists then the dialog only lets me select top-level files but not folders. I do see a way to manually add folders via the VSTS UI. Is there a simpler way to add all the contents of my solution folder at once as opposed to manually piecing this together as described above?</p>""",azure-devops
19893720,Scalling Wordpress on Windows Azure: <p>I'm running a Wordpress multisite which in short periods every week experience a big number of users requiring more CPU + RAM. </p>  <p>I therefore wish to make use of Azure autoscale to turn on more instances if the demand are there  however is it possible to make a setup where the different instances share same storage and database? And if yes how could it be done?</p>,azure-virtual-machine
44826846,"Team Services control options in Release task <p>I might be doing something wrong  but I have created a Build and a Release in VSTS. For the release I need to execute a task only if one of the previous failed. This is easy for the tasks in the Build  there is a dropdown with several options including \Only when a previous task has failed\""  however for the release  I only have Always run and continue on error  which doesn't work for me. </p>  <p>Is this because the control options for release doesn't support the same options as the build or is something missing for my VSTS?</p>""",azure-devops
50727626,"How to config dns of a virtual machine in Azure to point to another domain <p>I have an application that is installed on a virtual machine in <code>Azure</code>. It is accessible with the public ip and the dns name offered by Azure.</p>  <p>I have a domain name with ssl in namecheap. I want to point the dns name from Azure to it or another provider.</p>  <p>To illustrate even more:</p>  <p>My app is accessible to the outside world using: <code>x.x.x.x/app/login</code></p>  <p>or with: <code>mydnsname.azure.com/app/login</code></p>  <p>What I want is: <code>anotherdomain.com/app/login</code></p>  <p><a href=\https://i.stack.imgur.com/0LNRg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/0LNRg.png\"" alt=\""azure to namecheap\""></a></p>  <p>I don't want to change my records inside namecheap  i.e. changing <code>CNAME</code> record to point to my dns and <code>A</code> record to the public ip of my vm.</p>  <p>I know this method but in my situation it doesn't work.</p>  <p><a href=\""https://i.stack.imgur.com/aSe3M.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/aSe3M.png\"" alt=\""namecheap to azure\""></a></p>""",azure-virtual-machine
51965087,"spring boot azure storage connection string error <p>I use spring boot 2.0.2. when I run the application spring boot in cmd with the mvn spring-boot: run command running smoothly  but when I export it to war and I run it on tomcat with the ROOT path I get the following error:</p>  <pre><code>2018-08-22 17:21:17.312  INFO 10764 --- [ost-startStop-1] m.s.d.PriorityQueueEmailSchedulerService : Scheduled email Email{from=developerglob@gmail.com  to=[cisvapery@gmail.com]  subject=Glob report buy point firetime \\'2018-08-22T16:38+07:00\\' and priority 1  body=  attachments=[report_buy_point pripurna bandung.csv]  encoding=UTF-8} at UTC time [2018-08-22T16:38+07:00  1] with priority {} with template [WARN] AnnotationConfigServletWebServerApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'storageAzureService': Unsatisfied dependency expressed through field 'cloudStorageAccount'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'com.microsoft.azure.spring.autoconfigure.storage.StorageAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.boot.context.properties.ConfigurationPropertiesBindException: Error creating bean with name 'azure.storage-com.microsoft.azure.spring.autoconfigure.storage.StorageProperties': Could not bind properties to 'StorageProperties' : prefix=azure.storage  ignoreInvalidFields=false  ignoreUnknownFields=true; nested exception is org.springframework.boot.context.properties.bind.BindException: Failed to bind properties under 'azure.storage' to com.microsoft.azure.spring.autoconfigure.storage.StorageProperties 2018-08-22 17:21:18.183  INFO 10764 --- [ost-startStop-1] m.s.d.PriorityQueueEmailSchedulerService : Closing EmailScheduler 2018-08-22 17:21:18.185  INFO 10764 --- [ost-startStop-1] m.s.d.PriorityQueueEmailSchedulerService : Interrupting email scheduler consumer Exception in thread \PriorityQueueEmailSchedulerService -- Consumer\"" org.springframework.mail.MailSendException: Mail server connection failed; nested exception is javax.mail.MessagingException: Could not convert socket to TLS;   nested exception is:         javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target. Failed messages: javax.mail.MessagingException: Could not convert socket to TLS;   nested exception is:         javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; message exception details (1) are: Failed message 1: javax.mail.MessagingException: Could not convert socket to TLS;   nested exception is:         javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target         at com.sun.mail.smtp.SMTPTransport.startTLS(SMTPTransport.java:2155)         at com.sun.mail.smtp.SMTPTransport.protocolConnect(SMTPTransport.java:752)         at javax.mail.Service.connect(Service.java:366)         at org.springframework.mail.javamail.JavaMailSenderImpl.connectTransport(JavaMailSenderImpl.java:515)         at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:435)         at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:359)         at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:354)         at it.ozimov.springboot.mail.service.defaultimpl.DefaultEmailService.send(DefaultEmailService.java:138)         at it.ozimov.springboot.mail.service.defaultimpl.PriorityQueueEmailSchedulerService$Consumer.run(PriorityQueueEmailSchedulerService.java:443) Caused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target         at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)         at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1959)         at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:328)         at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:322)         at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1614)         at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:216)         at sun.security.ssl.Handshaker.processLoop(Handshaker.java:1052)         at sun.security.ssl.Handshaker.process_record(Handshaker.java:987)         at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1072)         at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1385)         at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1413)         at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1397)         at com.sun.mail.util.SocketFetcher.configureSSLSocket(SocketFetcher.java:620)         at com.sun.mail.util.SocketFetcher.startTLS(SocketFetcher.java:547)         at com.sun.mail.smtp.SMTPTransport.startTLS(SMTPTransport.java:2150)         ... 8 more Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target         at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:397)         at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:302)         at sun.security.validator.Validator.validate(Validator.java:260)         at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324)         at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229)         at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:124)         at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1596)         ... 18 more Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target         at sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:141)         at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:126)         at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:280)         at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:392)         ... 24 more 2018-08-22 17:21:39.400  INFO 10764 --- [ost-startStop-1] m.s.d.PriorityQueueEmailSchedulerService : Closed EmailScheduler [INFO] LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default' 2018-08-22 17:21:39.431  INFO 10764 --- [ost-startStop-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated... 2018-08-22 17:21:39.437  INFO 10764 --- [ost-startStop-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed. [INFO] ConditionEvaluationReportLoggingListener -  Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. [ERROR] LoggingFailureAnalysisReporter - *************************** APPLICATION FAILED TO START ***************************  Description:  Failed to bind properties under 'azure.storage' to com.microsoft.azure.spring.autoconfigure.storage.StorageProperties:      Property: azure.storage.connection-string     Value: DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=globimage;AccountKey=j98PljOhAYdToMXHxFeLd5sC6afk1DMBeF8dfYETOYJU0j8AHp0Fkh3dgikoevByrkb2zCr4IwzST4HqjkBTUQ==     Origin: class path resource [application.properties]:60:33     Reason: HV000030: No validator could be found for constraint 'javax.validation.constraints.NotEmpty' validating type 'java.lang.String'. Check configuration for 'connectionString'  Action:  Update your application's configuration </code></pre>  <p>even though the application properties are correct application.properties:</p>  <pre><code>#Server konfiguration port server.port=8087 #spring.resources.static-locations[0]=file:src/main/resources/static/ #spring.resources.static-locations[1]=classpath:/static/  #JPA Konfiguration spring.datasource.url=jdbc:sqlserver://52.230.65.127;databaseName=globdbreview spring.datasource.username=sa spring.datasource.password=Develasas spring.datasource.driverClassName=com.microsoft.sqlserver.jdbc.SQLServerDriver spring.jpa.show-sql=true spring.jpa.hibernate.ddl-auto = update spring.jpa.properties.hibernate.legacy_limit_handler=true  #SQL Server JPA konfiguration spring.jpa.properties.hibernate.dialect=com.bridgetech.glob.model.SQLServerNativeDialect spring.jpa.hibernate.naming.implicit-strategy=org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl  #default JSP #spring.mvc.view.prefix=/WEB-INF/jsp/ #spring.mvc.view.suffix=.jsp  #Logging logging.level.org.springframework.web=INFO  #Thymeleaf konfiguration spring.thymeleaf.cache=false  # Specify the Lucene Directory #spring.jpa.properties.hibernate.search.default.directory_provider = filesystem  # Using the filesystem DirectoryProvider you also have to specify the default # base directory for all indexes  #spring.jpa.properties.hibernate.search.default.indexBase = indexpath  #Smtp mail konfiguration spring.mail.default-encoding=UTF-8 spring.mail.host=smtp.gmail.com spring.mail.username=developerglobsa@gmail.com spring.mail.password=@asdadsadsa spring.mail.port=587 spring.mail.protocol=smtp spring.mail.test-connection=false spring.mail.properties.mail.smtp.auth=true spring.mail.properties.mail.smtp.starttls.enable=true  #upload file #spring.servlet.multipart.max-file-size=50mb #spring.servlet.multipart.max-request-size=50mb  spring.mail.scheduler.enabled=true spring.mail.scheduler.priorityLevels=5  spring.mail.scheduler.persistence.enabled=false spring.mail.scheduler.persistence.redis.embedded=false spring.mail.scheduler.persistence.redis.enabled=false  #azure storage azure.storage.connection-string=DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=globim;AccountKey=j98PljOhAYdToMXHxFeLd5sC6afk1DMBeF8dfYETOYJU0j8AHp0Fkh3dgik </code></pre>  <p>StorageAzureService:</p>  <pre><code>@Service public class StorageAzureService {      @Autowired     private CloudStorageAccount cloudStorageAccount;      public static final String storageConnectionString = \""DefaultEndpointsProtocol=[http|https];EndpointSuffix=core.windows.net;AccountName=globimage;AccountKey=j98PljOhAYdToMXHxFeLd5sC6afk1DMBeF8dfYETOYJU0j8AHp0Fkh3dgikoevByrkb2zCr4IwzST4HqjkBTUQ==\"";      final String containerName = \""image\"";      public StorageAzureService() { //      try { //          cloudStorageAccount = CloudStorageAccount.parse(storageConnectionString); //      } catch (InvalidKeyException e) { //          // TODO Auto-generated catch block //          e.printStackTrace(); //      } catch (URISyntaxException e) { //          // TODO Auto-generated catch block //          e.printStackTrace(); //      }         // TODO Auto-generated constructor stub     }      public void createContainerIfNotExists() {         try {             // Create a blob client.             final CloudBlobClient blobClient = cloudStorageAccount.createCloudBlobClient();             // Get a reference to a container. (Name must be lower case.)             final CloudBlobContainer container = blobClient.getContainerReference(containerName);             // Create the container if it does not exist.             if (container.createIfNotExists()) {                 System.out.println(\""True: \"" + containerName);             } else {                 System.out.println(\""False: \"" + containerName);             }         } catch (Exception e) {             // Output the stack trace.             e.printStackTrace();         }     }      public String uploadTextBlob(MultipartFile file  String fileName) {         try {              // Create a blob client.             final CloudBlobClient blobClient = cloudStorageAccount.createCloudBlobClient();             // Get a reference to a container. (Name must be lower case.)             final CloudBlobContainer container = blobClient.getContainerReference(containerName);             // Get a blob reference for a text file.             CloudBlockBlob blob = container.getBlockBlobReference(fileName);             // Upload some text into the blob.             blob.upload(file.getInputStream()  file.getSize());             System.out.println(\""success upload.\"" + blob.getUri().toString());             return blob.getUri().toString();         } catch (Exception e) {             // Output the stack trace.             e.printStackTrace();         }         return null;     }      public void deleteTextBlob(String fileName) {         try {             if (fileName.startsWith(\""https://globimage.blob.core.windows.net/glob-images/\"")) {                 System.out.println(\""True: https://globimage.blob.core.windows.net/glob-images/\"");                 String fileNameImgGlob = fileName.substring(52);                 // Create a blob client.                 final CloudBlobClient blobClient = cloudStorageAccount.createCloudBlobClient();                 // Get a reference to a container. (Name must be lower case.)                 final CloudBlobContainer container = blobClient.getContainerReference(containerName);                 // Get a blob reference for a text file.                 CloudBlockBlob blob = container.getBlockBlobReference(fileNameImgGlob);                 // Upload some text into the blob.                 if (blob.exists()) {                     blob.deleteIfExists();                     System.out.println(\""success delete.\"" + blob.getUri().toString());                 } else {                     System.out.println(\""file not found.\"");                 }             }         } catch (Exception e) {             // Output the stack trace.             e.printStackTrace();         }     }      public void deleteShareFile() {          try {              // Create the file client.             CloudFileClient fileClient = cloudStorageAccount.createCloudFileClient();              // Get a reference to the file share             CloudFileShare share = fileClient.getShareReference(\""sampleshare\"");              if (share.deleteIfExists()) {                 System.out.println(\""sampleshare deleted\"");             }         } catch (Exception e) {             e.printStackTrace();         }      }      public void createDirectory() {          try {             // Create the file client.             CloudFileClient fileClient = cloudStorageAccount.createCloudFileClient();              // Get a reference to the file share             CloudFileShare share = fileClient.getShareReference(\""sampleshare\"");              // Get a reference to the root directory for the share.             CloudFileDirectory rootDir = share.getRootDirectoryReference();              // Get a reference to the sampledir directory             CloudFileDirectory sampleDir = rootDir.getDirectoryReference(\""sampledir\"");              if (sampleDir.createIfNotExists()) {                 System.out.println(\""sampledir created\"");             } else {                 System.out.println(\""sampledir already exists\"");             }         } catch (Exception e) {             // TODO: handle exception         }      }      public void deleteDirectory() {         try {             // Create the file client.             CloudFileClient fileClient = cloudStorageAccount.createCloudFileClient();              // Get a reference to the file share             CloudFileShare share = fileClient.getShareReference(\""sampleshare\"");              // Get a reference to the root directory for the share.             CloudFileDirectory rootDir = share.getRootDirectoryReference();              // Get a reference to the directory you want to delete             CloudFileDirectory containerDir = rootDir.getDirectoryReference(\""sampledir\"");              // Delete the directory             if (containerDir.deleteIfExists()) {                 System.out.println(\""Directory deleted\"");             }         } catch (Exception e) {             // TODO: handle exception         }     }      public void listFilesAndDirectories() {         try {             // Create the file client.             CloudFileClient fileClient = cloudStorageAccount.createCloudFileClient();              // Get a reference to the file share             CloudFileShare share = fileClient.getShareReference(containerName);             // Get a reference to the root directory for the share.             CloudFileDirectory rootDir = share.getRootDirectoryReference();              for (ListFileItem fileItem : rootDir.listFilesAndDirectories()) {                 System.out.println(fileItem.getUri());             }         } catch (Exception e) {             e.printStackTrace();         }     }      public void uploadFile() {         try {             // Create the file client.             CloudFileClient fileClient = cloudStorageAccount.createCloudFileClient();              // Get a reference to the file share             CloudFileShare share = fileClient.getShareReference(\""share-images\"");              if (share.createIfNotExists()) {                 System.out.println(\""New share created\"");             }              // Get a reference to the root directory for the share.             CloudFileDirectory rootDir = share.getRootDirectoryReference();              // Define the path to a local file.             final String filePath = \""D:\\\\uploads\\\\my.jpg\"";              CloudFile cloudFile = rootDir.getFileReference(\""my.jpg\"");             cloudFile.uploadFromFile(filePath);         } catch (Exception e) {             // TODO: handle exception             System.out.println(e.getMessage());         }     }      public void downloadFile() {         try {             // Create the file client.             CloudFileClient fileClient = cloudStorageAccount.createCloudFileClient();              // Get a reference to the file share             CloudFileShare share = fileClient.getShareReference(\""sampleshare\"");              // Get a reference to the root directory for the share.             CloudFileDirectory rootDir = share.getRootDirectoryReference();              // Get a reference to the directory that contains the file             CloudFileDirectory sampleDir = rootDir.getDirectoryReference(\""sampledir\"");              // Get a reference to the file you want to download             CloudFile file = sampleDir.getFileReference(\""SampleFile.txt\"");              // Write the contents of the file to the console.             System.out.println(file.downloadText());         } catch (Exception e) {             // TODO: handle exception         }     }      public void deleteFile2() {         try {             // Create the file client.             CloudFileClient fileClient = cloudStorageAccount.createCloudFileClient();              // Get a reference to the file share             CloudFileShare share = fileClient.getShareReference(\""sampleshare\"");              // Get a reference to the root directory for the share.             CloudFileDirectory rootDir = share.getRootDirectoryReference();              // Get a reference to the directory where the file to be deleted is in             CloudFileDirectory containerDir = rootDir.getDirectoryReference(\""sampledir\"");              String filename = \""SampleFile.txt\"";             CloudFile file;              file = containerDir.getFileReference(filename);             if (file.deleteIfExists()) {                 System.out.println(filename + \"" was deleted\"");             }         } catch (Exception e) {             // TODO: handle exception         }     }  } </code></pre>  <p>GlobApplication:</p>  <pre><code>@ComponentScan(basePackages = \""com.bridgetech.glob\"") @SpringBootApplication @EnableEmailTools public class GlobApplication //implements ApplicationContextAware {      @Autowired     EmailSenderService emailSenderService; //   //  private ApplicationContext applicationContext;      @Bean     WebMvcConfigurer configurer() {         return new WebMvcConfigurer() {             @Override             public void addResourceHandlers(ResourceHandlerRegistry registry) {                 registry.addResourceHandler(\""/static/**\"").addResourceLocations(\""classpath:/static/\"");             }         };     }      public static void main(String[] args) {         SpringApplication.run(GlobApplication.class  args);     }  //  @Override //  public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { //      this.applicationContext = applicationContext; //  } //     @PostConstruct     public void sendEmail() throws UnsupportedEncodingException  InterruptedException  CannotSendEmailException  URISyntaxException {         emailSenderService.scheduleSixEmails(1);  //      close();     }  //  private void close() { //      TimerTask shutdownTask = new TimerTask() { //          @Override //          public void run() { //              ((AbstractApplicationContext) applicationContext).close(); //          } //      }; //      Timer shutdownTimer = new Timer(); //      shutdownTimer.schedule(shutdownTask  TimeUnit.SECONDS.toMillis(20)); //  }  } </code></pre>  <p>pom.xml:</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""UTF-8\""?&gt; &lt;project xmlns=\""http://maven.apache.org/POM/4.0.0\""     xmlns:xsi=\""http://www.w3.org/2001/XMLSchema-instance\""     xsi:schemaLocation=\""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\""&gt;     &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;      &lt;groupId&gt;com.bridgetech&lt;/groupId&gt;     &lt;artifactId&gt;glob&lt;/artifactId&gt;     &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;     &lt;packaging&gt;war&lt;/packaging&gt;      &lt;name&gt;glob&lt;/name&gt;     &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;      &lt;parent&gt;         &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;         &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;         &lt;version&gt;2.0.2.RELEASE&lt;/version&gt;         &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;     &lt;/parent&gt;      &lt;properties&gt;         &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;         &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;         &lt;java.version&gt;1.8&lt;/java.version&gt;         &lt;azure.version&gt;2.0.4&lt;/azure.version&gt;     &lt;/properties&gt;      &lt;dependencyManagement&gt;         &lt;dependencies&gt;             &lt;dependency&gt;                 &lt;groupId&gt;com.microsoft.azure&lt;/groupId&gt;                 &lt;artifactId&gt;azure-spring-boot-bom&lt;/artifactId&gt;                 &lt;version&gt;${azure.version}&lt;/version&gt;                 &lt;type&gt;pom&lt;/type&gt;                 &lt;scope&gt;import&lt;/scope&gt;             &lt;/dependency&gt;         &lt;/dependencies&gt;     &lt;/dependencyManagement&gt;      &lt;dependencies&gt;         &lt;dependency&gt;             &lt;groupId&gt;com.microsoft.azure&lt;/groupId&gt;             &lt;artifactId&gt;azure-storage-spring-boot-starter&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.json&lt;/groupId&gt;             &lt;artifactId&gt;json&lt;/artifactId&gt;             &lt;version&gt;20180130&lt;/version&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;!-- &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;              &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; --&gt;         &lt;dependency&gt;             &lt;groupId&gt;com.microsoft.sqlserver&lt;/groupId&gt;             &lt;artifactId&gt;mssql-jdbc&lt;/artifactId&gt;             &lt;scope&gt;runtime&lt;/scope&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;             &lt;scope&gt;provided&lt;/scope&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;             &lt;scope&gt;test&lt;/scope&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;javax.servlet&lt;/groupId&gt;             &lt;artifactId&gt;jstl&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;             &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;             &lt;scope&gt;provided&lt;/scope&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt;             &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;commons-beanutils&lt;/groupId&gt;             &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt;             &lt;version&gt;1.9.3&lt;/version&gt;         &lt;/dependency&gt;           &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;com.icegreen&lt;/groupId&gt;             &lt;artifactId&gt;greenmail&lt;/artifactId&gt;             &lt;version&gt;1.5.5&lt;/version&gt;             &lt;scope&gt;test&lt;/scope&gt;         &lt;/dependency&gt;          &lt;!-- bootstrap and jquery --&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.webjars&lt;/groupId&gt;             &lt;artifactId&gt;bootstrap&lt;/artifactId&gt;             &lt;version&gt;3.3.7&lt;/version&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.webjars&lt;/groupId&gt;             &lt;artifactId&gt;jquery&lt;/artifactId&gt;             &lt;version&gt;3.2.1&lt;/version&gt;         &lt;/dependency&gt;          &lt;!-- https://mvnrepository.com/artifact/org.apache.poi/poi --&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.apache.poi&lt;/groupId&gt;             &lt;artifactId&gt;poi&lt;/artifactId&gt;             &lt;version&gt;3.17&lt;/version&gt;         &lt;/dependency&gt;          &lt;!-- https://mvnrepository.com/artifact/com.lowagie/itext --&gt;         &lt;dependency&gt;             &lt;groupId&gt;com.lowagie&lt;/groupId&gt;             &lt;artifactId&gt;itext&lt;/artifactId&gt;             &lt;version&gt;2.1.7&lt;/version&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt;             &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;org.eclipse.persistence&lt;/groupId&gt;             &lt;artifactId&gt;eclipselink&lt;/artifactId&gt;             &lt;version&gt;2.7.0&lt;/version&gt;         &lt;/dependency&gt;          &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-webmvc --&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework&lt;/groupId&gt;             &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;             &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;         &lt;/dependency&gt;          &lt;!-- https://mvnrepository.com/artifact/com.itextpdf/itextpdf --&gt;         &lt;dependency&gt;             &lt;groupId&gt;com.itextpdf&lt;/groupId&gt;             &lt;artifactId&gt;itextpdf&lt;/artifactId&gt;             &lt;version&gt;5.5.13&lt;/version&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;org.json&lt;/groupId&gt;             &lt;artifactId&gt;json&lt;/artifactId&gt;             &lt;version&gt;20160810&lt;/version&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;com.google.firebase&lt;/groupId&gt;             &lt;artifactId&gt;firebase-admin&lt;/artifactId&gt;             &lt;version&gt;5.9.0&lt;/version&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;it.ozimov&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-email-core&lt;/artifactId&gt;             &lt;version&gt;0.6.3&lt;/version&gt;         &lt;/dependency&gt;          &lt;dependency&gt;             &lt;groupId&gt;it.ozimov&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-freemarker-email&lt;/artifactId&gt;             &lt;version&gt;0.6.3&lt;/version&gt;         &lt;/dependency&gt;          &lt;!-- &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;             &lt;optional&gt;true&lt;/optional&gt;         &lt;/dependency&gt; --&gt;     &lt;/dependencies&gt;      &lt;build&gt;         &lt;plugins&gt;             &lt;plugin&gt;                 &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                 &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;             &lt;/plugin&gt;             &lt;plugin&gt;                 &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                 &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;                 &lt;configuration&gt;                     &lt;nonFilteredFileExtensions&gt;                         &lt;nonFilteredFileExtension&gt;ttf&lt;/nonFilteredFileExtension&gt;                         &lt;nonFilteredFileExtension&gt;woff&lt;/nonFilteredFileExtension&gt;                         &lt;nonFilteredFileExtension&gt;woff2&lt;/nonFilteredFileExtension&gt;                     &lt;/nonFilteredFileExtensions&gt;                 &lt;/configuration&gt;             &lt;/plugin&gt;          &lt;/plugins&gt;     &lt;/build&gt;   &lt;/project&gt; </code></pre>  <p>How do I fix this problem  thank you</p>""",azure-storage
34053720,"Grunt VSO VM MSBuild <p>I've been trying install grunt on the vm for vso task  but for some reason i get an error \null --gruntfile\""</p>  <p>Does any body know from live experience how to install grunt properly?</p>  <p><a href=\""https://i.stack.imgur.com/phi1m.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/phi1m.png\"" alt=\""grunt task\""></a></p>  <p>task setup works fine with hosted but not with my vm. Many thanks for any help</p>""",azure-devops
47430581,"War deployment on Tomcat in AZure Webapp <p>I have a Web app created in Azure App service which have tomcat enabled. Tomcat seems to be running fine. I am able to login to Manager and start war deployment. After the deployment reaches to 100% the page refresh or it actually starts the war deployment  the page displays \The resource you are looking for has been removed  had its name changed  or is temporarily unavailable.\"". </p>  <p>There seems to be some permission problem but not getting how specifically to resolve it.  </p>""",azure-web-app-service
51065229,"Not able to Map Workspace in local folder using VS 2017 <p>I was trying to map workspace  due to some issue I have canceled the process and deleted the entry from Manage Workspace. But when I retried the process  I am getting below error </p>  <pre><code>\The workspace [workspaceName];[Owner] already exists on computer [ComputerName]\"" </code></pre>  <p>I have tried below things to resolve it</p>  <p>1) using VS Command prompt</p>  <pre><code>First display list of workspaces for named computer giving workspace name and owner:  &gt;tf  workspaces /computer:oldComputerName /collection:”http://devsrvr:8080/tfs/DefaultCollection&amp;#8221;    To delete:  &gt;tf workspace /delete WorkSpaceName;OwnerName /collection:”http://devsrvr:8080/tfs/DefaultCollection&amp;#8221; </code></pre>  <p>But listing command is not showing any workspace. so this option dosen't help me. I got the help reference form <a href=\""https://tatvog.wordpress.com/2016/07/27/tfs-the-workspace-already-exists-on-computer/\"" rel=\""nofollow noreferrer\"">here</a></p>  <p>2) Tried Repair Local Visual Studio TFS Workspace Mapping by clearing cache data from <code>%localappdata%\\Microsoft\\Team Foundation\\5.0\\Cache</code>. This option also didn't work for me. I am still getting same error. <a href=\""https://stackoverflow.com/questions/25429753/repair-local-visual-studio-tfs-workspace-mapping\"">Reference</a></p>  <p>3) Checked <code>Control Panel &gt;&gt; User Account &gt;&gt; Mange Password</code> for deleted the enetries (It is used to work with older VS version). But this also didn't work.</p>  <p>Please let me know if any one know the resolution.</p>""",azure-devops
45624262,Azure deploying a web.config file with connection string in plain text <p>The web.config file within my code just contains my local dev database connection string  and when I deploy my web app to Azure  it is correctly taking my database's connection string from the Connection Strings entry within Application Settings on the Portal. However it is then creating and deploying a web.config file with this string in plain text (I can see this if I check the file via FTP).</p>  <p>Is this the correct behaviour? I don't really want the connection string to be stored in plain text within the deployed web.config file (however secure that may already be).</p>  <p>Is it now a case of encrypting that section of the web.config file via some build/deploy step? I have seen this mentioned in other posts but it's unclear how to do it on Azure.</p>  <p>N.B. Apologies if this has already been asked by I've done a lot of searching and just can't find anything referring directly to the final web.config file deployed.  </p>,azure-web-app-service
52404870,AAD Logout Azure Active Directory <p>I deployed a web app in azure with authorization/authentication being set-up. Once you logged in the web app you would be able to get the token using:</p>  <blockquote>   <p>https:{webappname}.azurewebsites.com/.auth/me</p> </blockquote>  <p>then i tried to get the token and used it in postman using AUTHORIZATION header and it worked i was able to access the site with postman using that token. Now my concerns in after i logged out using: </p>  <blockquote>   <p>https:{webappname}.azurewebsites.com/.auth/logout</p> </blockquote>  <p>I can still access the site using the token that i got recently. can someone explain why is this happening.</p>  <p>Thanks :D</p>,azure-web-app-service
51443030,"Node.js/Azure: upload HTML to BlobStorage <p>I have a frontend which sends the HTML of that page to a Node.js server. The server should then send that HTML to Azure BlobStorage.</p>  <p>Here is my express route to handle this:</p>  <pre><code>router.post(\/sendcode\""  function(req  res) {   let code = \""\"";   code = req.body.code;   console.log(code);   let service = storage.createBlobService(process.env.AccountName  process.env.AccountKey);   service.createContainerIfNotExists(\""htmlcontainer\""  function(error  result  response) {     if (error) {       throw error;     } else {       service.createBlockBlobFromStream(\""htmlcontainer\""  code  function(err  result  response) {         if (err) {           throw err;         } else {           console.log(result);           console.log(response);         }       });     }   }); }); </code></pre>  <p>When I call this route  I receive this in my console:</p>  <pre><code>&lt;html&gt;&lt;style&gt;* { box-sizing: border-box; } body {margin: 0;}&lt;/style&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; </code></pre>  <p>How can I send it to BlobStorage? Avoid the method I used as it maybe wrong because I can't figure out what function to use because of scarce documentation.</p>""",azure-storage
50613574,"Azure Durable Functions \Not Found\"" <p>I am trying to run the Microsoft durable functions sample. <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-install\"" rel=\""nofollow noreferrer\"">The article is here</a>. When I run the functions project (C#  Visual Studio) it appears to launch fine  the CLI spins up and I get the Host Initialised and the two start URLs listed. </p>  <pre><code>Http Functions:          HttpStart: http://localhost:7071/orchestrators/{functionName}          HttpSyncStart: http://localhost:7071/orchestrators/{functionName}/wait </code></pre>  <p>However  when I navigate to a function to start it  it tell me \""Not Found\"" e.g. through:</p>  <blockquote>   <p><a href=\""http://localhost:7071/orchestrators/E1_HelloSequence\"" rel=\""nofollow noreferrer\"">http://localhost:7071/orchestrators/E1_HelloSequence</a></p> </blockquote>  <p>I get \""Not Found\"":</p>  <pre><code>[30/05/2018 21:17:40] Executed HTTP request: { [30/05/2018 21:17:40]   \""requestId\"": \""9b82e4b2-c0df-4cf4-a191-ce7d7709d30f\""  [30/05/2018 21:17:40]   \""method\"": \""GET\""  [30/05/2018 21:17:40]   \""uri\"": \""/orchestrators/E1_HelloSequence\""  [30/05/2018 21:17:40]   \""authorizationLevel\"": \""Anonymous\""  [30/05/2018 21:17:40]   \""status\"": \""NotFound\"" [30/05/2018 21:17:40] } </code></pre>  <p>Any idea why this most basic of samples if giving me such a headache? I have tried many different combinations  all to no avail. </p>""",azure-functions
16519922,"Azure RDP using public IP not DNS....? <p>I and unable to RDP Azure VM on my corporate network using \DNS:Port\"" (like vmname.cloudapp.net:3389). It works fine on my home network  which means  endpoints are set correctly.</p>  <p>However  it was possible to RDP VM using Public IP but not anymore. With public IP  I was able to RDP VM on my corporate network  but not sure this has restricted recently?</p>  <p>Any way of to access a VM using Public IP rather DNS:Port format?</p>  <p>Thanks</p>""",azure-virtual-machine
40808441,"Azure Cloud Service (Classic) Staging slot fails to start  and gives no errors <p>I have inherited a project running on Azure's Cloud Service (Classic).  I have a build of the app that  when pushing to the staging slot  will not launch the staging slot. I can find no errors anywhere in the table logs or activity log stating a failure of any kind.  The activity log actually shows <code>Write DeploymentSlots Accepted</code>.  The staging slot sits with blank information.</p>  <p><a href=\https://i.stack.imgur.com/Qnlzc.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Qnlzc.png\"" alt=\""enter image description here\""></a></p>  <p>There is also a \""test\"" environment set up for this app  and the same build pushed to that starts with no issue. As far as I can tell the two environments are identical.</p>""",azure-web-app-service
55249552,"Building an MSI package from Powershell <p>We are setting up a new Azure DevOps pipeline to deploy our (awful) legacy software to our private server. Our goal is to use a modified Git Flow process to build and deploy our software for the Dev  Stage  and then Production (or Release) servers. We are using Cake scripts and Powershell scripts for the building of the different pieces of our software.</p>  <p>One of the requirements from my Software Manager is to build MSI packages for our software (at least for the Production builds when we version a new release). There are two problems that arise from this:</p>  <p>1) Back end software is made up of several projects with all kinds of weird dependencies off of each other (and on external SSIS project which we need to consider as a \black box\"" outside of our project that I have no control over)  and 1 executable which uses most  but not all of the DLLs from the building of the other projects. </p>  <p>The front end software is a Sitecore project which is simply a bunch of DLLs and files that need to be copied from one place to another with an IIS restart to refresh the servers. </p>  <p>The back end and the front end will likely have separate Setup projects. But in each setup project  do I just add in all of the built projects' output to the Application Folder and hope for the best that they all get put in the right output folders on MSI install?</p>  <p>2) How do I instantiate the build of the Setup project (the project which builds the installer) from Cake Build and/or Powershell? I want to make sure this only runs for the Release builds that we build from the master branch. Is there an Azure tool I need to be made aware of.</p>  <p>Please be understanding as this is my first full DevOps implementation  I haven't built an .NET installer package in 10 years since school  and my Powershell skills suck (came from a Web development/Linux world).</p>""",azure-devops
47636141,"Azure Functions: CosmosDBTrigger connection string storage <p>I asked <a href=\https://stackoverflow.com/questions/47625959/cosmosdbtrigger-where-to-specify-connection-string\"">yesterday</a> where to store the connection string for a CosmosDBTrigger. It worked great until I had to push it up to Azure. Now the function isn't working at all. It works locally just fine though. There is no difference between codebases so the only thing I can think of is the connection string isn't be pulled from <code>local.settings.json</code> when on Azure. I mean  it wouldn't surprise me if that was the case since the file has the word <code>local</code> in it.</p>  <p>I tried putting the contents in the <code>host.json</code>  but that didn't work either.</p>  <p>How do you specify the connection string when your Function is running on Azure?</p>""",azure-functions
52317092,Using azure app service deployment slots to run different apps? <p>Deployment slots on azure app service are really intended to run new versions of same app for blue/green deploy strategies. The question I have is it against the rules to run an app with multiple components (front end/back end) to put them into different deployment. On Standard plan  I can load up to 5 services into a single azure app service plan. This would be great as cost saving measure in non prod environments where a single instance of each service is just fine. The question I have is a) is this against the rules? b) are there any pitfalls with this strategy?</p>  <p>Thanks</p>,azure-web-app-service
53679960,"The Pull Request merge commit has unexpected first parent (VSTS) <p>In our system  every PR triggers a PR validation build on a build controller  where:</p>  <ol> <li>The build controller workspace is updated to origin/master</li> <li>The PR is merged</li> <li>The PR merge commit is checked out</li> <li>The build is triggered</li> </ol>  <p>My understanding is that the PR merge commit will have the following two parents:</p>  <ol> <li>origin/master</li> <li>The last commit in the PR</li> </ol>  <p>However  this is not always the case!</p>  <p>Please  observe:</p>  <p><strong>Get Sources build step output</strong></p>  <pre><code>2018-11-27T15:39:21.3096756Z    bf58eb148..b00bf1df0  master               -&gt; origin/master 2018-11-27T15:39:21.3099964Z  * [new ref]             refs/pull/3987/merge -&gt; pull/3987/merge 2018-11-27T15:39:31.3045930Z ##[command]git checkout --progress --force refs/remotes/pull/3987/merge 2018-11-27T15:39:32.8530040Z Previous HEAD position was ce1d1c670... Merge pull request 3982 from wfm/work/pbi476403 into master 2018-11-27T15:39:32.8530496Z HEAD is now at 81317ea59... Merge pull request 3987 from onboarding/476463-Automation_GettingStarted_Performance_Improvements into master </code></pre>  <p>The PR 3987 contains only one commit:</p>  <p><a href=\https://i.stack.imgur.com/qcDJL.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/qcDJL.png\"" alt=\""enter image description here\""></a></p>  <p>From which my logic tells me that:</p>  <ol> <li>At that moment origin/master = b00bf1df0  </li> <li>The local PR merge commit  i.e. pull/3987/merge = 81317ea59</li> <li>The first parent of pull/3987/merge would be origin/master  i.e. b00bf1df0  </li> <li>The second parent of pull/3987/merge would be the last commit of the PR  i.e. b7d9617fc </li> </ol>  <p>Now I will go the build controller and check there:</p>  <p><a href=\""https://i.stack.imgur.com/a2C7k.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/a2C7k.png\"" alt=\""enter image description here\""></a></p>  <p>I see that the first parent is not b00bf1df0  but some other commit 959f488bb.</p>  <p>I do not understand how this is possible. Can anyone explain?</p>""",azure-devops
51408740,Azure Web App FTP 550 Access Denied <p>I am trying to use FTP to upload specific files (not a full release) to an Azure Web App. Essentially I am using a PowerShell script to FTP files up to the web app in Azure. I can add new files  create files and folders but when I try to overwrite or delete a file  I get a 550 Access is denied. </p>  <p>I tried creating a a new deployment credential and was able to log in but the result was the same when trying to delete anything; 550 Access is Denied. </p>  <p>Is there any way to grant more permissions to this user or is this impossible? Thanks! </p>,azure-web-app-service
48437609,How to let docker container log output sdb disk in Azure cloud <p>Currently  my cloud environment based on Azure cloud and the VM type is D3V2(14G/200G)  Azure VM provide OS disk called sda that has 30 GB  and Ephemeral disk called sdb that has 200 GB. My container orchestration is based on mesos/marathon  all containers logs output to sda not sdb  so after several days  the disk space is full. How to utilize the sdb disk and let the logs can output to sdb?</p>  <p>following is output of <code>df -k</code> in my VM:</p>  <pre><code>root@dcos-agentprivate-service000003:/home/test# df -k Filesystem     1K-blocks    Used Available Use% Mounted on udev             7155096       0   7155096   0% /dev tmpfs            1435028  134880   1300148  10% /run /dev/sda1       30428648 7590548  22821716  25% / tmpfs            7175128       0   7175128   0% /dev/shm tmpfs               5120       0      5120   0% /run/lock tmpfs            7175128       0   7175128   0% /sys/fs/cgroup overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/2f479dc1d57d3ef848f957ae4b1751dc68eafab44249aa2028492eb44491ba9a/merged shm                65536       0     65536   0% /var/lib/docker/containers/6301aefde9113502687503e77e65ce6bb8c2d39eb678944c10a41198cbd58e74/shm overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/89ce9ca51728b61d29778131a7f2e6b859cba6b70b1777664d62b5154f741ac8/merged shm                65536       0     65536   0% /var/lib/docker/containers/5bb83ee7bd75b92c16044d03b216754e127ca9d53eb3fb17df88f881f7928f79/shm overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/4986839f2046dab76caacea057590af338433dda133165920facf8b62901bbf4/merged shm                65536       0     65536   0% /var/lib/docker/containers/58eb5ae765785d35941133607e9667214c65a89743325767755b4ff3f4a89e27/shm overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/ca68a2ce6c4b35a0efc2d8d5748e295686402f195b62bcf5aeb5e0b7b0d8af6c/merged shm                65536       0     65536   0% /var/lib/docker/containers/619b5dac97338672669420f9aec7cd72b83ed2cd170d0f3f98ca8bdc4a139d77/shm overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/b1e4f59da0d59d1cfff6725827dad8da1bc80913c37be8b3468bcd103a781c53/merged shm                65536       0     65536   0% /var/lib/docker/containers/5127f81741c87759df9865a417beaf2c8d09871680b6de66b5e3cbe51385354d/shm overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/65a999e7d61d67384db9e955cf55a363129d124dc5385fe38ccd0688053239f2-init/merged overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/8356b0e83f436e02a7445cdc1a89286cdd731f57826dccf98f4e46b006f430e0-init/merged overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/28eecf196b970f824e72bdf000a6da4725be3408ec47d3c6477054e39c12167f-init/merged overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/3c12ab53b60588bba34b96eca8591ec063bc9072ac925b6e8f2d1e9f62492583-init/merged overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/465eb669a1bc191e9a798636b5441ccdc4d9f414063cd9a83c3921a633e8c2c5-init/merged overlay         30428648 7590548  22821716  25% /var/lib/docker/overlay/7210916bf5ffe265223c71d902e9c34ab8a1489655470cba94b7d6a8d5123991-init/merged tmpfs            1435028       0   1435028   0% /run/user/1000 </code></pre>,azure-virtual-machine
52470234,"View TraceWriter.Info() logs in Azure Function without Application Insights <p>My Azure Function app uses the TraceWriter.Info() method to write logs. Very simple to use and it used to be very simply to view:</p>  <pre><code>public static void Run([TimerTrigger(\0 0 22 * * *\""  RunOnStartup = false)]TimerInfo myTimer  TraceWriter log) {    log.Info(\""My log!\""); } </code></pre>  <p>However  now when I go to the portal and click the \""Monitor\"" tab  which used to show the output in a console-like window  it demands that I setup Application Insights whilst giving me an error:</p>  <p><a href=\""https://i.stack.imgur.com/kBuv9.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/kBuv9.png\"" alt=\""enter image description here\""></a></p>  <p>I cannot click the \""Configure\"" button to set it up. As far as I know my app specifies nothing about Application Insights  yet the error seems to suggest that it does.</p>  <p>My questions:</p>  <ul> <li>Is it possible to get the old console window back?</li> <li>Failing that  why can I not configure app insights?</li> </ul>""",azure-functions
56434124,"Deploy console webjob app to azure App service containing a webapi using azure devops pipelines <p>I have 2 webAPI’s written in .net core 2.2.The 2 web api’s are triggered by web jobs which are console Apps in .netcore 2.2. They are all different projects and in different repositories in Azure DevOps.</p>  <p>I am trying to deploy the web Api's together with the webjob into 2 web app services(eg: WebApi1 + Web job1 into App service1 and WebApi2 + Web job2 into App service2) in Azure using the Azure DevOps build and release pipelines. </p>  <p>I am able to add the webjobs manually into App Service from Azure portal and it works fine.But I want to deploy it using Azure DevOps pipelines.</p>  <p>I tried different ways to publish the web jobs(console apps) with the web api in the app service  like trying to publish it to App_Data folder from Azure DevOps.</p>  <p>I mainly followed the blog below.</p>  <p><a href=\https://www.andrewhoefling.com/Blog/Post/deploying-dotnet-core-webjobs-to-azure-using-azure-pipelines\"" rel=\""nofollow noreferrer\"">https://www.andrewhoefling.com/Blog/Post/deploying-dotnet-core-webjobs-to-azure-using-azure-pipelines</a></p>  <p>But when I try to publish the webjob it overwrites the web api code(all the 4 projects have seperate build/release pipelines). The webjob code gets deployed in the site/wwwroot folder rather than the site/job folder.</p>  <p><a href=\""https://i.stack.imgur.com/FSYp9.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/FSYp9.png\"" alt=\""enter image description here\""></a></p>  <p><strong>My Build steps:</strong></p>  <p><a href=\""https://i.stack.imgur.com/MBFdu.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/MBFdu.png\"" alt=\""enter image description here\""></a> <a href=\""https://i.stack.imgur.com/2gcfT.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/2gcfT.png\"" alt=\""enter image description here\""></a></p>  <p><strong>My Release steps:</strong></p>  <p><a href=\""https://i.stack.imgur.com/RxAtZ.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/RxAtZ.png\"" alt=\""enter image description here\""></a></p>  <p>I am not sure what I am doing wrong. Is there a way to copy the webjobs files into the same app service without overwritting the actual webapi code?</p>""",azure-devops
57215531,"Coverage status check failed? <p>I committed the changes to the pull request and yt shows </p>  <blockquote>   <p>\Code coverage status failed.\"". </p> </blockquote>  <p>I have searched a lot  but couldn't find the cause or solution to resolve this. </p>  <pre><code>Azure pipeline test service  Diff coverage check failed.0/70 (0.00 %) changed lines are covered up to update 2. Diff coverage target is 70.00 %.  </code></pre>  <p>Verification build is successful but the status is showing code coverage has failed.</p>""",azure-devops
55580436,"Restrict invocation of Azure functions to portal and timers <p>I'm trying to clear the following recommendation from the Azure portal:</p>  <p><a href=\https://i.stack.imgur.com/neRR2.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/neRR2.png\"" alt=\""Restrict access to App Services (Preview)\""></a></p>  <p>The App Services in question only exist to host Functions  and those functions are only called by a timer (or  if done manually  through the portal). I don't need them open to the wider internet at all  but I <em>do</em> need them visible to the Azure portal itself.</p>  <p>The only settings I see  though  are <a href=\""https://docs.microsoft.com/en-us/azure/app-service/app-service-ip-restrictions\"" rel=\""nofollow noreferrer\"">IP-based</a>. Is there a specific set of IPs to whitelist for the Azure portal and timers to still work? (I tried \""deny-all\""  but then I get a message on the function overview page saying \""Access restrictions have been added to your function app which may affect your ability to manage it from the portal.\"")</p>""",azure-functions
4494040,"Azure: How to create the WADLogsTable for capturing diagnostics code? <p>I have a worker role that I would like to get diagnoistics feedback on... after adding the appropriate connection string to the ServiceConfiguration.cscfg and the following code:</p>  <pre><code>//DiagnosticMonitor.Start(\DiagnosticsConnectionString\""); DiagnosticMonitorConfiguration diagConfig = DiagnosticMonitor.GetDefaultInitialConfiguration(); diagConfig.WindowsEventLog.DataSources.Add(\""Application!*\""); diagConfig.WindowsEventLog.ScheduledTransferPeriod = System.TimeSpan.FromMinutes(5.0); diagConfig.Logs.ScheduledTransferPeriod = System.TimeSpan.FromMinutes(5.0);  Microsoft.WindowsAzure.Diagnostics.DiagnosticMonitor.Start(\""DiagnosticsConnectionString\""  diagConfig); CrashDumps.EnableCollection(true); </code></pre>  <p>When I call \""System.Diagnostics.Trace.TraceInformation(\""test log\"") I expect to be able to find the record in the WADLogsTable of the target Azure Storage Account.  Howver  the table doesn't exist- how is it created?  None of the documentation I've read covers this.<br> Thanks in advance </p>""",azure-storage
51749573,Does Azure Storage Emulator Support File Shares? <p>I have the Azure Storage Emulator running but it currently looks like (as of v5.6.0.0) that it only supports Blob  Queue  and Table storage:</p>  <p><code> BlobEndpoint: http://127.0.0.1:10000/ QueueEndpoint: http://127.0.0.1:10001/ TableEndpoint: http://127.0.0.1:10002/ </code></p>  <p>The confusing part is when you configure a local connection via the desktop Azure Storage Explorer by selecting <code>Attached to a local emulator</code>  there's an option for Files port.</p>  <p>Am I missing something here?</p>,azure-storage
52271088,Execute python scripts in Azure DataFactory <p>I have my data stored in blobs and I have written a python script to do some computations and create another csv. How can I execute this in Azure Data Factory ?</p>,azure-storage
54929065,PersistKeysToAzureBlobStorage(): Is there an equivalent Method for .Net Framework 4.6/4.x Applications? <p>Is there an equivalent method  to the.Net Core PersistKeysToAzureBlobStorage() method  which is available for .Net Framework 4.6 applications?</p>  <p>I have a .Net Framework 4.6 MVC app  and would like to persist the encryption key  used for cookie encryption/decryption  to an Azure container.  I've found that this can be done for .Net Core applications  but need to do the same in a .Net Framework 4.6 app. </p>,azure-storage
55724970,"Azure build pipeline yaml template reference <p>I have a step defintion template  that I intend to use within build pipelines.  The step definition's location is not under the same folder as the build pipeline itself. </p>  <p>During the validation of the pipeline  AzureDevops considers build pipeline's location as the root location. This is appended to the path of the reference</p>  <p>consider the following example of code hierarchy</p>  <pre><code> azure    |----products            |----resource-type1                         |----step-def.yaml            |----resource-type2                         |----step-def.yaml    |----solutions            |----solution1                     |----local-step-def.yaml                     |----build.yaml            |----solution2                     |----build.yaml </code></pre>  <p>Following works when the build.yaml is as below</p>  <pre><code>jobs: - job: Linux   pool:     vmImage: 'ubuntu-16.04'   steps:   - template: solution1/local-step-def.yml </code></pre>  <p>If you change the template reference as below  it does not work</p>  <pre><code>  - template: ../products/resource-type1/step-def.yml </code></pre>  <p>When validation is done on the pipeline  azure-devops maps to</p>  <pre><code># &lt;path-of-the-build-pipeline&gt;/&lt;template-ref&gt; azure/solutions/solution1/&lt;template-reference&gt; </code></pre>  <p>Here is the documentation  <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops#step-re-use\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops#step-re-use</a> </p>  <p>So how can I map to the step-def.yaml file that lives in the products folder hierarchy?</p>""",azure-devops
45436313,How to migrate code from TFS 2012 to Visual Studio team services? <p>We are planning to migrate from tfs 2012 to VSTS  wanted to check if there is any method that can be used to migrate the source code that is in in TFS to VSTS (either GIT or TFVC)?</p>  <p>Many Thanks </p>,azure-devops
48429494,"Move DevTest Lab VM to another DevTest Lab <p>I'm trying to move a VM custom image from one DevTest Lab to another and can't seem to find an easy way to accomplish that. My VM is using managed disks and also has a data disk.</p>  <p>I've read the following article <a href=\https://azure.microsoft.com/en-us/updates/azure-devtest-labs-changes-in-exporting-custom-image-vhd-files/\"" rel=\""nofollow noreferrer\"">https://azure.microsoft.com/en-us/updates/azure-devtest-labs-changes-in-exporting-custom-image-vhd-files/</a> and it states that </p>  <blockquote>   <p>Azure DevTest Lab now generates a managed image and \""<em>…This allows   Sysprep'ed/deprovisioned custom images to support data disks in   addition to the OS disk through a single image.</em>\""</p> </blockquote>  <p>This is fine but the image that is created can't be exported. </p>  <p>Is it even possible to accomplish  am I missing something?</p>  <p>Thanks for your help</p>""",azure-virtual-machine
49887807,What is the bandwidth of a Standard B1ms Virtual Machine? <p>I cannot find any documentation on what is the bandwidth of a Standard B1ms machine.. if you have any info  please share. </p>,azure-virtual-machine
55580136,"How to get the Azure function app operationid in my .netcore code <p>I have created .netcore 2.0 Azure Function App for Linux. Can i get the below operationId in my code. For tracking purpose we need this. While logging exception we want to include this operationId also  in my .net core code.  <a href=\https://i.stack.imgur.com/PMn8n.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/PMn8n.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
39637572,"Automatically generated region certificate in Azure <p>In Azure portal when I get the list of all resource I can see a machine-generated resource of type Microsoft.Web/certificates which I (as Admin) cant view the details. At what point does this resource gets created and is this region specific? The reason I ask about the region is that its name contains the name of the region itself. If that is region specific then I should have two of these automatically generated certificates because I have resources in two region. Could this resource have been generated by visual studio publishing tool? How can I know more about this resource?</p>  <p><a href=\https://i.stack.imgur.com/Q3c5k.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Q3c5k.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
50113731,"read image path from file share and store in table storage azure <p>I'm able to upload the image in the Azure file share using below code. </p>  <pre><code>CloudStorageAccount cloudStorageAccount = ConnectionString.GetConnectionString();             CloudFileClient cloudFileClient = cloudStorageAccount.CreateCloudFileClient();                          CloudFileShare fileShare = cloudFileClient.GetShareReference(\sampleimage\"");            if (await fileShare.CreateIfNotExistsAsync())             {                 await fileShare.SetPermissionsAsync(                     new FileSharePermissions                     {                      });             }             //fileShare.CreateIfNotExists();              string imageName = Guid.NewGuid().ToString() + \""-\"" + Path.GetExtension(imageToUpload.FileName);             CloudFile cloudFile = fileShare.GetRootDirectoryReference().GetFileReference(imageName);             cloudFile.Properties.ContentType = imageToUpload.ContentType;              await cloudFile.UploadFromStreamAsync(imageToUpload.InputStream);              imageFullPath = cloudFile.Uri.ToString();         }         catch (Exception ex)         {          }         return imageFullPath; </code></pre>  <p>Here is how I'm trying to read the file path: [Before insertinginto a table]</p>  <pre><code>public class ReadFileSharePath {     string Path = null;     public string ReadFilePath()     {          try         {             CloudStorageAccount cloudStorageAccount = ConnectionString.GetConnectionString();             CloudFileClient cloudFileClient = cloudStorageAccount.CreateCloudFileClient();             CloudFileShare fileShare = cloudFileClient.GetShareReference(\""sampleimage\"");             if (fileShare.Exists())             {                 CloudFileDirectory rootdir = fileShare.GetRootDirectoryReference();                  CloudFileDirectory sampleDir = rootdir.GetDirectoryReference(\""sampleimage\"");                  if (sampleDir.Exists())                 {                     // Get a reference to the file we created previously.                     CloudFile file = sampleDir.GetFileReference(\""90e94676-492d-4c3c-beb2-1d8d48044e4e-.jpg\"");                      // Ensure that the file exists.                     if (file.Exists())                     {                         // Write the contents of the file to the console window.                         //Console.WriteLine(file.DownloadTextAsync().Result);                         Path = file.DownloadTextAsync().Result.ToString();                     }                 }             }          }         catch (Exception)         {              throw;         }         return Path;      }  } </code></pre>  <p>However  this if condition  </p>  <blockquote>   <p>if (sampleDir.Exists()) </p> </blockquote>  <p>is getting failed.And  the control is not entering into loop.</p>  <p>I would like to store the path of file share in the Azure table storage. I would like to get partition key and row key. How to achieve this ? any link or suggestion would help? Thanks.</p>""",azure-storage
57374193,"Not able to run blob trigger when published on azure functions <p>I have created a simple blob trigger in visual studio for which <strong>init</strong>.py is as below </p>  <pre><code>import logging  import azure.functions as func   def main(myblob: func.InputStream):    logging.info(f\Python blob trigger function processed blob \\n\""              f\""Name: {myblob.name}\\n\""              f\""Blob Size: {myblob.length} bytes\"") </code></pre>  <p>and function.json is as below</p>  <pre><code>{   \""scriptFile\"": \""__init__.py\""    \""bindings\"": [      {       \""name\"": \""myblob\""        \""type\"": \""blobTrigger\""        \""direction\"": \""in\""        \""path\"": \""mycontainer/{name}\""        \""connection\"": \""AzureWebJobsStorage\""      }     ] } </code></pre>  <p>local.settings.json looks as below</p>  <pre><code>{   \""IsEncrypted\"": false    \""Values\"": {   \""FUNCTIONS_WORKER_RUNTIME\"": \""python\""    \""AzureWebJobsStorage\"": \""DefaultEndpointsProtocol=https;  AccountName=****;AccountKey=*****;EndpointSuffix=core.windows.net\""    } } </code></pre>  <p>This code works fine with visual studio on local machine. But when published on azure portal it can not read blob path from function.json and gives error as </p>  <pre><code>Invalid blob path specified : ''. Blob identifiers must be in the format 'container/blob'. </code></pre>  <p>I have published function using command to push contains of local.settings.json. </p>  <pre><code>func azure functionapp publish FUNCTIONNAME --build-native-deps --publish-local-settings -i </code></pre>  <p>. Can anyone please guid me what I am missing after publishing.</p>""",azure-functions
43543108,"integrate webapp with Azure VNET <p>I have deployed a Web app in Azure and is available in <a href=\http://XXX.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://XXX.azurewebsites.net</a>. I would like to limit the access to this site by placing the web app in the Virtual Network using Point to Site.</p>  <p>I have created a VNET and successfully established the Point to site connection. Then i have integrated the Webapp to the created VNET. </p>  <p>Now Clients who dont have client certificate also able to access the site/URL. how to restrict that?</p>  <p>My Expected Behaviour is Clients whoever have the client certificate and vpn client package can access the site using the above url. Others should not be able to access the site using \""XXX.azurewebsites.net\"" url.</p>  <p>Please help me in achieving this.</p>""",azure-web-app-service
49641086,Use and setup of WAF with Azure App Service Web Application? <p>I run a number of App Service MVC Asp.Net web applications. I think it would be a good idea to add a WAF to the front the App Service website to enable OWASP protection as well as more visibility on suspicious attacks. Also I would want this to be linked into Azure Security Centre. </p>  <p>As far as I can see this is not a problem with VM websites  but with App Service websites I have seen SO comment (April 2017) about how this may not be supported. Although this information may be outdated now.</p>  <p>1)  Am I just trying to replace existing threat detection features that is built into App Services  so adding a WAF is not required?</p>  <p>2) If required  is App Service WAFs supported  and especially linked to Azure Security Centre.</p>  <p>3) If required and possible  then any pointers please?</p>  <p>By the way  I have considered the use of Cloudflare as a WAF wrapper around Azure which looks interesting  but intitially wanted to check out Azure functionality to start with.</p>  <p>Thanks.</p>,azure-web-app-service
52049238,"Azure Storage Service Rest APIs: Constructing Signature String(stringToSign) dynamically with the given URI input in java <p>Is there a way to construct a <strong>stringToSign</strong> String dynamically for any given azure storage rest API with the given URI input in java?</p>  <p><a href=\https://docs.microsoft.com/en-us/rest/api/storageservices/authorize-with-shared-key\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/storageservices/authorize-with-shared-key</a></p>""",azure-storage
55286747,Python Memcached  connect to Azure VM server <p>I have installed Memcached on an Azure VM server (Ubuntu). I now need to connect to this from my Python program that runs elsewhere.</p>  <p>When they were installed on the same server  this worked:</p>  <pre><code>import memcache MEMCACHE_SOCKET_PATH = 'unix:&lt;path_to&gt;/memcached.sock'   memcache_client = memcache.Client([MEMCACHE_SOCKET_PATH]  debug=0) </code></pre>  <p>Now I'm not sure what to use for MEMCACHE_SOCKET_PATH. The VM running Memcached has a static IP address and I have created an endpoint (opened a port) to 11211. memcached.sock sits in the home directory.</p>  <p>This is how I am running Memcached on the VM:</p>  <pre><code>memcached -d -m 500 -s $HOME/memcached.sock -P $HOME/memcached.pid </code></pre>,azure-virtual-machine
51542507,How to extract filename and other properties from multipart form data prior to uploading file to azure <p>I want to extract the and set the filename based on application logic on server prior to uploading file to azure..</p>  <p>My current scenario: Client -> Application Web Api -> Azure Storage</p>  <p>Following is code:</p>  <pre><code>public async Task&lt;IHttpActionResult&gt; UploadProfilePic()     {         if (!Request.Content.IsMimeMultipartContent())         {             throw new HttpResponseException(HttpStatusCode.UnsupportedMediaType);         }          AzureStorageCls = new MyAzureStorage(WebApiApplication.AllowedImageExtensions);  //Need to set file name based on custom logic prior to upload of image  //Below method calls the  pRequest.Content.ReadAsMultipartAsync(provider) of custom MultipartStreamProvider         BlobStorage BlobImage = await AzureStorageCls.UploadImageToAzure(modifiedFileName  Request);          return Ok();      } </code></pre>  <p>We want to customize the file name that we send to azure blob storage based on ids</p>  <p>But as i know now we can get all properties only after calling ReadAsMultipartAsync(provider) in provider.</p>  <p>I am sure there must be a simpler way to solve this that I am unaware of</p>  <p>Any help will be highly appreciated. Thanks in advance</p>,azure-storage
50031391,"asp.net-core-signalr can't stay connected for more than a minute or so <p>Just upgraded our app service from .net 4.6 to .net core. Part of that migration was to upgrade to the new .net core version of SignalR. Everything was working fine while running locally  but when it was published to an azure app service  the connection doesn't stay connected for more than a minute (usually less than 30 seconds). The error that I'm seeing in the console logs is:</p>  <p>Error: Connection disconnected with error 'Error: Websocket closed with status code: 1006 ()'.</p>  <p>Has anyone else experienced this before? I ran across <a href=\https://stackoverflow.com/questions/48397181/asp-netcore-signalr-not-work-on-aws\"">this post</a>  but it has very little feedback. Not sure if it has the same root cause or not.</p>""",azure-web-app-service
56430949,"Error \No file format header found\"" when building Cloud Service (ccproj) project in Visual Studio with Azure Pipelines <p>I was recently trying to set up CI for a Cloud Service project. It builds fine in Visual Studio 2017 and 2019. However  when MSBuild is called to run it in Azure DevOps / ADO  I get the following build error:</p>  <p>\""No file format header found\""</p>  <p>Well that's annoying! Initially I thought it was a BOM issue  or an XML issue. Fixing that didn't work. Then I found some articles here about NuGet causing issues  but that wasn't it  either.</p>  <p>Here's my build step:</p>  <p><code> - task: VSBuild@1   displayName: 'Build Worker Cloud Service - INT'   inputs:   solution: '**\\MyService.ccproj'   msbuildArgs: '/t:Publish /t:restore /p:SkipInvalidConfigurations=true /p:BclBuildImported=Ignore /p:OutputPath=bin\\ /p:PublishDir=$(build.artifactstagingdirectory)\\appcloud\\Provisioning.QA /p:TargetProfile=QA'     platform: '$(BuildPlatform)'     configuration: '$(BuildConfiguration_Release)'     restoreNugetPackages: true </code></p>""",azure-devops
45281935,Monitoring the Azure app services <p>I was wondering if someone can shed some lights on the application monitoring and alerting solution that's being used to specifically monitor the Azure app service. We have multiple API apps running on App service service and we would like to monitor certain metrics (ex: Availability  response time  number of request received  etc). I enabled the application insight on each of these apps and the result is quite promising  it fulfills all my requirement  but there's one small issue: I need to scroll through each app to see their performance. I can't aggregate them all in one space. I would like to create a centralized dashboard for all aforementioned metrics and have them displayed. I tried using OMS but it seems to be lacking a lot of functionality.</p>  <p>Any pointer would be very appreciated.</p>,azure-web-app-service
29496567,replication with SQL AZure from Azure VM <p>Is it possible to configure replication that can transfer data from SQL Azure DB to AZURE VM with SQL Server?</p>  <p>Basically  i want to move Transactional data from Sql AZURE to local server in Azure VM where SQL Server Standard is installed. I use SSRS From the Server on Azure VM and want to run reports from this data source.</p>  <p>We tried to configure the Geo Replication for SQL Azure DB but unless it is a Premium DB (Which is expensive) we can not decide region for the Secondary database. By default Azure uses North for South region and similar which will make the reports run very slow.</p>,azure-virtual-machine
19655868,"Streaming video from Azure blob storage <p>I'm having problems getting an <code>.mp4</code> video stored in Azure blob storage to show in a website hosted on Azure. The video type is set to <code>video/mp4</code>  the storage account is not public  but it is linked to the web role  and I've updated the version using this bit of code:</p>  <pre><code>var credentials = new StorageCredentials(\myaccountname\""  \""mysecretkey\"");  var account = new CloudStorageAccount(credentials  true);  var client = account.CreateCloudBlobClient();  var properties = client.GetServiceProperties();  properties.DefaultServiceVersion = \""2012-02-12\"";  client.SetServiceProperties(properties);  </code></pre>  <p>I'm not using any video player  just the HTML5 video tag. I also don't need anything fancy  I just want the video to play.</p>  <p>Looking at the network tab in Chrome's dev tools  there are two entries for the <code>GET</code> request to fetch the video. The first one has a status of <code>(pending)</code> and the next one is <code>(canceled)</code>. </p>  <p>I also gave it a link to a video which is in the website's content folder. This one also starts as <code>pending</code> but is resolved with a <code>204 Partial Content</code> and the video plays just fine.</p>  <p>I'm out of stuff to look at  and any help and pointers are appreciated.</p>""",azure-storage
57520028,"How to use different Service Connection for every stage in Azure Pipelines? <p>When using <a href=\https://devblogs.microsoft.com/devops/whats-new-with-azure-pipelines/\"" rel=\""nofollow noreferrer\"">multistage pipelines</a> from yaml in Azure Pipelines and every stage is deploying resources to a separate environment  I'd like to use a dedicated service connection for each stage. In my case every stage is making use of the same deployment jobs  i.e. yaml templates. So I'm using a lot of variables that have specific values dependent on the environment. This works fine  except for the service connection.</p>  <p>Ideally  the variable that contains the service connection name  is added to the stage level like this:</p>  <pre><code>stages: - stage: Build     # (Several build-stage specific jobs here)  - stage: DeployToDEV   dependsOn: Build   condition: succeeded()   variables:     AzureServiceConnection: 'AzureSubscription_DEV' # This seems like a logical solution   jobs:     # This job would ideally reside in a yaml template     - job: DisplayDiagnostics       pool:         vmImage: 'Ubuntu-16.04'       steps:         - checkout: none         - task: AzurePowerShell@4           inputs:             azureSubscription: $(AzureServiceConnection)             scriptType: inlineScript             inline: |               Get-AzContext             azurePowerShellVersion: LatestVersion  - stage: DeployToTST   dependsOn: Build   condition: succeeded()   variables:     AzureServiceConnection: 'AzureSubscription_TST' # Same variable  different value   jobs:     # (Same contents as DeployToDEV stage) </code></pre>  <p>When this code snippet is executed  it results in the error message:</p>  <blockquote>   <p>There was a resource authorization issue: \""The pipeline is not valid.   Job DisplayDiagnostics: Step AzurePowerShell input   ConnectedServiceNameARM references service connection   $(AzureServiceConnection) which could not be found. The service   connection does not exist or has not been authorized for use. For   authorization details  refer to <a href=\""https://aka.ms/yamlauthz\"" rel=\""nofollow noreferrer\"">https://aka.ms/yamlauthz</a>.</p> </blockquote>  <p>So  it probably can't <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&amp;tabs=yaml%2Cbatch#expansion-of-variables\"" rel=\""nofollow noreferrer\"">expand the variable</a> <code>AzureServiceConnection</code> soon enough when the run is started. But if that's indeed the case  then what's the alternative solution to make use of separate service connections for every stage?</p>  <p>One option that works for sure is setting the service connection name directly to all tasks  but that would involve duplicating identical yaml tasks for every stage  which I obviously want to avoid.</p>  <p>Anyone has a clue on this? Thanks in advance!</p>""",azure-devops
53060229,"Azure DevOps Extension custom service endopint for ID/KEY <p>I am developing Azure DevOps extension which contain service endpoint to hold secret ID/KEY. My requirement is to have endpoint just consist of Connection name  ID  and Key in it.I have gone trough list of provided endpoints in Microsoft but I couldn't find suitable option to satisfy my requirement.</p>  <p><a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/library/service-endpoints?view=vsts#sep-ssh\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/library/service-endpoints?view=vsts#sep-ssh</a></p>  <p>closest solution I found is as below . But it contains input box for server URL(Which I need to omit (in this example though I don't define server URL it displays in popup dialog)). Please refer below image.</p>  <p><a href=\""https://i.stack.imgur.com/IaJGg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/IaJGg.png\"" alt=\""enter image description here\""></a></p>  <p>Is it possible to remove Server URL from above dialog box Or it there better endpoint type I can use for this requirement? please be kind enough to share some light with me.</p>""",azure-devops
48075879,"How can I add one more property using c# into existing json object inside Azure Functions? <p>Inside the <code>Azure function</code> my <code>input is ServiceBus queue properties</code></p>  <p>Code is to retrieve that all properties are - </p>  <pre><code>using System.Net; using Newtonsoft.Json;  public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequestMessage req  TraceWriter log) {   string jsonContent = await req.Content.ReadAsStringAsync();      return req.CreateResponse(HttpStatusCode.OK jsonContent); } </code></pre>  <p>Output is -</p>  <pre><code>[     \{\\\""DeliveryCount\\\"":\\\""1\\\"" \\MessageId\\\"":\\\""bac52de2d23a487a9ed388f7313d93e5\\\""}\"" ] </code></pre>  <p>I want to add one more property into this json object   how can I add it here in azure function so that I can return modified object like below - </p>  <pre><code>[     \""{\\\""DeliveryCount\\\"":\\\""1\\\"" \\MessageId\\\"":\\\""bac52de2d23a487a9ed388f7313d93e5\\\"" \\\""MyProperty\\\"":\\\""TEST\\\""}\"" ] </code></pre>""",azure-functions
48517386,Which Reports can deploy in Azure Standard Website Plan? <p>I want to know  is there any reporting tool available which supports in Azure App/Web service?</p>  <p>As per my reading  for SSRS its compulsory required Virtual Machine. Crystal Reports also cannot be working with Azure App/Web Service?</p>  <p>I don't want to take other service like Power BI or Virtual Machine to run report. So please guide me is there any solution for the same?</p>  <p>Thanks</p>,azure-web-app-service
46114240,"Download Azure VHD to local use powershell <p>How can I download azure vhd with powershell to local machine?</p>  <p>I read the document  but I can't find the blob url like \<a href=\""https://XXX.blob.core.windows.net/vhds/XXX.vhd\"" rel=\""nofollow noreferrer\"">https://XXX.blob.core.windows.net/vhds/XXX.vhd</a>\""</p>  <p>Anybody know that?</p>  <p>Thanks</p>""",azure-virtual-machine
50707153,"Azure Managed Disk not showing when trying to attach to VM <p>I have a premium Azure Managed Disk (SSD) in the same region as a Windows VM  but when I go to attach it via the Azure portal (settings -> Disks -> + Add data disk) the drop down under name says \No managed disk available\"" (see below). What do I need to do?</p>  <p><a href=\""https://i.stack.imgur.com/1uX4h.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/1uX4h.png\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
45570201,Azure create data disk and copy files to it <p>Is it possible to create a data disk  copy files to it  and then attach it to an existing virtual machine on Azure? What would be the broad steps for this to work?</p>,azure-virtual-machine
19541198,"Clipboard/file sharing support in Ubuntu virtual machines on Azure <p>I've created a new <strong>Ubuntu 12.04</strong> virtual machine on Azure. Then using </p>  <pre><code>$ sudo apt-get install ubuntu-desktop  $ sudo apt-get install xrdp </code></pre>  <p>installed the standard Ubuntu and <strong>xrdp</strong> which implements the RDP protocol.</p>  <p>Going to Azure portal and downloading *.rdp file then logging </p>  <p><img src=\https://i.stack.imgur.com/O8SXU.jpg\"" alt=\""enter image description here\""></p>  <p>with the following check boxes still doesn't enable clipboard. </p>  <p><img src=\""https://i.stack.imgur.com/5GUvU.jpg\"" alt=\""enter image description here\""></p>  <p><img src=\""https://i.stack.imgur.com/7r4v0.jpg\"" alt=\""enter image description here\""></p>  <p>I've found several reference that suggest installing <a href=\""http://scarygliders.net/2013/10/11/x11rdp-o-matic-version-3-01-now-released/\"" rel=\""nofollow noreferrer\""><strong>X11RDP</strong></a> but i really don't want to unless there is no other option.</p>  <p>Also it seems that </p>  <blockquote>   <p>Text clipboard in xrdp works with certain restrictions.</p> </blockquote>  <p>Am I missing something or copy/pasting files  text is not supported?</p>""",azure-virtual-machine
55948976,"How to get the filepath while uploading a file to azure-storage in django <p>I have a form in which files can be uploaded. the uploaded file has to be stored in azure-storage. I am using create_blob_from_path to upload a file to azure-storage.create_blob_from_path  expects file path as one of the parameters. but how can I get file path in this case as the operation has to be in on the fly mode(The uploaded file cannot be stored in any local storage).it should get stored directly in Azure.</p>  <pre><code>if request.method==\POST\"":     pic=request.FILES['pic']     block_blob_service = BlockBlobService(account_name='samplestorage'  account_key='5G+riEzTzLmm3MR832NEVjgYxaBKA4yur6Ob+A6s5Qrw==')     container_name ='quickstart'     block_blob_service.create_container(container_name)             block_blob_service.set_container_acl(container_name  public_access=PublicAccess.Container)     block_blob_service.create_blob_from_path(container_name  pic  full_path_to_file)//full_path_to_file=? </code></pre>  <p>the file uploaded dynamically has to be stored in Azure</p>""",azure-storage
41149423,"Avoid over-writing blobs AZURE on the server <p>I have a .NET app which uses the WebClient and the SAS token to upload a blob to the container. The default behaviour is that a blob with the same name is replaced/overwritten. </p>  <p>Is there a way to change it on the server  i.e. prevents from replacing the already existing blob?</p>  <p>I've seen the <a href=\https://stackoverflow.com/questions/16958629/avoid-over-writing-blobs-azure\"">Avoid over-writing blobs AZURE</a> but it is about the client side. </p>  <p>My goal is to secure the server from overwritting blobs.</p>  <p>AFAIK the file is uploaded directly to the container without a chance to intercept the request and check e.g. existence of the blob.</p>  <p><em>Edited</em></p>  <p>Let me clarify: My client app receives a SAS token to upload a new blob. However  an evil hacker can intercept the token and upload a blob with an existing name. Because of the default behavior  the new blob will replace the existing one (effectively deleting the good one).</p>  <p>I am aware of different approaches to deal with the replacement on the client. However  I need to do it on the server  somehow even against the client (which could be compromised by the hacker).</p>""",azure-storage
47191570,Azure: Provisioning of virtual machine fails. <p>I am trying to provision Azure Virtual Machines to the same availability set one after the other. I see this error when trying to a provision in Australia East. </p>  <pre><code> Provisioning failed. Allocation failed. Please try reducing the VM size or   number of VMs  retry later  or try deploying to a different Availability Set   or different Azure location.. AllocationFailed </code></pre>,azure-virtual-machine
51072365,"Azure Function (ServiceBus) System.Private.CoreLib Error (Works locally) <p>When I run my Azure functions locally they work like a charm. But when I publish and run them in the cloud I get following error:</p>  <blockquote>   <p>[Error] System.Private.CoreLib: Exception while executing function: Alert. Function.PowerBI: Abandom message in AzureFunction.PowerBi.</p> </blockquote>  <p>Running a function called Alert in a Function called PowerBi. Is there a way  maybe in Kudu to see the actually error or how should i interpret an error in </p>  <blockquote>   <p>System.Private.CoreLib</p> </blockquote>  <p>Code:</p>  <pre><code>    [FunctionName(\Alert\"")]     public static async Task Alert([ServiceBusTrigger(Topic.Alert  Subscription.PowerBi  Connection = \""servicebusconnectionstring\"")] Message message  TraceWriter log)     {         if (!MessageHandler.Validate(message  Subscription.PowerBi))             return;          var json = Encoding.UTF8.GetString(message.Body);         var messageCounter = message.SystemProperties.DeliveryCount;          try         {             var alert = Validator.ValidateCloudAlert(json);             if (alert != null)             {                 var powerBiAlert = alert.ToPowerBiAlert();                 var result = await PowerBiService.AddRow(powerBiAlert);                 if (!result)                     throw new PowerBiCommandException($\""PowerBiService.AddRows returned value: {result}\"");             }         }         catch (Exception e)         {             EventLogger.LoggException(\""Function.PowerBi.Alert\""  e  new Dictionary&lt;string  string&gt;() { { \""Messsage\""  json } });             if (messageCounter &gt;= 5)             {                 EventLogger.LoggEvent(\""DeadLetterQueue\""  new Dictionary&lt;string  string&gt;() { { \""Function\""  \""Function.PowerBi.Alert\"" }  { \""Messsage\""  json } });                 await QueueService.SendAsync(Queue.Deadletter  JsonConvert.DeserializeObject&lt;CloudAlert&gt;(json)  Topic.Alert  Subscription.PowerBi);             }             else                 throw new MessageAbandonException($\""Abandom message in AzureFunction.PowerBi\"");         }     } </code></pre>  <p>Thanks for the help!</p>""",azure-functions
55557524,"How do I Publish using Azure DevOps? <p>I am trying to setup CI/CD pipeline and publish process for .NET Core 2.1 sample project (it's default project that comes out of the box) using Azure DevOps. So far I have not alter the default code nor have added/removed any references in the project. It's building and running without any error locally.</p>  <p>I have created a simple build pipeline with tasks like Restore  Build and Publish.</p>  <p>For some reason  Publish fails with the following error.</p>  <pre><code>##[section]Starting: Publish ============================================================================== Task         : .NET Core Description  : Build  test  package  or publish a dotnet application  or run a custom dotnet command. For package commands  supports NuGet.org and authenticated feeds like Package Management and MyGet. Version      : 2.149.0 Author       : Microsoft Corporation Help         : [More Information](https://go.microsoft.com/fwlink/?linkid=832194) ============================================================================== [command]C:\\windows\\system32\\chcp.com 65001 Active code page: 65001 [command]\C:\\Program Files\\dotnet\\dotnet.exe\"" publish \""D:\\a\\1\\s\\Devops Demo\\Devops Demo.csproj\"" --configuration release --output D:\\a\\1\\a\\Devops Demo Microsoft (R) Build Engine version 15.9.20+g88f5fadfbe for .NET Core Copyright (C) Microsoft Corporation. All rights reserved.  MSBUILD : error MSB1008: Only one project can be specified. Switch: Demo  For switch syntax  type \""MSBuild /help\"" ##[error]Error: C:\\Program Files\\dotnet\\dotnet.exe failed with return code: 1 ##[error]Dotnet command failed with non-zero exit code on the following projects : D:\\a\\1\\s\\Devops Demo\\Devops Demo.csproj ##[section]Finishing: Publish </code></pre>  <p>I have Googled and founded several people complaining about this error but no body has any definite solution for it.</p>  <p>So far I have not tried anything fancy in my project and CI/CD config. Above error is a blocker for me as I am unable to proceed with my simple devops setup.</p>  <p>Please let me know if you have any suggestion for me to fix this error.</p>  <p>My YAML is as below </p>  <pre><code>pool:   name: Hosted VS2017 #Your build pipeline references an undefined variable named ‘Parameters.RestoreBuildProjects’. Create or edit the build pipeline for this YAML file  define the variable on the Variables tab. See https://go.microsoft.com/fwlink/?linkid=865972 #Your build pipeline references an undefined variable named ‘Parameters.RestoreBuildProjects’. Create or edit the build pipeline for this YAML file  define the variable on the Variables tab. See https://go.microsoft.com/fwlink/?linkid=865972 #Your build pipeline references the ‘BuildConfiguration’ variable  which you’ve selected to be settable at queue time. Create or edit the build pipeline for this YAML file  define the variable on the Variables tab  and then select the option to make it settable at queue time. See https://go.microsoft.com/fwlink/?linkid=865971 #Your build pipeline references the ‘BuildConfiguration’ variable  which you’ve selected to be settable at queue time. Create or edit the build pipeline for this YAML file  define the variable on the Variables tab  and then select the option to make it settable at queue time. See https://go.microsoft.com/fwlink/?linkid=865971  steps: - task: DotNetCoreCLI@2   displayName: Restore   inputs:     command: restore     projects: '$(Parameters.RestoreBuildProjects)'  - task: DotNetCoreCLI@2   displayName: Build   inputs:     projects: '$(Parameters.RestoreBuildProjects)'     arguments: '--configuration $(BuildConfiguration)'  - task: DotNetCoreCLI@2   displayName: Publish   inputs:     command: publish     publishWebProjects: True     arguments: '--configuration $(BuildConfiguration) --output $(build.artifactstagingdirectory)'     workingDirectory: 'Devops Demo'  - task: PublishBuildArtifacts@1   displayName: 'Publish Artifact'   inputs:     PathtoPublish: '$(build.artifactstagingdirectory)' </code></pre>""",azure-devops
31862825,"Is it useless to setup Azure VM \Availability Set\"" without setting up \""Load Balancing\""? <p>Let's say I have VM1 and VM2  using the service WS.cloudapp.com. Let's say I have an web app that has been depployed in both VM1 and VM2 in port 80. Because I'm not yet set up load balancing  so  for the port 80  only one VM can own  let's say VM1. When VM1 is down  end users also can not connect to WS.cloudapp.com. That lead to configuration high availability set is useless  isn't it?  </p>""",azure-virtual-machine
50340216,"ListBlobsSegmentedAsync doesn't return all blob directories <p>I have a hierarchy-structured blob container with around 12k blobs.</p>  <p>--level1</p>  <pre><code>   --level21           --level211           --level212     --level22 </code></pre>  <p>so currently I have two issues</p>  <ol> <li><p>I can not see ListBlobs  even though it occurs in a lot of articles.I know it is weird. but the compiler doesn't pass. <a href=\https://i.stack.imgur.com/bVnrC.jpg\"" rel=\""nofollow noreferrer\"">https://i.stack.imgur.com/bVnrC.jpg</a> I am using c# .netcore 1.1 and WindowsAzure.Storage 8.0  so it should not be version issue.</p></li> <li><p>so I am using ListBlobsSegmentedAsync  for instance  there are 80 sub-folders under level21  but this method only returns 10 of them. await blobs.ListBlobsSegmentedAsync(false  BlobListingDetails.None  20000  null  null  null);</p></li> </ol>""",azure-storage
31513870,"Azure Website Logs Including Internal IPs in Entries <p>For the last couple of weeks  we have been seeing an increasing amount of entries in the web logs of our Azure website whose originating IP address (in the c-ip column of the log) appears to be in the range 100.90.X.X. It has now reached more than half of all the traffic being logged  and is interfering with our ability to perform analytics and threat detection.</p>  <p>According to <a href=\https://en.wikipedia.org/wiki/Reserved_IP_addresses\"" rel=\""nofollow noreferrer\"">the Wikipedia entry on reserved IP addresses</a>  this block is part of one \""Used for communications between a service provider and its subscribers when using a Carrier-grade NAT  as specified by RFC 6598\""  so <strong>could this be a problem in Azure</strong>? </p>  <p>Looking at the logs  the traffic comes from many different user agents (both normal users and the common legitimate bots) and is requesting a broad range of resources  so does not immediately appear suspicious other than the IPs. It looks more like legitimate traffic is being given an incorrect (internal) IP. </p>  <p>It seems to be only affecting static content (e.g. images and XML files)  but not ALL static content.</p>  <p>We are using a single Small Standard instance in Western Europe  with a single web app running on it. We are not using any scaling features. There is a linked SQL database  and the website runs primarily over HTTPs. 95%+ of our traffic comes from UK sources. We have not made any changes to logging  which is handled by Azure.</p>  <p><strong>Is there any way that we can return to seeing the actual IPs here  or is this malicious traffic?</strong> </p>""",azure-web-app-service
57332314,"reading content of blob from azure function <p>I'm trying to read the content of a blob inside an azure function.</p>  <p>Here's the code:</p>  <p>Note:  If I comment out the using block and return the blob i.e.</p>  <p>return new OkObjectResult(blob);</p>  <p>I get back the blob object.</p>  <p>However  if I use the using block  I get 500.</p>  <p>Any idea why I can't get the content?</p>  <pre><code>string storageConnectionString = \myConnectionString\""; CloudStorageAccount storageAccount; CloudStorageAccount.TryParse(storageConnectionString  out storageAccount); CloudBlobClient cloudBlobClient = storageAccount.CreateCloudBlobClient(); CloudBlobContainer container = cloudBlobClient.GetContainerReference(\""drawcontainer\"");   var blob = drawingsContainer.GetBlockBlobReference(\""notes.txt\"");  using (StreamReader reader = new StreamReader(blob.OpenRead())) {     content = reader.ReadToEnd(); } return new OkObjectResult(content); </code></pre>""",azure-functions
57613198,"UrlHelper returning http links on Azure App Service <p>I have a service that when deployed on Azure App Services returns <code>http</code> links instead of <code>https</code> links when using <code>UrlHelper</code>. When testing on my development machine it returns <code>https</code> links as expected  and the service is available and accessed through <code>https</code> requests.</p>  <p>An example of the type of route from my startup I'm trying to use is:</p>  <pre class=\lang-cs prettyprint-override\""><code>routes.MapRoute(     \""FooBar\""      \""api/Foo/{Id}/Bar\""); </code></pre>  <p>The link is then constructed using:</p>  <pre class=\""lang-cs prettyprint-override\""><code>IUrlHelper _urlHelper = // Injected into class via service registration int id = 42; // Arbitrary value for example _urlHelper.Link(\""FooBar\""  new {Id = id}); </code></pre>  <p>When running on my local machine using Docker on Windows from Visual Studio I get a link of <code>https://localhost:1234/api/Foo/42/Bar</code>  but on my deployed Linux Container App Service on Azure I get <code>http://my-app-name.azurewebsites.net/api/Foo/42/Bar</code>.</p>  <p>I don't know what I'm doing wrong to get an <code>http</code> link instead of an <code>https</code> link  and would appreciate any advice/pointing in the right direction.</p>""",azure-web-app-service
41380707,Any way to upload file to azure virtual machine from external application <p>I have a windows application and I want to upload a file from this windows application to azure virtual machine data disk or os disk. I need this because there is some process(run by third party add-on) which work on azure virtual machine  that process only able to read file from local drive. But that file will be generate through my windows application. </p>  <p>Is there any way to achieve this.</p>  <p>Thanks in advance!!</p>,azure-virtual-machine
50225208,Export from Azure Storage Queue to a CSV file <p>What is the easiest way to export data from Azure Queue to a <em>CSV</em> file without writing codes?</p>,azure-storage
40852776,Why is docker stats CPU Percentage greater than 100 times number of cores <p>I have an Azure VM with 2 cores. From my understanding  the CPU % returned by <code>docker stats</code> can be greater than 100% if multiple cores are used. So  this should max out at 200% for this VM. However  I get results like this with CPU % greater than 1000%</p>  <pre><code>CONTAINER           CPU %               MEM USAGE / LIMIT       MEM %               NET I/O               BLOCK I/O             PIDS 545d4c69028f        3.54%               94.39 MiB / 6.803 GiB   1.35%               3.36 MB / 1.442 MB    1.565 MB / 5.673 MB   6 008893e3f70c        625.00%             191.3 MiB / 6.803 GiB   2.75%               0 B / 0 B             0 B / 24.58 kB        35 f49c94dc4567        0.10%               46.85 MiB / 6.803 GiB   0.67%               2.614 MB / 5.01 MB    61.44 kB / 0 B        31 08415d81c355        0.00%               28.76 MiB / 6.803 GiB   0.41%               619.1 kB / 3.701 MB   0 B / 0 B             11 03f54d35a5f8        1.04%               136.5 MiB / 6.803 GiB   1.96%               83.94 MB / 7.721 MB   0 B / 0 B             22 f92faa7321d8        0.15%               19.29 MiB / 6.803 GiB   0.28%               552.5 kB / 758.6 kB   0 B / 2.798 MB        7 2f4a27cc3e44        0.07%               303.8 MiB / 6.803 GiB   4.36%               32.52 MB / 20.27 MB   2.195 MB / 0 B        11 ac96bc45044a        0.00%               19.34 MiB / 6.803 GiB   0.28%               37.28 kB / 12.76 kB   0 B / 3.633 MB        7 7c1a45e92f52        2.20%               356.9 MiB / 6.803 GiB   5.12%               86.36 MB / 156.2 MB   806.9 kB / 0 B        16 0bc4f319b721        14.98%              101.8 MiB / 6.803 GiB   1.46%               138.1 MB / 64.33 MB   0 B / 73.74 MB        75 66aa24598d27        2269.46%            1.269 GiB / 6.803 GiB   18.65%              1.102 GB / 256.4 MB   14.34 MB / 3.412 MB   50 </code></pre>  <p>I can verify there are only two cores:</p>  <pre><code>$ grep -c ^processor /proc/cpuinfo 2 </code></pre>  <p>The output of <code>lshw -short</code> is also confusing to me:</p>  <pre><code>H/W path      Device           Class      Description =====================================================                                system     Virtual Machine /0                             bus        Virtual Machine /0/0                           memory     64KiB BIOS /0/5                           processor  Intel(R) Xeon(R) CPU E5-2673 v3 @ 2.40GHz /0/6                           processor  Xeon (None) /0/7                           processor  (None) /0/8                           processor  (None) /0/9                           processor  (None) /0/a                           processor  (None) /0/b                           processor  (None) /0/c                           processor  (None) /0/d                           processor  (None) /0/e                           processor  (None) /0/f                           processor  (None) /0/10                          processor  (None) ... </code></pre>  <p>with well over 50 processors listed</p>,azure-virtual-machine
50807409,"Many 4 character storage containers being created in my storage account <p>I have an Azure storage account. </p>  <p>For a while now  something has been creating 4 character empty containers as shown here  there are hundreds of them:</p>  <p><a href=\https://i.stack.imgur.com/CIlXp.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/CIlXp.jpg\"" alt=\""enter image description here\""></a></p>  <p>This storage account is used by:</p>  <ul> <li>Function Apps</li> <li>Document Db (Cosmos)</li> <li>Terraform State</li> <li>Container Registry for Docker images</li> </ul>  <p>It's not a big deal but I don't want millions of empty containers being created by an unknown process. </p>  <p><strong>Note1</strong>: I have looked for any way to find more statistics / history of these folders but I cant find any</p>  <p><strong>Note2</strong>: We don't have any custom code that creates storage containers in our release pipelines (ie... PowerShell or CLI)</p>  <p>thanks Russ </p>""",azure-storage
13995734,Azure VMs Virtual Network inter-communication <p>I'm new to Azure (strike 1) and totally suck at networking (strike 2).</p>  <p>Nevertheless  I've got two VMs up and running in the same virtual network; one will act as a web server and the other will act as a SQL database server.</p>  <p>While I can see that their internal IP addresses are both in the same network I'm unable to verify that the machines can communicate with each other and am sort of confused regarding the appropriate place to address this.  </p>  <p>Microsoft's own documentation says </p>  <blockquote>   <p>All virtual machines that you create in Windows Azure can   automatically communicate using a private network channel with other   virtual machines in the same cloud service or <strong>virtual network</strong>.   However  you need to add an endpoint to a machine for other resources   on the Internet or other virtual networks to communicate with it. You   can associate specific ports and a protocol to endpoints. Resources   can connect to an endpoint by using a protocol of TCP or UDP. The TCP   protocol includes HTTP and HTTPS communication.</p> </blockquote>  <p>So why can't the machines at least ping each other via internal IPs?  Is it Windows Firewall getting in the way? I'm starting to wonder if I've chose the wrong approach for a simple web server/database server setup.  Please forgive my ignorance.  Any help would be greatly appreciated.</p>,azure-virtual-machine
54008309,"Azure functions local.settings.json represented in appsettings.json for a ServiceBusTrigger <p>I currently have an azure function using the ServiceBusTrigger binding</p>  <pre><code> [ServiceBusTrigger(\%TopicName%\""  \""%SubscripionName%\""  Connection = \""MyConnection\"")]          string  catclogueEventMsgs  ILogger log  ExecutionContext context) </code></pre>  <p>which uses this local.settings.json file</p>  <pre><code>   \""Values\"": {              …     \""MyConnection\"": \""Endpoint=sb://testxxxxxxxxxxxxxxxxxx     \""SubscriptionName\"": \""testsubscriptionName\""     \""TopicName\"": \""testtopicName\""    } </code></pre>  <p>How do I represent this in the appsettings.json file. Will it be like the below?</p>  <pre><code>   \""Values\"": {     \""MyConnection\"": \""Endpoint=sb://testxxxxxxxxxxxxxxxxxx     \""SubscriptionName\"": \""testsubscriptionName\""     \""TopicName\"": \""testtopicName\""    } </code></pre>  <p>Instead of using a “Values” object can I use eg “MySubs” object like the below?</p>  <pre><code>   \""MySubs\"": {     \""MyConnection\"": \""Endpoint=sb://testxxxxxxxxxxxxxxxxxx     \""SubscriptionName\"": \""testsubscriptionName\""     \""TopicName\"": \""testtopicName\""    } </code></pre>  <p>If its possible to use the above settings  how do I represent this in the ServiceBusTrigger binding? would i change it to this?</p>  <pre><code> [ServiceBusTrigger(\""%MySubs.TopicName%\""  \""%MySubs.SubscripionName%\""  Connection = \""MySubs.MyConnection\"")]          string  catclogueEventMsgs  ILogger log  ExecutionContext context) </code></pre>""",azure-functions
