{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2b8f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get a dataset by name\n",
    "train_ds = Dataset.get_by_name(workspace=ws, name='Stackoverflow dataset')\n",
    "data = train_ds.to_pandas_dataframe()\n",
    "data.columns = ['idx', 'description', 'classification']\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7955a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import BertTokenizer, TFBertPreTrainedModel, TFBertMainLayer\n",
    "from transformers.modeling_tf_utils import get_initializer\n",
    "class TFBertForMultiClassification(TFBertPreTrainedModel):\n",
    "    def __init__(self, config, *inputs, **kwargs):\n",
    "        super(TFBertForMultiClassification, self).__init__(config, *inputs, **kwargs)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = TFBertMainLayer(config, name='bert')\n",
    "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(config.num_labels,\n",
    "                                                kernel_initializer=get_initializer(config.initializer_range),\n",
    "                                                name='classifier',\n",
    "                                                activation='softmax')\n",
    "    def call(self, inputs, **kwargs):\n",
    "        outputs = self.bert(inputs, **kwargs)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output, training=kwargs.get('training', False))\n",
    "        logits = self.classifier(pooled_output)\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        return outputs  # logits, (hidden_states), (attentions)\n",
    "    \n",
    "max_seq_length = 128\n",
    "labels = ['azure-web-app-service', 'azure-storage', 'azure-devops', 'azure-virtual-machine', 'azure-functions']\n",
    "loaded_model = TFBertForMultiClassification.from_pretrained('./model', num_labels=len(labels))\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "print(\"Model loaded from disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "import shap\n",
    "import scipy as sp\n",
    "# from datasets import load_dataset\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0209910",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\",use_fast=True)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased')\n",
    "# config = AutoConfig.from_pretrained('./model/config.json')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('./model/tf_model.h5')\n",
    "model = AutoModelForCausalLM.from_pretrained('./model/tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab21870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.Explainer(model, tokenizer)\n",
    "import shap\n",
    "\n",
    "explainer = shap.DeepExplainer(model, data['Column2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer()\n",
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85022b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
