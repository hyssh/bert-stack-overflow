{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability With Tensorflow 2.0 On Azure Machine Learning Service\n",
    "\n",
    "## Overview of Tutorial\n",
    "This notebook is Part 4 (Explaining Your Model Using Interpretability) of a four part workshop that demonstrates an end-to-end workflow for using Tensorflow 2.0 on Azure Machine Learning Service. The different components of the workshop are as follows:\n",
    "\n",
    "- Part 1: [Preparing Data and Model Training](https://github.com/microsoft/bert-stack-overflow/blob/master/1-Training/AzureServiceClassifier_Training.ipynb)\n",
    "- Part 2: [Inferencing and Deploying a Model](https://github.com/microsoft/bert-stack-overflow/blob/master/2-Inferencing/AzureServiceClassifier_Inferencing.ipynb)\n",
    "- Part 3: [Setting Up a Pipeline Using MLOps](https://github.com/microsoft/bert-stack-overflow/tree/master/3-ML-Ops)\n",
    "- Part 4: [Explaining Your Model Interpretability](https://github.com/microsoft/bert-stack-overflow/blob/master/4-Interpretibility/IBMEmployeeAttritionClassifier_Interpretability.ipynb)\n",
    "\n",
    "**In this specific tutorial, we will cover the following topics:**\n",
    "\n",
    "- TODO\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Azure Machine Learning Service?\n",
    "Azure Machine Learning service is a cloud service that you can use to develop and deploy machine learning models. Using Azure Machine Learning service, you can track your models as you build, train, deploy, and manage them, all at the broad scale that the cloud provides.\n",
    "![](./images/aml-overview.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Machine Learning Interpretability?\n",
    "Interpretability is the ability to explain why your model made the predictions it did. The Azure Machine Learning service offers various interpretability features to help accomplish this task. These features include:\n",
    "\n",
    "- Feature importance values for both raw and engineered features.\n",
    "- Interpretability on real-world datasets at scale, during training and inference.\n",
    "- Interactive visualizations to aid you in the discovery of patterns in data and explanations at training time.\n",
    "\n",
    "By accurately interpretabiliting your model, it allows you to:\n",
    "\n",
    "- Use the insights for debugging your model.\n",
    "- Validate model behavior matches their objectives.\n",
    "- Check for for bias in the model.\n",
    "- Build trust in your customers and stakeholders.\n",
    "\n",
    "![](./images/interpretability-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Azure Machine Learning Python SDK\n",
    "\n",
    "If you are running this on a Notebook VM, the Azure Machine Learning Python SDK is installed by default. If you are running this locally, you can follow these [instructions](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/install?view=azure-ml-py) to install it using pip.\n",
    "\n",
    "This tutorial series requires version 1.0.69 or higher. We can import the Python SDK to ensure it has been properly installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"Azure Machine Learning Python SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect To Workspace\n",
    "\n",
    "Just like in the previous tutorials, we will need to connect to a [workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace(class)?view=azure-ml-py).\n",
    "\n",
    "The following code will allow you to create a workspace if you don't already have one created. You must have an Azure subscription to create a workspace:\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.create(name='myworkspace',\n",
    "                      subscription_id='<azure-subscription-id>',\n",
    "                      resource_group='myresourcegroup',\n",
    "                      create_resource_group=True,\n",
    "                      location='eastus2')\n",
    "```\n",
    "\n",
    "**If you are running this on a Notebook VM, you can import the existing workspace.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "print('Workspace name: ' + workspace.name, \n",
    "      'Azure region: ' + workspace.location, \n",
    "      'Subscription id: ' + workspace.subscription_id, \n",
    "      'Resource group: ' + workspace.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** that the above commands reads a config.json file that exists by default within the Notebook VM. If you are running this locally or want to use a different workspace, you must add a config file to your project directory. The config file should have the following schema:\n",
    "\n",
    "```\n",
    "    {\n",
    "        \"subscription_id\": \"<SUBSCRIPTION-ID>\",\n",
    "        \"resource_group\": \"<RESOURCE-GROUP>\",\n",
    "        \"workspace_name\": \"<WORKSPACE-NAME>\"\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability In Training\n",
    "We will start by showing how we can interpret our model during training. For this tutorial, we will be using Tensorflow 2.0 to train a basic feed forward neural network on the IBM Employee Attrition Dataset. \n",
    "\n",
    "**Write this script into a project directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = 'ibm-attrition-classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1323 samples, validate on 147 samples\n",
      "Epoch 1/3\n",
      "1323/1323 [==============================] - 0s 132us/sample - loss: 297.3814 - acc: 0.8360 - val_loss: 165.1564 - val_acc: 0.8639\n",
      "Epoch 2/3\n",
      "1323/1323 [==============================] - 0s 20us/sample - loss: 187.7943 - acc: 0.8360 - val_loss: 88.4600 - val_acc: 0.8639\n",
      "Epoch 3/3\n",
      "1323/1323 [==============================] - 0s 21us/sample - loss: 96.9134 - acc: 0.7944 - val_loss: 69.0247 - val_acc: 0.7551\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/train.py\n",
    "import logging\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from absl import flags\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ignore warnings in logs\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data = pd.read_csv(\"data/emp_attrition.csv\")\n",
    "\n",
    "    # replace binary labels with 1's and 0's\n",
    "    binary_data = {\n",
    "        'Gender': ['Male', 'Female'],\n",
    "        'Over18': ['N', 'Y'],\n",
    "        'OverTime': ['No', 'Yes'],\n",
    "        'Attrition': ['No', 'Yes']\n",
    "    }\n",
    "    for k, v in binary_data.items():\n",
    "        data[k].replace(v, [0, 1], inplace=True)\n",
    "\n",
    "    # Make column labeling consistent, so that 1 indicates True\n",
    "    data.rename(columns={'Gender': 'IsFemale'}, inplace = True)\n",
    "\n",
    "    # one-hot encode categorical data\n",
    "    one_hot_cols = ['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus']\n",
    "    for col_name in one_hot_cols:\n",
    "        data = pd.concat([data, pd.get_dummies(data[col_name], drop_first=True)], axis=1)\n",
    "        data.drop([col_name], axis=1, inplace=True)\n",
    "        \n",
    "    # Split data\n",
    "    train, test = train_test_split(data, test_size=0.1)\n",
    "    train_y = train.pop('Attrition')\n",
    "    test_y = test.pop('Attrition')\n",
    "    \n",
    "    return train, test, train_y, test_y\n",
    "\n",
    "# Load data\n",
    "raw_data = pd.read_csv(\"data/emp_attrition.csv\")\n",
    "train_x, test_x, train_y, test_y = preprocess_data(raw_data)\n",
    "\n",
    "# Train model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=16, activation='relu', input_shape=(len(train_x.columns),)))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train neural network\n",
    "model.fit(train_x, train_y, epochs=3, verbose=1, batch_size=128, validation_data=(test_x, test_y))\n",
    "\n",
    "# Save model\n",
    "model.save('ibm-attrition-classifier/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run training script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"ibm-attrition-classifier/train.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "ImportError: No module named pandas\n"
     ]
    }
   ],
   "source": [
    "!python $project_folder/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model and perform interpretability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - From /anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING - From /anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# TODO:  LOAD MODEL AND EXPLAIN IT\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('ibm-attrition-classifier/model.h5')\n",
    "\n",
    "# from azureml.explain.model.tabular_explainer import TabularExplainer\n",
    "# # \"features\" and \"classes\" fields are optional\n",
    "# explainer = TabularExplainer(network, \n",
    "#                              train)\n",
    "\n",
    "# # you can use the training data or the test data here\n",
    "# global_explanation = explainer.explain_global(x_train)\n",
    "\n",
    "# # if you used the PFIExplainer in the previous step, use the next line of code instead\n",
    "# # global_explanation = explainer.explain_global(x_train, true_labels=y_test)\n",
    "\n",
    "# # sorted feature importance values and feature names\n",
    "# sorted_global_importance_values = global_explanation.get_ranked_global_values()\n",
    "# sorted_global_importance_names = global_explanation.get_ranked_global_names()\n",
    "# dict(zip(sorted_global_importance_names, sorted_global_importance_values))\n",
    "\n",
    "# # alternatively, you can print out a dictionary that holds the top K feature names and values\n",
    "# global_explanation.get_feature_importance_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Explain Locally\n",
    "We will start by training our model locally in the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Explain Remotely\n",
    "Now we will train our model on the compute target created back in the [first tutorial]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability In Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Feature Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
