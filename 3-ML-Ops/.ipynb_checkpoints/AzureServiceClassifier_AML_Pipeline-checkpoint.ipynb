{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23bd7455",
   "metadata": {},
   "source": [
    "# Part 3: Publish Azure Machine Learning Pipeline to Train BERT Model\n",
    "\n",
    "## Overview of the part 3\n",
    "For this exercise, we assume that you have trained and deployed a machine learning model and that you are now ready to manage the end-to-end lifecycle of your model. [MLOps](https://docs.microsoft.com/azure/machine-learning/service/concept-model-management-and-deployment) can help you to automatically deploy your model as a web application while implementing quality benchmarks, strict version control, model monitoring, and providing an audit trail.\n",
    "\n",
    "The different components of the workshop are as follows:\n",
    "\n",
    "- Part 1: [Preparing Data and Model Training](https://github.com/microsoft/bert-stack-overflow/blob/master/1-Training/AzureServiceClassifier_Training.ipynb)\n",
    "- Part 2: [Inferencing and Deploying a Model](https://github.com/microsoft/bert-stack-overflow/blob/master/2-Inferencing/AzureServiceClassifier_Inferencing.ipynb)\n",
    "- Part 3: [Setting Up a Pipeline Using MLOps](https://github.com/microsoft/bert-stack-overflow/tree/master/3-ML-Ops)\n",
    "- Part 4: [Explaining Your Model Interpretability](https://github.com/microsoft/bert-stack-overflow/blob/master/4-Interpretibility/IBMEmployeeAttritionClassifier_Interpretability.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a613c1",
   "metadata": {},
   "source": [
    "## Connect to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec584ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da13986",
   "metadata": {},
   "source": [
    "## Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aml_compute_target = \"gpu-nc8-t4\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 0, \n",
    "                                                                max_nodes = 2)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "print(\"Azure Machine Learning Compute attached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccf75a",
   "metadata": {},
   "source": [
    "## Pipeline-specific SDK imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb16bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.runconfig import RunConfiguration, CondaDependencies\n",
    "from azureml.core import Dataset, Datastore\n",
    "from azureml.train.dnn import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7e922",
   "metadata": {},
   "source": [
    "## Define Parameters for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = PipelineParameter(name=\"model_name\", default_value='azure-service-classifier')\n",
    "\n",
    "max_seq_length = PipelineParameter(name=\"max_seq_length\", default_value=128)\n",
    "\n",
    "learning_rate = PipelineParameter(name=\"learning_rate\", default_value=3e-5)\n",
    "\n",
    "num_epochs = PipelineParameter(name=\"num_epochs\", default_value=3)\n",
    "\n",
    "export_dir = PipelineParameter(name=\"export_dir\", default_value=\"./outputs/exports\")\n",
    "\n",
    "batch_size = PipelineParameter(name=\"batch_size\", default_value=32)\n",
    "\n",
    "steps_per_epoch = PipelineParameter(name=\"steps_per_epoch\", default_value=5)\n",
    "\n",
    "build_id = PipelineParameter(name='build_id', default_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1509e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get a dataset by name\n",
    "train_ds = Dataset.get_by_name(workspace=ws, name='Azure Services Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56566ac6",
   "metadata": {},
   "source": [
    "## Creating Steps in a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment \n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "\n",
    "aml_run_config = RunConfiguration(conda_dependencies=CondaDependencies.create(\n",
    "    conda_packages=['numpy', 'pandas',\n",
    "                    'scikit-learn', 'keras'],\n",
    "    pip_packages=['azureml-core==1.25.0', \n",
    "                  'azureml-defaults==1.25.0',\n",
    "                  'azureml-telemetry==1.25.0',\n",
    "                  'azureml-train-restclients-hyperdrive==1.25.0',\n",
    "                  'azureml-train-core==1.25.0',\n",
    "                  'azureml-dataprep',\n",
    "                  'tensorflow-gpu==2.0.0',\n",
    "                  'transformers==2.0.0',\n",
    "                  \"absl-py\",\n",
    "                  \"azureml-dataprep\",\n",
    "                  'h5py<3.0.0'])\n",
    ")\n",
    "\n",
    "aml_run_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = './scripts'\n",
    "\n",
    "trainStep = PythonScriptStep(name = 'Train_step',\n",
    "                            script_name = './training/train.py',\n",
    "                            arguments=['--data_dir', train_ds.as_named_input('azureservicedata').as_mount(),\n",
    "                              '--max_seq_length', max_seq_length,\n",
    "                              '--batch_size', batch_size,\n",
    "                              '--learning_rate', learning_rate,\n",
    "                              '--steps_per_epoch', steps_per_epoch,\n",
    "                              '--num_epochs', num_epochs,\n",
    "                              '--export_dir','./outputs/model'],\n",
    "                            compute_target = aml_compute,\n",
    "                            source_directory = source_directory,\n",
    "                            runconfig = aml_run_config,\n",
    "                            allow_reuse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalStep = PythonScriptStep(name = 'Eval_step',\n",
    "                           script_name = './evaluate/evaluate_model.py',\n",
    "                           arguments=['--build_id', build_id,\n",
    "                              '--model_name', model_name],\n",
    "                            compute_target = aml_compute,\n",
    "                            source_directory = source_directory,\n",
    "                            runconfig = aml_run_config,\n",
    "                            allow_reuse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalStep.run_after(trainStep)\n",
    "steps = [evalStep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df254bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "train_pipeline.validate()\n",
    "published_pipeline = train_pipeline.publish(name='AzureServiceClassifier_BERT_Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
