{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23bd7455",
   "metadata": {},
   "source": [
    "# Part 3: Publish Azure Machine Learning Pipeline to Train BERT Model\n",
    "\n",
    "## Overview of the part 3\n",
    "For this exercise, we assume that you have trained and deployed a machine learning model and that you are now ready to manage the end-to-end lifecycle of your model. [MLOps](https://docs.microsoft.com/azure/machine-learning/service/concept-model-management-and-deployment) can help you to automatically deploy your model as a web application while implementing quality benchmarks, strict version control, model monitoring, and providing an audit trail.\n",
    "\n",
    "The different components of the workshop are as follows:\n",
    "\n",
    "- Part 1: [Preparing Data and Model Training](https://github.com/microsoft/bert-stack-overflow/blob/master/1-Training/AzureServiceClassifier_Training.ipynb)\n",
    "- Part 2: [Inferencing and Deploying a Model](https://github.com/microsoft/bert-stack-overflow/blob/master/2-Inferencing/AzureServiceClassifier_Inferencing.ipynb)\n",
    "- Part 3: [Setting Up a Pipeline Using MLOps](https://github.com/microsoft/bert-stack-overflow/tree/master/3-ML-Ops)\n",
    "- Part 4: [Explaining Your Model Interpretability](https://github.com/microsoft/bert-stack-overflow/blob/master/4-Interpretibility/IBMEmployeeAttritionClassifier_Interpretability.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a613c1",
   "metadata": {},
   "source": [
    "## Connect to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec584ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: mtcs-stg-azml\n",
      "Azure region: westus2\n",
      "Subscription id: 256c7222-4083-4ba7-8714-baa0df54bfe6\n",
      "Resource group: mtcs-stg-azml-rg\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da13986",
   "metadata": {},
   "source": [
    "## Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29eb8dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found existing compute target.\n",
      "Azure Machine Learning Compute attached\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aml_compute_target = \"gpu-nc8-t4\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 0, \n",
    "                                                                max_nodes = 2)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "print(\"Azure Machine Learning Compute attached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccf75a",
   "metadata": {},
   "source": [
    "## Pipeline-specific SDK imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb16bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.runconfig import RunConfiguration, CondaDependencies\n",
    "from azureml.core import Dataset, Datastore\n",
    "from azureml.train.dnn import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7e922",
   "metadata": {},
   "source": [
    "## Define Parameters for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6209d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = PipelineParameter(name=\"model_name\", default_value='azure-service-classifier')\n",
    "\n",
    "max_seq_length = PipelineParameter(name=\"max_seq_length\", default_value=128)\n",
    "\n",
    "learning_rate = PipelineParameter(name=\"learning_rate\", default_value=3e-5)\n",
    "\n",
    "num_epochs = PipelineParameter(name=\"num_epochs\", default_value=3)\n",
    "\n",
    "export_dir = PipelineParameter(name=\"export_dir\", default_value=\"./outputs/exports\")\n",
    "\n",
    "batch_size = PipelineParameter(name=\"batch_size\", default_value=32)\n",
    "\n",
    "steps_per_epoch = PipelineParameter(name=\"steps_per_epoch\", default_value=100)\n",
    "\n",
    "build_id = PipelineParameter(name='build_id', default_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1509e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get a dataset by name\n",
    "train_ds = Dataset.get_by_name(workspace=ws, name='Azure Services Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56566ac6",
   "metadata": {},
   "source": [
    "## Creating Steps in a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e423a374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"script\": null,\n",
       "    \"arguments\": [],\n",
       "    \"target\": \"local\",\n",
       "    \"framework\": \"Python\",\n",
       "    \"communicator\": \"None\",\n",
       "    \"maxRunDurationSeconds\": null,\n",
       "    \"nodeCount\": 1,\n",
       "    \"priority\": null,\n",
       "    \"environment\": {\n",
       "        \"name\": null,\n",
       "        \"version\": null,\n",
       "        \"environmentVariables\": {\n",
       "            \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "        },\n",
       "        \"python\": {\n",
       "            \"userManagedDependencies\": false,\n",
       "            \"interpreterPath\": \"python\",\n",
       "            \"condaDependenciesFile\": null,\n",
       "            \"baseCondaEnvironment\": null,\n",
       "            \"condaDependencies\": {\n",
       "                \"name\": \"project_environment\",\n",
       "                \"dependencies\": [\n",
       "                    \"python=3.6.2\",\n",
       "                    {\n",
       "                        \"pip\": [\n",
       "                            \"azureml-core~=1.27.0\",\n",
       "                            \"azureml-defaults~=1.27.0\",\n",
       "                            \"azureml-telemetry~=1.27.0\",\n",
       "                            \"azureml-train-restclients-hyperdrive~=1.27.0\",\n",
       "                            \"azureml-train-core~=1.27.0\",\n",
       "                            \"tensorflow-gpu==2.0.0\",\n",
       "                            \"transformers==2.0.0\",\n",
       "                            \"absl-py\",\n",
       "                            \"azureml-dataprep\",\n",
       "                            \"h5py<3.0.0\"\n",
       "                        ]\n",
       "                    },\n",
       "                    \"numpy\",\n",
       "                    \"pandas\",\n",
       "                    \"scikit-learn\",\n",
       "                    \"keras\"\n",
       "                ],\n",
       "                \"channels\": [\n",
       "                    \"anaconda\",\n",
       "                    \"conda-forge\"\n",
       "                ]\n",
       "            }\n",
       "        },\n",
       "        \"docker\": {\n",
       "            \"enabled\": false,\n",
       "            \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1\",\n",
       "            \"baseDockerfile\": null,\n",
       "            \"sharedVolumes\": true,\n",
       "            \"shmSize\": \"2g\",\n",
       "            \"arguments\": [],\n",
       "            \"baseImageRegistry\": {\n",
       "                \"address\": null,\n",
       "                \"username\": null,\n",
       "                \"password\": null,\n",
       "                \"registryIdentity\": null\n",
       "            },\n",
       "            \"platform\": {\n",
       "                \"os\": \"Linux\",\n",
       "                \"architecture\": \"amd64\"\n",
       "            }\n",
       "        },\n",
       "        \"spark\": {\n",
       "            \"repositories\": [],\n",
       "            \"packages\": [],\n",
       "            \"precachePackages\": true\n",
       "        },\n",
       "        \"databricks\": {\n",
       "            \"mavenLibraries\": [],\n",
       "            \"pypiLibraries\": [],\n",
       "            \"rcranLibraries\": [],\n",
       "            \"jarLibraries\": [],\n",
       "            \"eggLibraries\": []\n",
       "        },\n",
       "        \"r\": null,\n",
       "        \"inferencingStackVersion\": null\n",
       "    },\n",
       "    \"history\": {\n",
       "        \"outputCollection\": true,\n",
       "        \"snapshotProject\": true,\n",
       "        \"directoriesToWatch\": [\n",
       "            \"logs\"\n",
       "        ]\n",
       "    },\n",
       "    \"spark\": {\n",
       "        \"configuration\": {\n",
       "            \"spark.app.name\": \"Azure ML Experiment\",\n",
       "            \"spark.yarn.maxAppAttempts\": 1\n",
       "        }\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"useDocker\": false,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"arguments\": [],\n",
       "        \"shmSize\": \"2g\"\n",
       "    },\n",
       "    \"hdi\": {\n",
       "        \"yarnDeployMode\": \"cluster\"\n",
       "    },\n",
       "    \"tensorflow\": {\n",
       "        \"workerCount\": 1,\n",
       "        \"parameterServerCount\": 1\n",
       "    },\n",
       "    \"mpi\": {\n",
       "        \"processCountPerNode\": 1,\n",
       "        \"nodeCount\": 1\n",
       "    },\n",
       "    \"pytorch\": {\n",
       "        \"communicationBackend\": \"nccl\",\n",
       "        \"processCount\": null,\n",
       "        \"nodeCount\": 1\n",
       "    },\n",
       "    \"paralleltask\": {\n",
       "        \"maxRetriesPerWorker\": 0,\n",
       "        \"workerCountPerNode\": 1,\n",
       "        \"terminalExitCodes\": null\n",
       "    },\n",
       "    \"dataReferences\": {},\n",
       "    \"data\": {},\n",
       "    \"outputData\": {},\n",
       "    \"sourceDirectoryDataStore\": null,\n",
       "    \"amlcompute\": {\n",
       "        \"vmSize\": null,\n",
       "        \"vmPriority\": null,\n",
       "        \"retainCluster\": false,\n",
       "        \"name\": null,\n",
       "        \"clusterMaxNodeCount\": null\n",
       "    },\n",
       "    \"credentialPassthrough\": false,\n",
       "    \"command\": \"\"\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment \n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "\n",
    "# env = Environment.get(ws, name='AzureML-TensorFlow-2.0-GPU')\n",
    "# env.python.conda_dependencies.add_pip_package(\"transformers==2.0.0\")\n",
    "# env.python.conda_dependencies.add_pip_package(\"absl-py\")\n",
    "# env.python.conda_dependencies.add_pip_package(\"azureml-dataprep\")\n",
    "# env.python.conda_dependencies.add_pip_package(\"h5py<3.0.0\")\n",
    "# env.python.conda_dependencies.add_pip_package(\"pandas\")\n",
    "\n",
    "# env.name = \"Bert_training\"\n",
    "\n",
    "# aml_run_config.environment.python.conda_dependencies = env.python.conda_dependencies\n",
    "# aml_run_config.environment.docker.enabled = True\n",
    "\n",
    "aml_run_config = RunConfiguration(conda_dependencies=CondaDependencies.create(\n",
    "    conda_packages=['numpy', 'pandas',\n",
    "                    'scikit-learn', 'keras'],\n",
    "    pip_packages=['azureml-core==1.25.0', \n",
    "                  'azureml-defaults==1.25.0',\n",
    "                  'azureml-telemetry==1.25.0',\n",
    "                  'azureml-train-restclients-hyperdrive==1.25.0',\n",
    "                  'azureml-train-core==1.25.0',\n",
    "                  'azureml-dataprep',\n",
    "                  'tensorflow-gpu==2.0.0',\n",
    "                  'transformers==2.0.0',\n",
    "                  \"absl-py\",\n",
    "                  \"azureml-dataprep\",\n",
    "                  'h5py<3.0.0'])\n",
    ")\n",
    "\n",
    "# aml_run_config .DockerConfiguration.use_docker = True\n",
    "\n",
    "aml_run_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = './scripts'\n",
    "\n",
    "trainStep = PythonScriptStep(name = 'Train_step',\n",
    "                            script_name = './training/train.py',\n",
    "                            arguments=['--data_dir', train_ds.as_named_input('azureservicedata').as_mount(),\n",
    "                              '--max_seq_length', max_seq_length,\n",
    "                              '--batch_size', batch_size,\n",
    "                              '--learning_rate', learning_rate,\n",
    "                              '--steps_per_epoch', steps_per_epoch,\n",
    "                              '--num_epochs', num_epochs,\n",
    "                              '--export_dir','./outputs/model'],\n",
    "                            compute_target = aml_compute,\n",
    "                            source_directory = source_directory,\n",
    "                            runconfig = aml_run_config,\n",
    "                            allow_reuse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalStep = PythonScriptStep(name = 'Eval_step',\n",
    "                           script_name = './evaluate/evaluate_model.py',\n",
    "                           arguments=['--build_id', build_id,\n",
    "                              '--model_name', model_name],\n",
    "                            compute_target = aml_compute,\n",
    "                            source_directory = source_directory,\n",
    "                            runconfig = aml_run_config,\n",
    "                            allow_reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalStep.run_after(trainStep)\n",
    "steps = [evalStep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df254bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "train_pipeline.validate()\n",
    "published_pipeline = train_pipeline.publish(name='AzureServiceClassifier_BERT_Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca3956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
